# Comparing `tmp/fbnlab_preview-0.1.74-py3-none-any.whl.zip` & `tmp/fbnlab_preview-0.1.8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,64 +1,52 @@
-Zip file size: 57466 bytes, number of entries: 62
--rw-r--r--  2.0 unx      456 b- defN 23-Aug-02 09:59 finbourne_lab/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab/analysis/__init__.py
--rw-r--r--  2.0 unx    16852 b- defN 23-Aug-02 09:59 finbourne_lab/analysis/ab_test.py
--rw-r--r--  2.0 unx     6397 b- defN 23-Aug-02 09:59 finbourne_lab/analysis/distribution.py
--rw-r--r--  2.0 unx    11428 b- defN 23-Aug-02 09:59 finbourne_lab/analysis/linear.py
--rw-r--r--  2.0 unx     6286 b- defN 23-Aug-02 09:59 finbourne_lab/analysis/plotting.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab/common/__init__.py
--rw-r--r--  2.0 unx     2258 b- defN 23-Aug-02 09:59 finbourne_lab/common/base_lab.py
--rw-r--r--  2.0 unx     3554 b- defN 23-Aug-02 09:59 finbourne_lab/common/convener.py
--rw-r--r--  2.0 unx     3385 b- defN 23-Aug-02 09:59 finbourne_lab/common/experiment.py
--rw-r--r--  2.0 unx     1072 b- defN 23-Aug-02 09:59 finbourne_lab/common/observation.py
--rw-r--r--  2.0 unx     2215 b- defN 23-Aug-02 09:59 finbourne_lab/common/sdk_experiment.py
--rw-r--r--  2.0 unx     2248 b- defN 23-Aug-02 09:59 finbourne_lab/common/shopper.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab/common/recorder/__init__.py
--rw-r--r--  2.0 unx     2265 b- defN 23-Aug-02 09:59 finbourne_lab/common/recorder/base.py
--rw-r--r--  2.0 unx     1890 b- defN 23-Aug-02 09:59 finbourne_lab/common/recorder/drive.py
--rw-r--r--  2.0 unx     1259 b- defN 23-Aug-02 09:59 finbourne_lab/common/recorder/file.py
--rw-r--r--  2.0 unx      413 b- defN 23-Aug-02 09:59 finbourne_lab/common/recorder/no_op.py
--rw-r--r--  2.0 unx     6412 b- defN 23-Aug-02 09:59 finbourne_lab/common/recorder/sql_db.py
--rw-r--r--  2.0 unx      442 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/__init__.py
--rw-r--r--  2.0 unx     3339 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/__main__.py
--rw-r--r--  2.0 unx     3759 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/base.py
--rw-r--r--  2.0 unx     7399 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/core.py
--rw-r--r--  2.0 unx     4202 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/drive.py
--rw-r--r--  2.0 unx     4232 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/experiment.py
--rw-r--r--  2.0 unx      979 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/shopper_setup.py
--rw-r--r--  2.0 unx     1141 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/utils.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/lusid/__init__.py
--rw-r--r--  2.0 unx      886 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/lusid/base.py
--rw-r--r--  2.0 unx     7146 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/lusid/ensure.py
--rw-r--r--  2.0 unx     7638 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/lusid/lusid_read.py
--rw-r--r--  2.0 unx     8376 b- defN 23-Aug-02 09:59 finbourne_lab/luminesce/lusid/lusid_write.py
--rw-r--r--  2.0 unx      172 b- defN 23-Aug-02 09:59 finbourne_lab/lusid/__init__.py
--rw-r--r--  2.0 unx      203 b- defN 23-Aug-02 09:59 finbourne_lab/lusid/base.py
--rw-r--r--  2.0 unx     5406 b- defN 23-Aug-02 09:59 finbourne_lab/lusid/client.py
--rw-r--r--  2.0 unx      262 b- defN 23-Aug-02 09:59 finbourne_lab/lusid/experiment.py
--rw-r--r--  2.0 unx      936 b- defN 23-Aug-02 09:59 finbourne_lab/lusid/instrument.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/integration/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/integration/luminesce/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/integration/lusid/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/analysis/__init__.py
--rw-r--r--  2.0 unx     3401 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/analysis/test_ab_test.py
--rw-r--r--  2.0 unx     2213 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/analysis/test_distribution.py
--rw-r--r--  2.0 unx     2792 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/analysis/test_linear.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/common/__init__.py
--rw-r--r--  2.0 unx     2560 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/common/test_convener.py
--rw-r--r--  2.0 unx     3412 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/common/test_experiment.py
--rw-r--r--  2.0 unx     1425 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/common/test_observation.py
--rw-r--r--  2.0 unx     1266 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/common/test_recorder.py
--rw-r--r--  2.0 unx     2254 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/common/test_sdk_experiment.py
--rw-r--r--  2.0 unx     1607 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/common/test_shopper.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/luminesce/__init__.py
--rw-r--r--  2.0 unx     2281 b- defN 23-Aug-02 09:59 finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py
--rw-r--r--  2.0 unx        0 b- defN 23-Aug-02 09:59 finbourne_lab_test/utils/__init__.py
--rw-r--r--  2.0 unx     3218 b- defN 23-Aug-02 09:59 finbourne_lab_test/utils/mock.py
--rw-r--r--  2.0 unx     1333 b- defN 23-Aug-02 09:59 finbourne_lab_test/utils/test_data_generation.py
--rw-r--r--  2.0 unx      697 b- defN 23-Aug-02 10:07 fbnlab_preview-0.1.74.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Aug-02 10:07 fbnlab_preview-0.1.74.dist-info/WHEEL
--rw-r--r--  2.0 unx       33 b- defN 23-Aug-02 10:07 fbnlab_preview-0.1.74.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     5835 b- defN 23-Aug-02 10:07 fbnlab_preview-0.1.74.dist-info/RECORD
-62 files, 159327 bytes uncompressed, 47920 bytes compressed:  69.9%
+Zip file size: 40626 bytes, number of entries: 50
+-rw-r--r--  2.0 unx      106 b- defN 22-Jul-29 08:09 finbourne_lab/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab/analysis/__init__.py
+-rw-r--r--  2.0 unx    10041 b- defN 22-Jul-29 08:09 finbourne_lab/analysis/linear.py
+-rw-r--r--  2.0 unx     6291 b- defN 22-Jul-29 08:09 finbourne_lab/analysis/plotting.py
+-rw-r--r--  2.0 unx      126 b- defN 22-Jul-29 08:09 finbourne_lab/base/__init__.py
+-rw-r--r--  2.0 unx     5885 b- defN 22-Jul-29 08:09 finbourne_lab/base/experiment.py
+-rw-r--r--  2.0 unx     2313 b- defN 22-Jul-29 08:09 finbourne_lab/base/measurement_factory.py
+-rw-r--r--  2.0 unx     1309 b- defN 22-Jul-29 08:09 finbourne_lab/base/result.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab/common/__init__.py
+-rw-r--r--  2.0 unx     3571 b- defN 22-Jul-29 08:09 finbourne_lab/common/api.py
+-rw-r--r--  2.0 unx     8568 b- defN 22-Jul-29 08:09 finbourne_lab/common/convener.py
+-rw-r--r--  2.0 unx       40 b- defN 22-Jul-29 08:09 finbourne_lab/drive/__init__.py
+-rw-r--r--  2.0 unx      934 b- defN 22-Jul-29 08:09 finbourne_lab/drive/experiment.py
+-rw-r--r--  2.0 unx      167 b- defN 22-Jul-29 08:09 finbourne_lab/drive/measurements.py
+-rw-r--r--  2.0 unx      201 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/__init__.py
+-rw-r--r--  2.0 unx     3837 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/experiment.py
+-rw-r--r--  2.0 unx    10469 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/lusid_reader.py
+-rw-r--r--  2.0 unx    13531 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/lusid_writer.py
+-rw-r--r--  2.0 unx     2397 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/measurements.py
+-rw-r--r--  2.0 unx    13211 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/standard.py
+-rw-r--r--  2.0 unx     1361 b- defN 22-Jul-29 08:09 finbourne_lab/luminesce/utils.py
+-rw-r--r--  2.0 unx       59 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/__init__.py
+-rw-r--r--  2.0 unx     5190 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/client.py
+-rw-r--r--  2.0 unx      964 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/experiment.py
+-rw-r--r--  2.0 unx      143 b- defN 22-Jul-29 08:09 finbourne_lab/lusid/measurements.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/drive/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/luminesce/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/integration/lusid/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/analysis/__init__.py
+-rw-r--r--  2.0 unx     2820 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/analysis/test_linear_scaling_model.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/common/__init__.py
+-rw-r--r--  2.0 unx     5659 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/common/test_base_experiment.py
+-rw-r--r--  2.0 unx     3185 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/common/test_measurement_set.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/drive/__init__.py
+-rw-r--r--  2.0 unx     1058 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/drive/test_drive_experiment.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/luminesce/__init__.py
+-rw-r--r--  2.0 unx     4123 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/lusid/__init__.py
+-rw-r--r--  2.0 unx     1058 b- defN 22-Jul-29 08:09 finbourne_lab_test/unit/lusid/test_lusid_experiment.py
+-rw-r--r--  2.0 unx        0 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/__init__.py
+-rw-r--r--  2.0 unx     2277 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/mock.py
+-rw-r--r--  2.0 unx     1333 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/test_data_generation.py
+-rw-r--r--  2.0 unx      725 b- defN 22-Jul-29 08:09 finbourne_lab_test/utils/test_experiment.py
+-rw-r--r--  2.0 unx      496 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/WHEEL
+-rw-r--r--  2.0 unx       33 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     4693 b- defN 22-Jul-29 08:14 fbnlab_preview-0.1.8.dist-info/RECORD
+50 files, 118266 bytes uncompressed, 32900 bytes compressed:  72.2%
```

## zipnote {}

```diff
@@ -1,187 +1,151 @@
 Filename: finbourne_lab/__init__.py
 Comment: 
 
 Filename: finbourne_lab/analysis/__init__.py
 Comment: 
 
-Filename: finbourne_lab/analysis/ab_test.py
-Comment: 
-
-Filename: finbourne_lab/analysis/distribution.py
-Comment: 
-
 Filename: finbourne_lab/analysis/linear.py
 Comment: 
 
 Filename: finbourne_lab/analysis/plotting.py
 Comment: 
 
-Filename: finbourne_lab/common/__init__.py
+Filename: finbourne_lab/base/__init__.py
 Comment: 
 
-Filename: finbourne_lab/common/base_lab.py
+Filename: finbourne_lab/base/experiment.py
 Comment: 
 
-Filename: finbourne_lab/common/convener.py
+Filename: finbourne_lab/base/measurement_factory.py
 Comment: 
 
-Filename: finbourne_lab/common/experiment.py
+Filename: finbourne_lab/base/result.py
 Comment: 
 
-Filename: finbourne_lab/common/observation.py
-Comment: 
-
-Filename: finbourne_lab/common/sdk_experiment.py
-Comment: 
-
-Filename: finbourne_lab/common/shopper.py
-Comment: 
-
-Filename: finbourne_lab/common/recorder/__init__.py
+Filename: finbourne_lab/common/__init__.py
 Comment: 
 
-Filename: finbourne_lab/common/recorder/base.py
+Filename: finbourne_lab/common/api.py
 Comment: 
 
-Filename: finbourne_lab/common/recorder/drive.py
+Filename: finbourne_lab/common/convener.py
 Comment: 
 
-Filename: finbourne_lab/common/recorder/file.py
+Filename: finbourne_lab/drive/__init__.py
 Comment: 
 
-Filename: finbourne_lab/common/recorder/no_op.py
+Filename: finbourne_lab/drive/experiment.py
 Comment: 
 
-Filename: finbourne_lab/common/recorder/sql_db.py
+Filename: finbourne_lab/drive/measurements.py
 Comment: 
 
 Filename: finbourne_lab/luminesce/__init__.py
 Comment: 
 
-Filename: finbourne_lab/luminesce/__main__.py
-Comment: 
-
-Filename: finbourne_lab/luminesce/base.py
-Comment: 
-
-Filename: finbourne_lab/luminesce/core.py
-Comment: 
-
-Filename: finbourne_lab/luminesce/drive.py
-Comment: 
-
 Filename: finbourne_lab/luminesce/experiment.py
 Comment: 
 
-Filename: finbourne_lab/luminesce/shopper_setup.py
-Comment: 
-
-Filename: finbourne_lab/luminesce/utils.py
-Comment: 
-
-Filename: finbourne_lab/luminesce/lusid/__init__.py
+Filename: finbourne_lab/luminesce/lusid_reader.py
 Comment: 
 
-Filename: finbourne_lab/luminesce/lusid/base.py
+Filename: finbourne_lab/luminesce/lusid_writer.py
 Comment: 
 
-Filename: finbourne_lab/luminesce/lusid/ensure.py
+Filename: finbourne_lab/luminesce/measurements.py
 Comment: 
 
-Filename: finbourne_lab/luminesce/lusid/lusid_read.py
+Filename: finbourne_lab/luminesce/standard.py
 Comment: 
 
-Filename: finbourne_lab/luminesce/lusid/lusid_write.py
+Filename: finbourne_lab/luminesce/utils.py
 Comment: 
 
 Filename: finbourne_lab/lusid/__init__.py
 Comment: 
 
-Filename: finbourne_lab/lusid/base.py
-Comment: 
-
 Filename: finbourne_lab/lusid/client.py
 Comment: 
 
 Filename: finbourne_lab/lusid/experiment.py
 Comment: 
 
-Filename: finbourne_lab/lusid/instrument.py
+Filename: finbourne_lab/lusid/measurements.py
 Comment: 
 
 Filename: finbourne_lab_test/__init__.py
 Comment: 
 
 Filename: finbourne_lab_test/integration/__init__.py
 Comment: 
 
+Filename: finbourne_lab_test/integration/drive/__init__.py
+Comment: 
+
 Filename: finbourne_lab_test/integration/luminesce/__init__.py
 Comment: 
 
 Filename: finbourne_lab_test/integration/lusid/__init__.py
 Comment: 
 
 Filename: finbourne_lab_test/unit/__init__.py
 Comment: 
 
 Filename: finbourne_lab_test/unit/analysis/__init__.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/analysis/test_ab_test.py
-Comment: 
-
-Filename: finbourne_lab_test/unit/analysis/test_distribution.py
-Comment: 
-
-Filename: finbourne_lab_test/unit/analysis/test_linear.py
+Filename: finbourne_lab_test/unit/analysis/test_linear_scaling_model.py
 Comment: 
 
 Filename: finbourne_lab_test/unit/common/__init__.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/common/test_convener.py
+Filename: finbourne_lab_test/unit/common/test_base_experiment.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/common/test_experiment.py
+Filename: finbourne_lab_test/unit/common/test_measurement_set.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/common/test_observation.py
+Filename: finbourne_lab_test/unit/drive/__init__.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/common/test_recorder.py
+Filename: finbourne_lab_test/unit/drive/test_drive_experiment.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/common/test_sdk_experiment.py
+Filename: finbourne_lab_test/unit/luminesce/__init__.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/common/test_shopper.py
+Filename: finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/luminesce/__init__.py
+Filename: finbourne_lab_test/unit/lusid/__init__.py
 Comment: 
 
-Filename: finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py
+Filename: finbourne_lab_test/unit/lusid/test_lusid_experiment.py
 Comment: 
 
 Filename: finbourne_lab_test/utils/__init__.py
 Comment: 
 
 Filename: finbourne_lab_test/utils/mock.py
 Comment: 
 
 Filename: finbourne_lab_test/utils/test_data_generation.py
 Comment: 
 
-Filename: fbnlab_preview-0.1.74.dist-info/METADATA
+Filename: finbourne_lab_test/utils/test_experiment.py
+Comment: 
+
+Filename: fbnlab_preview-0.1.8.dist-info/METADATA
 Comment: 
 
-Filename: fbnlab_preview-0.1.74.dist-info/WHEEL
+Filename: fbnlab_preview-0.1.8.dist-info/WHEEL
 Comment: 
 
-Filename: fbnlab_preview-0.1.74.dist-info/top_level.txt
+Filename: fbnlab_preview-0.1.8.dist-info/top_level.txt
 Comment: 
 
-Filename: fbnlab_preview-0.1.74.dist-info/RECORD
+Filename: fbnlab_preview-0.1.8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## finbourne_lab/__init__.py

```diff
@@ -1,9 +1,2 @@
 from finbourne_lab.common.convener import Convener
-from finbourne_lab.common.shopper import Shopper
-from finbourne_lab.common.recorder.file import FileRecorder
-from finbourne_lab.common.recorder.drive import DriveRecorder
-from finbourne_lab.common.recorder.sql_db import SqlDbRecorder
-from finbourne_lab.common.experiment import Experiment
-
-from finbourne_lab.analysis.linear import LinearModel
-from finbourne_lab.analysis.distribution import Distribution
+from finbourne_lab.analysis.linear import ScalingModel
```

## finbourne_lab/analysis/linear.py

```diff
@@ -1,18 +1,18 @@
 from __future__ import annotations
 
 from typing import Optional
 from typing import Union, List
 
-import matplotlib.pyplot as plt
 import numpy as np
 import pandas as pd
 import statsmodels.api as sm
 from pandas import DataFrame
 from statsmodels.regression.quantile_regression import QuantReg
+import matplotlib.pyplot as plt
 
 _cms_scheme = {
     'scatter_plot': {'color': 'black', 'alpha': 0.5},
     'median_line': {'color': 'black', 'ls': '--', 'lw': 2},
     'outer_band': {'color': 'lime', 'alpha': 1.0},
     'inner_band': {'color': 'yellow', 'alpha': 1.0},
 }
@@ -23,76 +23,56 @@
         'scatter_plot': {'color': c, 'alpha': 0.667},
         'median_line': {'color': c, 'ls': '--', 'lw': 2},
         'outer_band': {'color': c, 'alpha': 1 / 6},
         'inner_band': {'color': c, 'alpha': 1 / 3},
     }
 
 
-class LinearModel:
+class ScalingModel:
     """This class encapsulates the analysis of how an attribute of an experiment scales with a single input value.
 
     It consists of a set of quantile regressions that put bounds on the scaling behaviour alongside helper methods
     for plotting this relationship, getting its parameters and predicting its values.
 
     """
 
-    quantiles = [0.05, 0.25, 0.5, 0.75, 0.95]
-
-    def __init__(self, data: DataFrame, x: str, y: str, name: str, c_err_warn=0.15, m_err_warn=0.05):
+    def __init__(self, data: DataFrame, x: str, y: str, name: str):
         """The constructor method of the scaling model.
 
         Args:
             data (DataFrame): dataframe from an experimental run.
             x (str): the independent variable column name in the dataframe.
             y (str): the dependent variable column name in the dataframe.
-            name (str): the name of the model,
-            c_err_warn: value of intercept (c) fractional error to warn user and suggest getting more data. Default = 0.15.
-            m_err_warn: value of gradient (m) fractional error to warn user and suggest getting more data. Default = 0.05.
-
+            name (str): the name of the model
         """
 
         if len(data) == 0:
             raise ValueError('The model input dataframe was empty.')
 
         if 'errored' in data.columns:
             data = data[(~data.errored)]
         if 'force_stopped' in data.columns:
             data = data[(~data.force_stopped)]
 
-        data = data[~data[y].isna()]
-        data = data[~data[x].isna()]
-
-        self.data = data.reset_index(drop=True).copy()
+        self.data = data.copy()
 
         if self.data.shape[0] == 0:
-            raise ValueError(f"There was no valid data to use ({name})")
+            raise ValueError(f"There was no non-errored data to use from the experiment {data.iloc[0].ExperimentName}!")
 
         self.x = x
         self.y = y
         self.name = name
 
-        x_vals = self.data[self.x].astype(float)
-        y_vals = self.data[self.y].astype(float)
-        model = QuantReg(y_vals, sm.add_constant(x_vals))
-
-        self.fits = {q: model.fit(q) for q in self.quantiles}
-
-        fr = self.fit_results()
-        count = 0
-        for q, row in fr.iterrows():
-            me = row.m_frac_err.round(3)
-            ce = row.c_frac_err.round(3)
-            if ce > c_err_warn:
-                print(f'⚠️ {name} quantile {q} line has a frac error on c over threshold ({ce} > {c_err_warn})')
-                count += 1
-            if me > m_err_warn:
-                print(f'⚠️ {name} quantile {q} line has a frac error on m over threshold ({me} > {m_err_warn})')
-                count += 1
-        if count > 0:
-            print('Consider gathering more data or removing outliers (.remove_outliers())')
+        model = QuantReg(
+            self.data[self.y],
+            sm.add_constant(self.data[self.x])
+        )
+
+        quantiles = [0.05, 0.25, 0.5, 0.75, 0.95]
+        self.fits = {q: model.fit(q) for q in quantiles}
 
     def predict(self, x: Union[float, List[float], np.array]) -> DataFrame:
         """Predict the 5th, 25th, 50th, 75th and 95th percentiles for given values of the experiment input value.
 
         Args:
             x (Union[float, List[float], np.array]): a single input value, or array of values, to predict for.
 
@@ -139,45 +119,33 @@
                 'c': m.params[0],
                 'm': m.params[1],
                 'c_stderr': m.bse[0],
                 'm_stderr': m.bse[1],
             })
 
         fr_df = DataFrame(rows).set_index('quantile')
-        fr_df['c_frac_err'] = fr_df['c_stderr'] / abs(fr_df['c'])
-        fr_df['m_frac_err'] = fr_df['m_stderr'] / abs(fr_df['m'])
+        fr_df['c_frac_err'] = fr_df['c_stderr'] / fr_df['c']
+        fr_df['m_frac_err'] = fr_df['m_stderr'] / fr_df['m']
         return fr_df
 
     def outliers(self) -> DataFrame:
         """Get lines in the input data that might be outliers according to the fit model.
 
         Data points are flagged as outliers if they are above the upper quartile + 1.5 * the interquartile range (IQR)
         or are below the lower quartile - 1.5 * IQR.
 
         Returns:
             DataFrame: dataframe of rows in the input data that may be outliers.
         """
         odf = self.predict(self.data[self.x].values).reset_index()
         odf['IQR'] = odf[0.75] - odf[0.25]
         odf['y'] = self.data[self.y].values
-        lower_lim = odf[0.25] - 1.5 * odf['IQR']
-        upper_lim = odf[0.75] + 1.5 * odf['IQR']
-        odf = odf[~odf.y.between(lower_lim, upper_lim)]
-        return self.data[self.data.index.isin(odf.index)]
-
-    def remove_outliers(self) -> LinearModel:
-        """Fit a model, remove outliers from the input data and then fit a new model.
-
-        Returns:
-            LinearModel: a new scaling model fit to data with outliers removed
-        """
-        outliers = self.outliers()
-        data = pd.merge(self.data, outliers, indicator=True, how='outer')
-        data = data.query('_merge=="left_only"').drop('_merge', axis=1)
-        return LinearModel(data, self.x, self.y, self.name)
+        odf['execution_id'] = self.data['execution_id'].values
+        odf = odf[(odf['y'] > odf[0.75] + 1.5 * odf['IQR']) | (odf['y'] < odf[0.25] - 1.5 * odf['IQR'])]
+        return self.data[self.data.execution_id.isin(odf.execution_id.tolist())]
 
     def add_plot(self, ax, color_scheme: Optional[str] = 'cms', show_datapoints: Optional[bool] = True):
 
         """Add a plot of this scaling model's quantile bands, its median line and the data points that the model was
         fit with to a matplotlib axes object.
 
         Args:
@@ -208,113 +176,113 @@
         pred = self.predict(x)
 
         ax.plot(x, pred[0.5], label=f'Median ({self.name})', **scheme['median_line'])
         ax.fill_between(x, pred[0.25], pred[0.75], label=f'p25-p75 Range ({self.name})', **scheme['inner_band'])
         ax.fill_between(x, pred[0.75], pred[0.95], label=f'p5-p95 Range ({self.name})', **scheme['outer_band'])
         ax.fill_between(x, pred[0.05], pred[0.25], **scheme['outer_band'])
 
-    def show(self, save_to=None):
+    def remove_outliers(self) -> ScalingModel:
+        """Fit a model, remove outliers from the input data and then fit a new model.
+
+        Returns:
+            ScalingModel: a new scaling model fit to data with outliers removed
+        """
+        outliers = self.outliers()
+        data = self.data[~self.data.execution_id.isin(outliers.execution_id)].copy()
+        return ScalingModel(data, self.x, self.y, self.name)
+
+    def show(self):
         """Generate and show a single plot of this relationship
 
         """
         f, ax = plt.subplots(figsize=(12, 7))
         self.add_plot(ax)
         plt.xlabel(self.x)
         plt.ylabel(self.y)
         plt.legend()
         plt.grid(True, ls=':', zorder=-99)
-        if save_to:
-            plt.savefig(save_to)
         plt.show()
 
-    def __sub__(self, other: LinearModel) -> LinearModel:
+    def __sub__(self, other: ScalingModel) -> ScalingModel:
 
         x = self.data[self.x].values
         y = self.data[self.y].values
         y_pred = other.predict(x)[0.5].values
         delta = y - y_pred
 
         df = self.data
-        label = f'{self.y}_sub_{other.y}'
+        r = np.random.randint(1000)
+        label = f'_delta_{r}'
         df[label] = delta
 
-        return LinearModel(df, self.x, label, f'{self.name} - {other.name}')
+        return ScalingModel(df, self.x, label, f'{self.name} - {other.name}')
 
-    def __add__(self, other: LinearModel) -> LinearModel:
+    def __add__(self, other: ScalingModel) -> ScalingModel:
 
         x = self.data[self.x].values
         y = self.data[self.y].values
         total = y + other.predict(x)[0.5].values
 
         df = self.data
-        label = f'{self.y}_total_{other.y}'
+        r = np.random.randint(1000)
+        label = f'_total_{r}'
         df[label] = total
 
-        return LinearModel(df, self.x, label, f'{self.name} + {other.name}')
+        return ScalingModel(df, self.x, label, f'{self.name} + {other.name}')
 
-    def __truediv__(self, other: LinearModel) -> LinearModel:
+    def __truediv__(self, other: ScalingModel) -> ScalingModel:
 
         x = self.data[self.x].values
         y = self.data[self.y].values
         ratio = y / other.predict(x)[0.5].values
 
         df = self.data
-        label = f'{self.y}_div_{other.y}'
+        r = np.random.randint(1000)
+        label = f'_div_{r}'
         df[label] = ratio
 
-        return LinearModel(df, self.x, label, f'{self.name} / {other.name}')
+        return ScalingModel(df, self.x, label, f'{self.name} / {other.name}')
 
-    def __mul__(self, other: LinearModel) -> LinearModel:
+    def __mul__(self, other: ScalingModel) -> ScalingModel:
 
         x = self.data[self.x].values
         y = self.data[self.y].values
         y_pred = other.predict(x)[0.5].values
         prod = y * y_pred
 
         df = self.data
-        label = f'{self.y}_prod_{other.y}'
+        r = np.random.randint(1000)
+        label = f'_prod_{r}'
         df[label] = prod
 
-        return LinearModel(df, self.x, label, f'{self.name} * {other.name}')
+        return ScalingModel(df, self.x, label, f'{self.name} * {other.name}')
 
     def merge(self, other, name=None):
         """Merge the underlying data of two linear scaling models together and re-fit
 
         Args:
-            other (LinearModel): the other model
+            other (ScalingModel): the other model
             name (str): name to give the result of the merge
 
         Returns:
-            LinearModel: the new scaling model from the merged data
+            ScalingModel: the new scaling model from the merged data
         """
 
         if self.x != other.x or self.y != other.y:
             raise ValueError(
                 f'x and y must match when merging models but were different. '
                 f'x: {self.x} vs {other.x}, y: {self.y} vs {other.y}'
             )
 
         data_l = self.data
         data_r = other.data
         data = pd.concat([data_l, data_r])
-        return LinearModel(data, self.x, self.y, f"{self.x}_{self.y}" if name is None else name)
+        return ScalingModel(data, self.x, self.y, f"{self.x}_{self.y}" if name is None else name)
 
     def to_csv(self, filepath):
         """Export the constituent dataset this model is derived from to a CSV
 
         Args:
             filepath (str): the path to write the csv at.
 
         """
         self.data.to_csv(filepath, index=False)
-
-    def ab_test(self, b_model):
-        """Construct an A/B test between this linear model and another.
-
-        Args:
-            b_model (LinearModel): the b-sample linear model
-
-        Returns:
-            ScalingModelABTest: object encapsulating the A/B test result.
-        """
-        from .ab_test import ScalingModelABTest
-        return ScalingModelABTest(self, b_model)
```

### encoding

```diff
@@ -1 +1 @@
-utf-8
+us-ascii
```

## finbourne_lab/analysis/plotting.py

```diff
@@ -1,21 +1,21 @@
 import matplotlib
 import matplotlib.pyplot as plt
 import numpy as np
 import pandas as pd
 
-from .linear import LinearModel
+from .linear import ScalingModel
 
 
-def superimposed_difference(baseline: LinearModel, *models: LinearModel, **kwargs):
+def superimposed_difference(baseline: ScalingModel, *models: ScalingModel, **kwargs):
     """Produce a plot that shows the difference between a series of linear scaling models and a baseline model.
 
     Args:
-        baseline (LinearModel): the baseline model to subtract from the others.
-        *models (LinearModel): the other models.
+        baseline (ScalingModel): the baseline model to subtract from the others.
+        *models (ScalingModel): the other models.
 
     Keyword Args:
         figsize: the figure size tuple to pass to matplotlib (default = (14, 10))
         xlim: the x axis range to use in the plot (defaults to matplotlib default)
         xlabel: the x axis label to use in the plot (defaults to whatever the x column is in the baseline model)
         ylabel: the y axis label to use in the plot (defaults to whatever the y column is in the baseline model)
         title: title to put at the top of the plot (defaults to none)
```

## finbourne_lab/common/convener.py

```diff
@@ -1,108 +1,259 @@
 import datetime as dt
-from multiprocessing import Queue
-from multiprocessing.context import ForkProcess
-from typing import Optional, Union
-from uuid import uuid4
+import os
+import time
+import uuid
+from pathlib import Path
+from tqdm import tqdm
 
 import numpy as np
-from tqdm import tqdm
+import pandas as pd
 
-from finbourne_lab.common.experiment import Experiment
-from finbourne_lab.common.recorder.base import BaseRecorder
-from finbourne_lab.common.shopper import Shopper
-from finbourne_lab.common.recorder.no_op import NoOpRecorder
+from finbourne_lab.base.experiment import BaseExperiment
+from multiprocessing import Queue
 
 
 class Convener:
-    """The Convener class is responsible for running an experiment/shopper with a given degree of paralellism, and
-    the recorder for storing their observations.
+    """The convener class looks after the running of experiments and recording their data.
 
     """
 
     def __init__(
             self,
-            to_run: Union[Experiment, Shopper],
-            recorder: Union[BaseRecorder, None],
-            n_parallel: Optional[int] = 1,
+            experiment: BaseExperiment,
+            work_dir: str,
+            name: str,
+            n_obs: int,
+            seed=None,
+            err_wait=1,
+            n_parallel=1,
+            soak_time=None,
     ):
-        """Constructor for the Convener class.
+        """Constructor of the convener class.
 
         Args:
-            to_run (Union[Experiment, Shopper]): the experiment/shopper instance to run in the convener.
-            recorder (BaseRecorder): recorder to record experimental observations with.
-            n_parallel (int): number of parallel copies to run of 'to_run'. Defaults to one.
+            experiment (BaseExperiment): the experiment to run.
+            work_dir (str): the working directory to write results to.
+            name (str): the name of the experiment.
+            n_obs (int): number of times to run the experiment and observe values.
+            seed (Optional[int]): random seed to set at the start of the experimental run. Will be chosen randomly if
+            not specified.
+            err_wait (Optional[int]): number of seconds to wait after getting an error.
+            n_parallel (Optional[Union[int, List[int]]]): number of concurrent runs of the experiment to run each time.
+            soak_time (Optional[int]): time in seconds to run repeated experiment iterations for.
+
         """
 
-        self.to_run = to_run
-        if recorder is None:
-            print(f'⚠️ No client-side data is being recorded (recorder = None)')
-            recorder = NoOpRecorder()
-        self.recorder = recorder
-        self.n_parallel = n_parallel
+        self.__validate_concurrency(n_parallel, soak_time)
+
+        self.__work_dir = work_dir
+        self.__name = name
+        self.__experiment = experiment
+        self.__n_obs = n_obs
+        self.__seed = seed if seed is not None else np.random.randint(1989)
+        self.__err_wait = err_wait
+        self.__n_parallel = n_parallel
+        self.__soak_time = soak_time
+        self.__force_stop = False
+
+        data_dir = f'{self.__work_dir}/data'
+        self.__data_file = f'{data_dir}/{self.__name}.csv'
+
+        Path(data_dir).mkdir(parents=True, exist_ok=True)
+        Path(f'{self.__work_dir}/plots').mkdir(parents=True, exist_ok=True)
 
     @staticmethod
-    def _pbar(time_limit):
+    def __validate_concurrency(n_parallel, soak_time):
 
-        # Very important. Do not remove.
-        emoji = np.random.choice(['🧪', '🔭', '⚗️', '🧬', '🔬', '📐'])
+        if isinstance(n_parallel, int):
+            _n_parallel = n_parallel
+        elif isinstance(n_parallel, (list, tuple)) and len(n_parallel) == 2:
+            _n_parallel = n_parallel[1]
+        else:
+            raise TypeError(
+                'Input value to n_parallel must be either a single integer or a pair of integers as list/tuple. '
+                f'Was {n_parallel} ({type(n_parallel).__name__}).'
+            )
+
+        if soak_time is None and _n_parallel > 1:
+            raise ValueError(
+                "When running concurrent experiments a value must be given for soak_time when building the convener."
+            )
+
+    def __job(self) -> pd.DataFrame:
 
-        if time_limit is None:
-            return tqdm(desc=f'{emoji}Doing Science Forever! ', bar_format='{desc}|{bar:30}|(∞️)')
+        np.random.seed(self.__seed + self.__n_obs * 2)
+        if isinstance(self.__n_parallel, int):
+            n_parallel = self.__n_parallel
+        elif isinstance(self.__n_parallel, (list, tuple)):
+            n_parallel = np.random.randint(self.__n_parallel[0], self.__n_parallel[1] + 1)
         else:
-            return tqdm(
-                desc=f'{emoji}Doing Science! ',
-                total=time_limit,
-                bar_format='{desc}|{bar:30}|{percentage:3.0f}% ' + f'(Running for {time_limit}s)',
-                colour='GREEN'
+            raise ValueError(f"Bad parallelism input: {self.__n_parallel}.")
+
+        def set_seed():
+            if self.__n_parallel == 1:
+                return self.__seed
+            else:
+                return np.random.randint(0, 100000)
+
+        seeds = [set_seed() for _ in range(n_parallel)]
+        tasks = [self.__experiment.copy(s) for s in seeds]
+        queues = [Queue() for _ in range(n_parallel)]
+
+        try:
+            for q, t in zip(queues, tasks):
+                # noinspection PyProtectedMember
+                t._attach_queue(q)._set_soak_time(self.__soak_time).start()
+
+            [t.join(force=False) for t in tasks]
+
+        except KeyboardInterrupt:
+            tqdm.write("\n🛑 Quitting the experimental run...\n")
+            [t.join(force=True) for t in tasks]
+            self.__force_stop = True
+
+        rows = []
+        for q in queues:
+            while not q.empty():
+                row = q.get()
+                row['n_parallel'] = n_parallel
+                rows.append(row)
+
+        if len(rows) == 0 and not self.__force_stop:
+            raise ValueError(
+                "Experiment processes produced no outputs. "
+                "There may have been errors in the subprocesses that caused a crash."
             )
 
-    def go(self, time_limit: Union[int, None]):
-        """Run the experiment or shopper for a period of time.
+        return pd.DataFrame(rows)
 
-        Args:
-            time_limit (Union[int, None]): time to run for. If set to None it will run indefinitely.
+    def go(self) -> None:
+        """Run the experiments.
+
+        Notes:
+            Can be halted with keyboard interrupt.
 
         """
 
-        queue = Queue(maxsize=-1)
-        run_id = str(uuid4())
-        seed = int(np.random.randint(10000))
+        run_id = str(uuid.uuid4())
 
-        def make_process(i):
-            return ForkProcess(target=self.to_run.run, args=(queue, seed + i, run_id))
+        # In case we want to restart a convener that was halted
+        self.__force_stop = False
 
-        ex_processes = [make_process(i) for i in range(self.n_parallel)]
+        error_count = 0
+        run_start = dt.datetime.utcnow()
+        offset = dt.datetime.now() - dt.datetime.utcnow()
 
-        try:
+        # Very important. Do not remove.
+        emoji = np.random.choice(['🧪', '🔭', '⚗️', '🧬', '🔬', '📐'])
+
+        times = []
+        start = None
+        total_obs = 0
+
+        tqdm.write(f"Experiment: {self.__name}")
+        tqdm.write(str(self.__experiment))
+        tqdm.write(f"Output file: {self.__data_file}")
+        tqdm.write(f"Run start: {(run_start + offset).strftime('%Y-%m-%d %H:%M:%S')}")
+
+        if self.__n_parallel != 1:
+            tqdm.write(f"Concurrency: {self.__n_parallel}  Soak Time: {self.__soak_time}")
+
+        pbar = tqdm(
+            range(1, self.__n_obs + 1),
+            desc=f'{emoji}Doing Science! ',
+            unit='Obs',
+            total=self.__n_obs,
+            bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}'
+        )
+        with pbar as t:
+
+            for _ in t:
+
+                new_start = dt.datetime.utcnow()
+                if start is not None:
+                    times.append((new_start - start).total_seconds())
+                start = new_start
+
+                if len(times) >= 1:
+                    t_mean = np.mean(times)
+                    est_len = self.__n_obs * t_mean / 60
+                    est_finish = run_start + dt.timedelta(minutes=est_len) + offset
+                    postfix = {
+                        'finish_at': f"{est_finish.strftime('%H:%M:%S')}",
+                        'error_count': error_count,
+                    }
+                    if error_count > 0:
+                        postfix['error_rate'] = f"{round(100 * error_count / total_obs, 2)}%"
+                    t.set_postfix(**postfix)
+
+                df = self.__job()
+
+                df['experiment_name'] = self.__name
+                df['run_start'] = run_start
+                experiment_id = str(uuid.uuid4())
+                df['experiment_id'] = experiment_id
+
+                if df.shape[0] > 0:
+                    total_obs += df.iloc[0].n_parallel
+
+                df['run_id'] = run_id
+                df.to_csv(
+                    self.__data_file,
+                    index=False,
+                    mode='a',
+                    header=not os.path.exists(self.__data_file)
+                )
+
+                if self.__force_stop:
+                    raise KeyboardInterrupt()
+
+                errors = df[df.errored].error_message.tolist()
+                if len(errors) > 0:
+                    error_count += len(errors)
+                    err_msg = '\n'.join(errors)
+                    s = 's' if len(errors) > 1 else ''
+                    tqdm.write(f"Error{s} in run {experiment_id}:\n{err_msg}")
+                    time.sleep(self.__err_wait)
+
+                self.__seed += 1
+
+    @property
+    def data_file_path(self) -> str:
+        """Get the file path for the data CSV.
 
-            with self._pbar(time_limit) as t:
-                start = dt.datetime.utcnow()
-                period = lambda: int((dt.datetime.utcnow() - start).total_seconds())
-                criterion = lambda: time_limit is None or period() < time_limit
+        Returns:
+            str: the data csv file path
+        """
+        return self.__data_file
 
-                for p in ex_processes:
-                    t.update(period() - t.n)
-                    p.start()
+    def read_csv(self) -> pd.DataFrame:
+        """Read the data CSV and return it as a pandas dataframe.
 
-                while True:
-                    t.update(period() - t.n)
+        Returns:
+            DataFrame: the contents of the data CSV file.
+        """
+        return pd.read_csv(self.__data_file)
 
-                    while not queue.empty() and criterion():
-                        self.recorder.put(queue.get())
-                        t.update(period() - t.n)
+    def get_name(self) -> str:
+        """Return the name of the experiment
 
-                    if not criterion():
-                        break
+        Returns:
+            str: the name of the experiment
+        """
+        return self.__name
 
-                t.update(period() - t.n)
+    def get_experiment(self) -> BaseExperiment:
+        """Return the experiment object that this convener manages
 
-                for p in ex_processes:
-                    p.terminate()
+        Returns:
+            BaseExperiment: the experiment object
+        """
+        return self.__experiment
 
-        except KeyboardInterrupt:
-            print('🛑 Halting run...')
-            for p in ex_processes:
-                p.terminate()
+    def get_work_dir(self):
+        """Return the path to the working directory that this convener writes to
 
-        self.recorder.put_all(queue)
-        self.recorder.flush()
+        Returns:
+            str: the working directory path
+        """
+        return self.__work_dir
```

## finbourne_lab/luminesce/__init__.py

```diff
@@ -1,8 +1,3 @@
-from finbourne_lab.luminesce.core import CoreLumiLab
-from finbourne_lab.luminesce.drive import DriveLumiLab
-from finbourne_lab.luminesce.lusid.lusid_read import LusidLumiLabRead
-from finbourne_lab.luminesce.lusid.lusid_write import LusidLumiLabWrite
-
-from finbourne_lab.luminesce.experiment import LumiExperiment
-from finbourne_lab.luminesce.shopper_setup import make_shopper
-from finbourne_lab.luminesce.utils import make_recorder_providers
+from finbourne_lab.luminesce.experiment import LuminesceExperiment
+from finbourne_lab.luminesce.measurements import LuminesceMeasurementFactory
+from finbourne_lab.luminesce.utils import Postprocessing
```

## finbourne_lab/luminesce/experiment.py

```diff
@@ -1,105 +1,112 @@
-import numpy as np
+import datetime as dt
+from typing import Union, List, Any, Set
+
 import pandas as pd
-from typing import Callable, Any, Union
-from finbourne_lab.common.experiment import Experiment
-from lumipy.lumiflex._common.str_utils import to_snake_case
-from lumipy.lumiflex._table.operation import TableOperation
+from finbourne_lab.base.experiment import BaseExperiment
+from finbourne_lab.base.result import BaseResult
 
 
-# noinspection SqlNoDataSourceInspection,SqlResolve
-class LumiExperiment(Experiment):
-    """Experiment class for running luminesce experiments.
+class LuminesceResult(BaseResult):
+    """Class that represents the result for a single luminesce query experiment.
 
     """
 
-    def __init__(self, name: str, build_fn: Callable, *ranges: Any, **metadata: Any):
-        """Constructor of the LumiExperiment class.
+    def __init__(self):
+        """Constructor for the luminesce experiment result class.
+
+        """
+        self.send = pd.NaT
+        self.submitted = pd.NaT
+        self.get = pd.NaT
+        self.download_finish = pd.NaT
+        self.obs_rows = None
+        self.obs_cols = None
+        self.start_query_time = None
+        self.query_time = None
+        self.download_time = None
+        super().__init__()
+
+
+class LuminesceExperiment(BaseExperiment):
+    """Class that encapsulates a luminesce experiment.
+
+    """
+
+    def __init__(
+            self,
+            build_fn,
+            *ranges: Union[List[Union[int, float]], Any, Set[Any]],
+            **kwargs: Any
+    ):
+        """Constructor for the experiment class.
 
         Args:
-            name (str): name of the luminesce experiment
-            build_fn (Callable): build function of the luminesce experiment. Must return a query object given some values.
-            *ranges (Any): parameter value ranges. Must be either constant values, a pair of integers or a set of values.
-            **metadata (Any): other values to be attached to observations or the lumipy client to be used.
+            build_fn (Callable): a function that returns a lumipy query object when given a set of values.
+            *ranges (Union[List[Union[int, float]], Union[int, float]]): single constant values or ranges to randomly
+            sample for the experiment.
 
         Keyword Args:
-            client (Client): the lumipy client to use when running SQL string experiments
-            keep_for (int): time to keep query results for. Defaults to 900s.
-            check_period (float): wait period before checking a query status. Defaults to 0.025s
-            skip_download (bool): whether to skip the download step. Defaults to true.
-
-        Notes:
-            When running a sql str-based experiment you must supply the client as a keyword arg. For example,
+            seed (int): random seed to set in numpy when selecting experiment arg values.
+            skip_download (Optional[bool]): whether to skip downloading the query (defaults to True).
 
-            ```
-            client = lm.get_client()
+        """
+        self.skip_download = kwargs.get('skip_download', True)
+        self.check_period = kwargs.get('check_period', 0.1)
+        self.keep_for = kwargs.get('keep_for', 900)
+        super().__init__(build_fn, *ranges, **kwargs)
+
+    def __str__(self):
+        return f"{super().__str__()}  " \
+               f"Skip Download: {self.skip_download}  " \
+               f"Check Period: {self.check_period}  " \
+               f"Keep for {self.keep_for}"
 
-            def build(x):
-                return f'select * from lusid.instrument limit {x}'
+    def copy(self, seed: int):
+        """Make an independent copy of this experiment object.
 
-            ex = LumiExperiment('lusid_instrument', build, [1, 10000], client=client)
-            ```
+        Args:
+            seed (int): random seed to set in numpy when selecting experiment arg values.
 
+        Returns:
+            LuminesceExperiment: an independent copy of this experiment.
         """
+        return LuminesceExperiment(self.build_fn, *self._ranges, seed=seed, skip_download=self.skip_download, keep_for=self.keep_for)
+
+    def _init_result(self) -> LuminesceResult:
+        return LuminesceResult()
 
-        self.client = metadata.get('client')
-        if self.client is not None:
-            del metadata['client']
-            self.client.run('select LusidInstrumentId from lusid.instrument limit 1', return_job=True)
-
-        self.keep_for = metadata.get('keep_for', 900)
-        self.check_period = metadata.get('check_period', 0.025)
-        self.skip_download = metadata.get('skip_download', True)
-
-        super().__init__(name, build_fn, *ranges, **metadata)
-
-    def measurement(self, obs, qry: Union[TableOperation, str]):
-
-        obs.log_time('send')
-        if hasattr(qry, 'go_async'):
-            job = qry.go_async(keep_for=self.keep_for)
-        elif isinstance(qry, str):
-            if self.client is None:
-                raise ValueError(f'You must give a client object when running a SQL string.')
-            job = self.client.run(qry, return_job=True)
-        else:
-            raise TypeError('Build function returned an unsupported type. Must be either a lumipy query object or str.')
-
-        obs['execution_id'] = job.ex_id
-        obs.log_time('submitted')
-        obs['start_query_time'] = (obs['submitted'] - obs['send']).total_seconds()
-
-        job.interactive_monitor(True, self.check_period)
-
-        obs.log_time('get')
-        obs['query_time'] = (obs['get'] - obs['submitted']).total_seconds()
-
-        def make_pair(x):
-            lhs, rhs = x.split(':')
-            name = ''.join(s for s in lhs.strip() if s.isalnum()).title() + 'Time'
-            val = float(rhs.strip().strip(' ms')) * 0.001
-            return to_snake_case(name), val
-
-        server_side = {}
-        arr = [line for line in job.get_progress().split('\n') if ' ms' in line]
-        for time_name, time_val in map(make_pair, arr):
-            server_side[time_name] = time_val
-
-        ss_cols = ['prep_time', 'providers_time', 'mergesql_time', 'filltable_time', 'total_time']
-        for col in ss_cols:
-            if col not in server_side:
-                obs[col] = np.NaN
-            else:
-                obs[col] = server_side[col]
-
-        if self.skip_download:
-            obs['download_finish'] = pd.NaT
-            obs['obs_rows'] = None
-            obs['obs_cols'] = None
-            obs['download_time'] = None
+    def _job(self, runnable) -> None:
+
+        qry = runnable
+
+        if self.should_stop():
+            return
+
+        self._return.send = dt.datetime.utcnow()
+        job = qry.go_async(keep_for=self.keep_for)
+        self._return.execution_id = job.ex_id
+        self._return.submitted = dt.datetime.utcnow()
+        self._return.start_query_time = (self._return.submitted - self._return.send).total_seconds()
+
+        if self.should_stop():
+            return
+
+        job.interactive_monitor(True, self.check_period, self.should_stop)
+        if job._status == 'Faulted':
+            message_lines = [l for l in job._progress_lines if l.strip() != '']
+            message = '\n'.join(message_lines[-10:])
+            raise ValueError(f'Query {job.ex_id} has ended in an error state:\n\n{message}')
+
+        self._return.get = dt.datetime.utcnow()
+        self._return.query_time = (self._return.get - self._return.submitted).total_seconds()
+
+        if self.should_stop() or self.skip_download:
             return
 
         df = job.get_result(False)
-        obs.log_time('download_finish')
-        obs['obs_rows'] = df.shape[0]
-        obs['obs_cols'] = df.shape[1]
-        obs['download_time'] = (obs['download_finish'] - obs['get']).total_seconds()
+        self._return.download_finish = dt.datetime.utcnow()
+
+        self._return.obs_rows = df.shape[0]
+        self._return.obs_cols = df.shape[1]
+
+        self._return.download_time = (self._return.download_finish - self._return.get).total_seconds()
```

## finbourne_lab/luminesce/utils.py

```diff
@@ -1,33 +1,40 @@
-from finbourne_lab.common.recorder.sql_db import create_db_providers
-from lumipy.provider import DType
-from lumipy.client import Client
-from typing import Literal
-
-
-def make_recorder_providers(client: Client, action: Literal['create', 'recreate'] = 'create'):
-
-    cols = [
-        ('download_finish', DType.DateTime),
-        ('download_time', DType.Decimal),
-        ('end', DType.DateTime),
-        ('error_message', DType.Text),
-        ('errored', DType.Boolean),
-        ('execution_id', DType.Text),
-        ('get', DType.DateTime),
-        ('name', DType.Text),
-        ('obs_cols', DType.Decimal),
-        ('obs_rows', DType.Decimal),
-        ('query_time', DType.Decimal),
-        ('run_id', DType.Text),
-        ('send', DType.DateTime),
-        ('start', DType.DateTime),
-        ('start_query_time', DType.Decimal),
-        ('submitted', DType.DateTime),
-        ('prep_time', DType.Double),
-        ('providers_time', DType.Double),
-        ('mergesql_time', DType.Double),
-        ('filltable_time', DType.Double),
-        ('total_time', DType.Double),
-    ]
+import pandas as pd
 
-    return create_db_providers(client, 'luminesce', cols, action)
+
+class Postprocessing:
+    """This class enriches an existing luminesce measurement dataset by adding the server-side data.
+
+    """
+
+    def __init__(self, atlas):
+        """Constructor of the dataset enricher.
+
+        Args:
+            atlas (Atlas): lumipy atlas to use to get the server side data.
+
+        """
+        self.atlas = atlas
+
+    def __call__(self, c):
+
+        ex_df = c.read_csv()
+        ex_df['start'] = pd.to_datetime(ex_df.start)
+        ex_df['end'] = pd.to_datetime(ex_df.end)
+
+        start = ex_df.start.min().to_pydatetime()
+        end = ex_df.end.max().to_pydatetime()
+        hcq = self.atlas.sys_logs_hcquery(start_at=start, end_at=end)
+
+        cols = [hcq.execution_id, hcq.data_volume,
+                hcq.total_time_ms, hcq.fill_table_time_ms,
+                hcq.merge_sql_time_ms, hcq.provider_time_ms,
+                hcq.prep_time_ms]
+        tv = hcq.select(*cols).to_table_var()
+        qry = tv.select('*').where(tv.execution_id.is_in(ex_df.execution_id.tolist()))
+        _df = qry.go()
+        _df.iloc[:, 2:] = _df.iloc[:, 2:] / 1000
+
+        m_df = pd.merge(ex_df, _df, left_on='execution_id', right_on='ExecutionId')
+        m_df = m_df[[c for c in m_df.columns if c != 'ExecutionId']]
+        m_df.to_csv(c.data_file_path.replace('.csv', '_enriched.csv'), index=False)
+        return m_df
```

## finbourne_lab/lusid/__init__.py

```diff
@@ -1,3 +1 @@
-from finbourne_lab.lusid.client import LusidClient
 from finbourne_lab.lusid.experiment import LusidExperiment
-from finbourne_lab.lusid.instrument import LusidInstrumentLab
```

## finbourne_lab/lusid/client.py

```diff
@@ -1,10 +1,11 @@
 import uuid
 
 import lusid
+from lusid import ApiException, models
 
 
 class LusidClient:
 
     def __init__(self, **kwargs):
 
         api_factory = lusid.utilities.ApiClientFactory(**kwargs)
@@ -28,15 +29,14 @@
         self.property_defs_api = api_factory.build(lusid.api.PropertyDefinitionsApi)
         self.quotes_api = api_factory.build(lusid.api.QuotesApi)
         self.reconciliations_api = api_factory.build(lusid.api.ReconciliationsApi)
         self.reference_portfolios_api = api_factory.build(lusid.api.ReferencePortfolioApi)
         self.scopes_api = api_factory.build(lusid.api.ScopesApi)
         self.search_api = api_factory.build(lusid.api.SearchApi)
         self.sequences_api = api_factory.build(lusid.api.SequencesApi)
-        self.strucured_results_api = api_factory.build(lusid.api.StructuredResultDataApi)
         self.system_config_api = api_factory.build(lusid.api.SystemConfigurationApi)
         self.transaction_portfolios_api = api_factory.build(lusid.api.TransactionPortfoliosApi)
 
     def ensure_portfolio(self, scope, code_prefix, effective_date):
         """
 
         Args:
@@ -49,17 +49,14 @@
         """
 
         def make_portfolio_code(prefix):
             return f"portfolio-{prefix}-{uuid.uuid4()}"
 
         code = make_portfolio_code(code_prefix)
 
-        import lusid.models as models
-        from lusid.exceptions import ApiException
-
         try:
             self.portfolios_api.get_portfolio(scope, code)
 
         except ApiException as e:
 
             transactions_portfolio_request = models.CreateTransactionPortfolioRequest(
                 display_name="test portfolio",
@@ -82,15 +79,14 @@
             scope:
             domain:
 
         Returns:
 
         """
 
-        import lusid.models as models
         for i in range(n_props):
             try:
                 self.property_defs_api.get_property_definition(
                     domain=domain,
                     scope=scope,
                     code=f"test_prop{i}"
                 )
@@ -119,15 +115,14 @@
         Returns:
 
         """
 
         if properties is None:
             properties = []
 
-        import lusid.models as models
         instruments = {
             f'inst_{i}': models.InstrumentDefinition(
                 name=f'Instrument{i}',
                 identifiers={"ClientInternal": models.InstrumentIdValue(f'{id_prefix}_{i}')},
                 properties=properties
             )
             for i in range(n_insts)
```

## finbourne_lab/lusid/experiment.py

```diff
@@ -1,8 +1,23 @@
-from finbourne_lab.common.sdk_experiment import SdkExperiment
+from finbourne_lab.common.api import ApiExperiment
 
 
-class LusidExperiment(SdkExperiment):
+class LusidExperiment(ApiExperiment):
+    """Experiment class for measuring using LUSID via the LUSID Web API
 
-    def __init__(self, name, build_fn, *ranges, **kwargs):
-        kwargs['application'] = 'lusid'
-        super().__init__(name, build_fn, *ranges, **kwargs)
+    """
+
+    def __init__(self, build_fn, *ranges, **kwargs):
+        """Constructor for the Lusid API experiment class
+
+        Args:
+            build_fn (Callable): a function that builds a callable given a set of values. This callable makes a request
+            to the API in question and returns the HTTPResponse object.
+            application (str): the name of the application the experiment is running against.
+            *ranges: range pairs, single values or sets to sample when running experiments.
+
+        Keyword Args:
+            throw_on_failure (bool): whether to throw an error when the metadata header doesn't show a success.
+            Sometimes a lusid call can fail but have a success status code.
+
+        """
+        super().__init__(build_fn, 'lusid', *ranges, **kwargs)
```

## finbourne_lab_test/unit/luminesce/test_luminesce_experiment.py

```diff
@@ -1,16 +1,15 @@
 import os
 import unittest
 from pathlib import Path
 from shutil import rmtree
 
-from finbourne_lab import Convener, FileRecorder, Shopper
-from finbourne_lab.luminesce import LumiExperiment
+from finbourne_lab import Convener
+from finbourne_lab.luminesce import LuminesceExperiment
 from finbourne_lab_test.utils.mock import MockQuery
-import pandas as pd
 
 
 class TestLuminesceExperiment(unittest.TestCase):
 
     work_dir = '/tmp/finbourne_lab_test/unit/luminesce/'
 
     @classmethod
@@ -34,42 +33,98 @@
         job = qry.go_async()
         job.interactive_monitor()
 
         df = job.get_result()
         self.assertSequenceEqual(df.shape, [5, 3])
         self.assertEqual(qry.call_count, 1)
 
-    def test_luminesce_experiment_run(self):
+    def test_sequential_experiment(self):
+
+        n_experiments = 5
+
+        build_fn = MockQuery.build
+        experiment = LuminesceExperiment(build_fn, [1, 10])
+        convener = Convener(experiment, self.work_dir, 'sequential', n_experiments, seed=1989)
+        convener.go()
+
+        df = convener.read_csv()
+
+        self.assertEqual(df.shape[0], n_experiments)
+
+        self.assertEqual(convener._Convener__seed, 1989 + n_experiments)
+        self.assertEqual(experiment._ranges, ([1, 10],))
+
+    def test_sequential_single_point_experiment(self):
+
+        n_experiments = 5
+
+        build_fn = MockQuery.build
+        experiment = LuminesceExperiment(build_fn, 10)
+        convener = Convener(experiment, self.work_dir, 'sequential_sp', n_experiments)
+        convener.go()
+
+        df = convener.read_csv()
+
+        self.assertEqual(df.shape[0], n_experiments)
+        self.assertTrue((df.arg0 == 10).all())
+
+    def test_concurrent_experiment(self):
+
+        n_experiments = 5
+        n_parallel = 5
 
         build_fn = MockQuery.build
-        experiment = LumiExperiment('test-1', build_fn, [1, 10], skip_download=False)
-        recorder = FileRecorder(self.work_dir)
-        convener = Convener(experiment, recorder)
-
-        convener.go(6)
-        df = pd.read_csv(self.work_dir + 'test-1.csv').head(3)
-
-        self.assertSequenceEqual([3, 23], df.shape)
-        self.assertTrue(all(v == 'test-1' for v in df.name))
-        self.assertTrue(all(not v for v in df.errored))
-        self.assertTrue(all(not v for v in df.skip_download))
+        experiment = LuminesceExperiment(build_fn, [1, 10])
+        convener = Convener(experiment, self.work_dir, 'concurrent', n_experiments, seed=1989, n_parallel=n_parallel, soak_time=1)
+        convener.go()
+
+        df = convener.read_csv()
+
+        self.assertEqual(df.shape[0], n_experiments * n_parallel)
+
+        for ex_id, ex_df in df.groupby(df.experiment_id):
+            self.assertEqual(ex_df.shape[0], n_parallel)
+            param_vals = ex_df.arg0.tolist()
+            self.assertTrue(all(0 < p <= 10 for p in param_vals))
+            self.assertTrue(all(e == ex_id for e in ex_df.experiment_id))
+            self.assertTrue(all(n == n_parallel for n in ex_df.n_parallel))
+
+        self.assertEqual(convener._Convener__n_parallel, 5)
+        self.assertEqual(convener._Convener__name, 'concurrent')
+        self.assertEqual(convener._Convener__seed, 1989 + n_experiments)
+
+        self.assertEqual(experiment._ranges, ([1, 10],))
+
+        self.assertEqual(convener._Convener__work_dir, self.work_dir)
+        self.assertFalse(df.errored.any())
 
-    def test_luminesce_experiments_in_shopper(self):
+    def test_random_concurrency(self):
+
+        n_experiments = 5
+        n_parallel = [1, 10]
 
         build_fn = MockQuery.build
+        experiment = LuminesceExperiment(build_fn, [1, 10])
+        convener = Convener(experiment, self.work_dir, 'concurrent_rand', n_experiments, n_parallel=n_parallel, soak_time=1)
+        convener.go()
+
+        df = convener.read_csv()
+        gdf = df.groupby('experiment_id').agg(Count=('experiment_id', 'count'))
+
+        self.assertGreater(gdf.Count.unique().shape[0], 1)
+        self.assertTrue(all(1 <= c <= 10 for c in gdf.Count))
 
-        ex1 = LumiExperiment('shop-1', build_fn, [0, 10])
-        ex2 = LumiExperiment('shop-2', build_fn, [0, 10])
-        ex3 = LumiExperiment('shop-3', build_fn, [0, 10])
-        shopper = Shopper(ex1, ex2, ex3)
-
-        recorder = FileRecorder(self.work_dir)
-        convener = Convener(shopper, recorder)
-
-        convener.go(15)
-        df1 = pd.read_csv(self.work_dir + 'shop-1.csv').head(3)
-        df2 = pd.read_csv(self.work_dir + 'shop-2.csv').head(3)
-        df3 = pd.read_csv(self.work_dir + 'shop-3.csv').head(3)
-
-        self.assertGreater(df1.shape[0], 0)
-        self.assertGreater(df2.shape[0], 0)
-        self.assertGreater(df3.shape[0], 0)
+    def test_error_catch(self):
+
+        n_experiments = 5
+
+        build_fn = MockQuery.build
+        experiment = LuminesceExperiment(build_fn, -1)
+        convener = Convener(experiment, self.work_dir, 'error', n_experiments, err_wait=0)
+        convener.go()
+
+        df = convener.read_csv()
+
+        self.assertEqual(df.shape[0], n_experiments)
+        self.assertEqual(df[df.errored].shape[0], n_experiments)
+        for error_message in df.error_message:
+            self.assertIn("This is a test error", error_message)
```

## finbourne_lab_test/utils/mock.py

```diff
@@ -132,34 +132,7 @@
             quiet:
 
         Returns:
 
         """
         return self.mock_query.result()
 
-    def get_progress(self):
-        return '''
-        FROM
-   [Sys.Finbourne.Lab.Luminesce]
-GROUP BY
-   [name], [errored], date([start])
-ORDER BY
-   [name] ASC, [start] ASC
-Rows         : 162
-Data Volume  : 12439 B
-Prep         : 207.5345 ms
-Providers    : 1150.7677 ms
-Merge/Sql    : 0.1951 ms
-FillTable    : 548.8983 ms
-(total)      : 1907.3956 ms
-Session Id   : ae8d941a-7f9a-47e1-aed0-4ad439a8d030
-Execution Id : 9f1653e4-26fe-4d94-8882-bb927666ddbc
-Ext. Ex. Id  : 0HMRJ2GO4B0EF:00000071
-Client       : fbn-ci
-Client Id    : 0oa7draltjzKvjCz92p7
-User Id      : 00u4edufouxFGBrcN2p7
-Api Version  : 1.13.10.0
-Dependency & Execution details:
-.                           |208ms|                        1.315s||          1.907s|
-Sys.Finbourne.Lab.Luminesce |     |>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>||                | -> 29024 row(s)
-Query Coordinator           |*****|-------------------------------|>>>>>>>>>>>>>>>>| -> 162 row(s)
-        '''
```

## Comparing `finbourne_lab/common/base_lab.py` & `finbourne_lab/base/measurement_factory.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,35 +1,48 @@
 from __future__ import annotations
 
-from finbourne_lab import Shopper
 from typing import Dict, Callable, List, Iterable
 
-from finbourne_lab.common.experiment import Experiment
 
-
-class BaseLab:
+class BaseMeasurementFactory:
     """Base class for standard measurement sets. Standard measurement sets are the set of standard measurements that
     characterise the performance of a given Finbourne application.
 
     Standard measurement sets should have a set of methods ending with _measurement for each individual standard
     measurement which output a Convener instance or a tuple of Convener instances.
 
     Each measurement method must be documented with a docstring.
     """
 
+    def __init__(self, work_dir):
+        """Base constructor of the measurement set
+
+        Args:
+            work_dir: the working directory to use in the conveners of the standard measurement set.
+
+        """
+
+        self.work_dir = work_dir
+        self._validate()
+
+    @staticmethod
+    def make_range_label(rng, prefix):
+        rng = rng if hasattr(rng, '__len__') else [rng]
+        return prefix + '-'.join(str(v) for v in rng)
+
     def get_measurements(self) -> Dict[str, Callable]:
         """Get a dictionary of all the measurement methods of this class.
 
         Returns:
             Dict[str, Callable]: the dictionary of measurement names and methods.
 
         """
         return {m: getattr(self, m) for m in dir(self) if m.endswith('_measurement')}
 
-    def list_experiments(self, **kwargs) -> List[Experiment]:
+    def list_conveners(self, **kwargs) -> List['Convener']:
         """List all the conveners to run in this standard measurement set.
 
         Returns:
             List[Convener]: the list of conveners.
 
         """
 
@@ -38,36 +51,27 @@
                 if isinstance(x, Iterable) and not isinstance(x, (str, bytes)):
                     yield from _flatten(x)
                 else:
                     yield x
 
         return list(_flatten(map(lambda x: x(**kwargs), self.get_measurements().values())))
 
-    def shopper(self, **kwargs) -> Shopper:
-        """Create a shopper object for each experiment in this lab object.
-
-        Args:
-            **kwargs: kwargs to pass down to list_experiments which will be passed to each *_measurement method.
-
-        Returns:
-            Shopper: the encapsulating shopper instance.
-        """
-        return Shopper(*self.list_experiments(**kwargs))
+    def _validate(self):
+        d = self.get_measurements()
+        not_documented = []
+        for k, v in d.items():
+            doc = v.__doc__
+            if doc is None:
+                not_documented.append(k)
 
     def teardown(self):
-        """Teardown step. Is a no-op in the base class.
-
-        """
         pass
 
     def setup(self):
-        """Setup step. Is a no-op in the base class.
-
-        """
         pass
 
     def __enter__(self):
         self.setup()
         return self
 
     def __exit__(self, exc_type, exc_val, exc_tb):
-        self.teardown()
+        self.teardown()
```

## Comparing `finbourne_lab_test/unit/analysis/test_linear.py` & `finbourne_lab_test/unit/analysis/test_linear_scaling_model.py`

 * *Files 11% similar despite different names*

```diff
@@ -1,19 +1,19 @@
 import os
 import unittest
 from pathlib import Path
 from shutil import rmtree
 
 import numpy as np
 
-from finbourne_lab import LinearModel
+from finbourne_lab import ScalingModel
 from finbourne_lab_test.utils.test_data_generation import generate_data
 
 
-class TestLinearModel(unittest.TestCase):
+class TestLinearScalingModel(unittest.TestCase):
 
     work_dir = '/tmp/finbourne_lab_test/linear_scaling_model/'
 
     @classmethod
     def setUpClass(cls) -> None:
 
         if os.path.exists(f'{cls.work_dir}'):
@@ -27,15 +27,15 @@
 
         cls.df1 = generate_data(1, 1000, n_rows, 1.0, 0.01, 0.1)
         cls.df2 = generate_data(1, 1000, n_rows, 0.5, 0.025, 0.1)
         cls.df3 = generate_data(1, 1000, n_rows, 0.5, 0.025, 3, 0.1)
 
     def test_scaling_model_fit_and_predict(self):
 
-        mod_1 = LinearModel(self.df1, 'arg0', 'call_time', 'model1')
+        mod_1 = ScalingModel(self.df1, 'arg0', 'call_time', 'model1')
 
         # Test the fit results meet expectations
         fit_df = mod_1.fit_results()
         quantiles = fit_df.index.tolist()
         c_pred = fit_df.c.round(2).tolist()
         m_pred = fit_df.m.round(2).tolist()
 
@@ -46,26 +46,26 @@
         # Test that the prediction results meet expectations
         x_pred = [1, 10, 100, 1000, 10000, 100000]
         pred_df = mod_1.predict(x_pred).round(2)
         self.assertSequenceEqual(pred_df.index.tolist(), x_pred)
 
     def test_scaling_model_outlier_handling(self):
 
-        mod_3 = LinearModel(self.df3, 'arg0', 'call_time', 'model3')
+        mod_3 = ScalingModel(self.df3, 'arg0', 'call_time', 'model3')
 
         outliers = mod_3.outliers()
         mod_3_proc = mod_3.remove_outliers()
 
         self.assertEqual(outliers.shape[0], 102)
         self.assertEqual(outliers.shape[0] + mod_3_proc.data.shape[0], mod_3.data.shape[0])
 
     def test_scaling_model_outlier_operator_overloads(self):
 
-        mod_1 = LinearModel(self.df1, 'arg0', 'call_time', 'model1')
-        mod_2 = LinearModel(self.df2, 'arg0', 'call_time', 'model2')
+        mod_1 = ScalingModel(self.df1, 'arg0', 'call_time', 'model1')
+        mod_2 = ScalingModel(self.df2, 'arg0', 'call_time', 'model2')
 
         # subtraction
         mod_diff = mod_2 - mod_1
         fr_df_diff = mod_diff.fit_results()
 
         # addition
         mod_sum = mod_2 + mod_1
@@ -75,14 +75,16 @@
         mod_ratio = mod_2 / mod_1
         fr_df_ratio = mod_ratio.fit_results()
 
         # multiplication
         mod_prod = mod_2 * mod_1
         fr_df_prod = mod_prod.fit_results()
 
+        pass
+
     def test_scaling_model_merge(self):
 
-        mod_1 = LinearModel(self.df1, 'arg0', 'call_time', 'model1')
-        mod_2 = LinearModel(self.df2, 'arg0', 'call_time', 'model2')
+        mod_1 = ScalingModel(self.df1, 'arg0', 'call_time', 'model1')
+        mod_2 = ScalingModel(self.df2, 'arg0', 'call_time', 'model2')
         mod = mod_1.merge(mod_2)
         self.assertEqual(mod.data.shape[0], mod_1.data.shape[0] + mod_2.data.shape[0])
```

