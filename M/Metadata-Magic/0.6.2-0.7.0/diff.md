# Comparing `tmp/Metadata_Magic-0.6.2-py3-none-any.whl.zip` & `tmp/Metadata_Magic-0.7.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,53 +1,48 @@
-Zip file size: 88286 bytes, number of entries: 51
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/__init__.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/main/__init__.py
--rw-rw-r--  2.0 unx     3095 b- defN 23-Jul-12 19:19 metadata_magic/main/meta_finder.py
--rw-rw-r--  2.0 unx    12155 b- defN 23-Jul-12 20:57 metadata_magic/main/meta_reader.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/main/comic_archive/__init__.py
--rw-rw-r--  2.0 unx     2846 b- defN 23-Jul-18 21:14 metadata_magic/main/comic_archive/archive_all.py
--rw-rw-r--  2.0 unx    14186 b- defN 23-Jul-18 21:33 metadata_magic/main/comic_archive/comic_archive.py
--rw-rw-r--  2.0 unx     5838 b- defN 23-Jul-17 23:12 metadata_magic/main/comic_archive/comic_archive_update.py
--rw-rw-r--  2.0 unx     9738 b- defN 23-Jul-12 21:30 metadata_magic/main/comic_archive/comic_xml.py
--rw-rw-r--  2.0 unx     3198 b- defN 23-Jul-18 21:14 metadata_magic/main/comic_archive/extract_all.py
--rw-rw-r--  2.0 unx     7950 b- defN 23-Jul-20 15:59 metadata_magic/main/comic_archive/series_info.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/main/epub/__init__.py
--rw-rw-r--  2.0 unx    33790 b- defN 23-Jul-12 22:49 metadata_magic/main/epub/epub.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/main/error_finding/__init__.py
--rw-rw-r--  2.0 unx     6038 b- defN 23-Jul-17 23:12 metadata_magic/main/error_finding/missing_fields.py
--rw-rw-r--  2.0 unx     2076 b- defN 23-Jul-12 22:34 metadata_magic/main/error_finding/missing_media.py
--rw-rw-r--  2.0 unx     2098 b- defN 23-Jul-12 22:34 metadata_magic/main/error_finding/missing_metadata.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jul-12 00:05 metadata_magic/main/file_tools/__init__.py
--rw-rw-r--  2.0 unx    10607 b- defN 23-Jul-18 21:14 metadata_magic/main/file_tools/file_tools.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/main/rename/__init__.py
--rw-rw-r--  2.0 unx     6412 b- defN 23-Jul-17 23:12 metadata_magic/main/rename/meta_rename.py
--rw-rw-r--  2.0 unx     7793 b- defN 23-Jul-19 17:44 metadata_magic/main/rename/rename_tools.py
--rw-rw-r--  2.0 unx     4400 b- defN 23-Jul-12 22:37 metadata_magic/main/rename/sort_rename.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/test/__init__.py
--rw-rw-r--  2.0 unx     4267 b- defN 23-Jul-12 19:08 metadata_magic/test/test_meta_finder.py
--rw-rw-r--  2.0 unx    22953 b- defN 23-Jul-12 19:13 metadata_magic/test/test_meta_reader.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/test/comic_archive/__init__.py
--rw-rw-r--  2.0 unx     3060 b- defN 23-Jul-18 21:14 metadata_magic/test/comic_archive/test_archive_all.py
--rw-rw-r--  2.0 unx    14166 b- defN 23-Jul-18 21:34 metadata_magic/test/comic_archive/test_comic_archive.py
--rw-rw-r--  2.0 unx     5322 b- defN 23-Jul-18 21:14 metadata_magic/test/comic_archive/test_comic_archive_update.py
--rw-rw-r--  2.0 unx    19952 b- defN 23-Jul-12 18:20 metadata_magic/test/comic_archive/test_comic_xml.py
--rw-rw-r--  2.0 unx     4941 b- defN 23-Jul-18 21:14 metadata_magic/test/comic_archive/test_extract_all.py
--rw-rw-r--  2.0 unx     8700 b- defN 23-Jul-12 18:29 metadata_magic/test/comic_archive/test_series_info.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/test/epub/__init__.py
--rw-rw-r--  2.0 unx    43439 b- defN 23-Jul-12 18:40 metadata_magic/test/epub/test_epub.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/test/error_finding/__init__.py
--rw-rw-r--  2.0 unx     7041 b- defN 23-Jul-17 23:12 metadata_magic/test/error_finding/test_missing_fields.py
--rw-rw-r--  2.0 unx     1539 b- defN 23-Jul-12 18:43 metadata_magic/test/error_finding/test_missing_media.py
--rw-rw-r--  2.0 unx     1580 b- defN 23-Jul-12 18:45 metadata_magic/test/error_finding/test_missing_metadata.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jul-12 00:05 metadata_magic/test/file_tools/__init__.py
--rw-rw-r--  2.0 unx    15906 b- defN 23-Jul-18 21:14 metadata_magic/test/file_tools/test_file_tools.py
--rw-rw-r--  2.0 unx       23 b- defN 23-Jun-16 04:28 metadata_magic/test/rename/__init__.py
--rw-rw-r--  2.0 unx     9707 b- defN 23-Jul-12 18:56 metadata_magic/test/rename/test_meta_rename.py
--rw-rw-r--  2.0 unx     9274 b- defN 23-Jul-19 17:41 metadata_magic/test/rename/test_rename_tools.py
--rw-rw-r--  2.0 unx     6745 b- defN 23-Jul-12 19:05 metadata_magic/test/rename/test_sort_rename.py
--rw-rw-r--  2.0 unx    35149 b- defN 23-Jul-20 15:59 Metadata_Magic-0.6.2.dist-info/LICENSE
--rw-rw-r--  2.0 unx     5754 b- defN 23-Jul-20 15:59 Metadata_Magic-0.6.2.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Jul-20 15:59 Metadata_Magic-0.6.2.dist-info/WHEEL
--rw-rw-r--  2.0 unx      779 b- defN 23-Jul-20 15:59 Metadata_Magic-0.6.2.dist-info/entry_points.txt
--rw-rw-r--  2.0 unx       15 b- defN 23-Jul-20 15:59 Metadata_Magic-0.6.2.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     5091 b- defN 23-Jul-20 15:59 Metadata_Magic-0.6.2.dist-info/RECORD
-51 files, 357991 bytes uncompressed, 79870 bytes compressed:  77.7%
+Zip file size: 86107 bytes, number of entries: 46
+-rwxr-xr-x  2.0 unx       23 b- defN 23-Jul-30 21:05 metadata_magic/__init__.py
+-rwxr-xr-x  2.0 unx    10673 b- defN 23-Aug-01 23:02 metadata_magic/file_tools.py
+-rwxr-xr-x  2.0 unx     3102 b- defN 23-Aug-01 17:03 metadata_magic/meta_finder.py
+-rwxr-xr-x  2.0 unx    12127 b- defN 23-Aug-01 18:05 metadata_magic/meta_reader.py
+-rwxr-xr-x  2.0 unx       58 b- defN 23-Jun-12 18:34 metadata_magic/archive/__init__.py
+-rwxr-xr-x  2.0 unx     2818 b- defN 23-Aug-02 02:54 metadata_magic/archive/archive_all.py
+-rwxr-xr-x  2.0 unx    13686 b- defN 23-Aug-02 02:49 metadata_magic/archive/comic_archive.py
+-rwxr-xr-x  2.0 unx     5747 b- defN 23-Aug-02 02:42 metadata_magic/archive/comic_archive_update.py
+-rwxr-xr-x  2.0 unx     9717 b- defN 23-Aug-01 23:55 metadata_magic/archive/comic_xml.py
+-rwxr-xr-x  2.0 unx    34338 b- defN 23-Aug-02 03:03 metadata_magic/archive/epub.py
+-rwxr-xr-x  2.0 unx     3162 b- defN 23-Aug-02 02:52 metadata_magic/archive/extract_all.py
+-rwxr-xr-x  2.0 unx     6452 b- defN 23-Aug-02 01:20 metadata_magic/archive/series_info.py
+-rwxr-xr-x  2.0 unx       23 b- defN 23-Jul-30 21:05 metadata_magic/error/__init__.py
+-rwxr-xr-x  2.0 unx     6103 b- defN 23-Aug-02 01:00 metadata_magic/error/missing_fields.py
+-rwxr-xr-x  2.0 unx     2023 b- defN 23-Aug-02 00:56 metadata_magic/error/missing_media.py
+-rwxr-xr-x  2.0 unx     2045 b- defN 23-Aug-02 00:57 metadata_magic/error/missing_metadata.py
+-rwxr-xr-x  2.0 unx       23 b- defN 23-Jul-30 21:05 metadata_magic/rename/__init__.py
+-rwxr-xr-x  2.0 unx     6442 b- defN 23-Aug-02 01:02 metadata_magic/rename/meta_rename.py
+-rwxr-xr-x  2.0 unx     7721 b- defN 23-Aug-01 17:07 metadata_magic/rename/rename_tools.py
+-rwxr-xr-x  2.0 unx     4300 b- defN 23-Aug-02 01:04 metadata_magic/rename/sort_rename.py
+-rwxr-xr-x  2.0 unx       23 b- defN 23-Jul-30 21:05 metadata_magic/test/__init__.py
+-rwxr-xr-x  2.0 unx    16894 b- defN 23-Aug-01 23:15 metadata_magic/test/test_file_tools.py
+-rwxr-xr-x  2.0 unx     4560 b- defN 23-Aug-01 22:56 metadata_magic/test/test_meta_finder.py
+-rwxr-xr-x  2.0 unx    24720 b- defN 23-Aug-01 21:10 metadata_magic/test/test_meta_reader.py
+-rwxr-xr-x  2.0 unx       58 b- defN 23-Jun-12 18:34 metadata_magic/test/archive/__init__.py
+-rwxr-xr-x  2.0 unx     2998 b- defN 23-Aug-01 20:59 metadata_magic/test/archive/test_archive_all.py
+-rwxr-xr-x  2.0 unx    15138 b- defN 23-Aug-01 20:51 metadata_magic/test/archive/test_comic_archive.py
+-rwxr-xr-x  2.0 unx     5541 b- defN 23-Aug-01 20:32 metadata_magic/test/archive/test_comic_archive_update.py
+-rwxr-xr-x  2.0 unx    21706 b- defN 23-Aug-01 20:24 metadata_magic/test/archive/test_comic_xml.py
+-rwxr-xr-x  2.0 unx    43585 b- defN 23-Aug-01 20:07 metadata_magic/test/archive/test_epub.py
+-rwxr-xr-x  2.0 unx     5173 b- defN 23-Aug-01 19:14 metadata_magic/test/archive/test_extract_all.py
+-rwxr-xr-x  2.0 unx     6491 b- defN 23-Aug-01 19:00 metadata_magic/test/archive/test_series_info.py
+-rwxr-xr-x  2.0 unx       23 b- defN 23-Jul-30 21:05 metadata_magic/test/error/__init__.py
+-rwxr-xr-x  2.0 unx     7349 b- defN 23-Aug-01 18:46 metadata_magic/test/error/test_missing_fields.py
+-rwxr-xr-x  2.0 unx     1577 b- defN 23-Aug-01 18:30 metadata_magic/test/error/test_missing_media.py
+-rwxr-xr-x  2.0 unx     1627 b- defN 23-Aug-01 18:26 metadata_magic/test/error/test_missing_metadata.py
+-rwxr-xr-x  2.0 unx       23 b- defN 23-Jul-30 21:05 metadata_magic/test/rename/__init__.py
+-rwxr-xr-x  2.0 unx    10348 b- defN 23-Aug-01 18:19 metadata_magic/test/rename/test_meta_rename.py
+-rwxr-xr-x  2.0 unx    10246 b- defN 23-Aug-01 17:17 metadata_magic/test/rename/test_rename_tools.py
+-rwxr-xr-x  2.0 unx     7015 b- defN 23-Aug-01 17:09 metadata_magic/test/rename/test_sort_rename.py
+-rwxr-xr-x  2.0 unx    35149 b- defN 23-Aug-02 03:09 Metadata_Magic-0.7.0.dist-info/LICENSE
+-rwxr-xr-x  2.0 unx     5754 b- defN 23-Aug-02 03:09 Metadata_Magic-0.7.0.dist-info/METADATA
+-rwxr-xr-x  2.0 unx       92 b- defN 23-Aug-02 03:09 Metadata_Magic-0.7.0.dist-info/WHEEL
+-rwxr-xr-x  2.0 unx      673 b- defN 23-Aug-02 03:09 Metadata_Magic-0.7.0.dist-info/entry_points.txt
+-rwxr-xr-x  2.0 unx       15 b- defN 23-Aug-02 03:09 Metadata_Magic-0.7.0.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     4372 b- defN 23-Aug-02 03:09 Metadata_Magic-0.7.0.dist-info/RECORD
+46 files, 361733 bytes uncompressed, 78963 bytes compressed:  78.2%
```

## zipnote {}

```diff
@@ -1,154 +1,139 @@
 Filename: metadata_magic/__init__.py
 Comment: 
 
-Filename: metadata_magic/main/__init__.py
+Filename: metadata_magic/file_tools.py
 Comment: 
 
-Filename: metadata_magic/main/meta_finder.py
+Filename: metadata_magic/meta_finder.py
 Comment: 
 
-Filename: metadata_magic/main/meta_reader.py
+Filename: metadata_magic/meta_reader.py
 Comment: 
 
-Filename: metadata_magic/main/comic_archive/__init__.py
+Filename: metadata_magic/archive/__init__.py
 Comment: 
 
-Filename: metadata_magic/main/comic_archive/archive_all.py
+Filename: metadata_magic/archive/archive_all.py
 Comment: 
 
-Filename: metadata_magic/main/comic_archive/comic_archive.py
+Filename: metadata_magic/archive/comic_archive.py
 Comment: 
 
-Filename: metadata_magic/main/comic_archive/comic_archive_update.py
+Filename: metadata_magic/archive/comic_archive_update.py
 Comment: 
 
-Filename: metadata_magic/main/comic_archive/comic_xml.py
+Filename: metadata_magic/archive/comic_xml.py
 Comment: 
 
-Filename: metadata_magic/main/comic_archive/extract_all.py
+Filename: metadata_magic/archive/epub.py
 Comment: 
 
-Filename: metadata_magic/main/comic_archive/series_info.py
+Filename: metadata_magic/archive/extract_all.py
 Comment: 
 
-Filename: metadata_magic/main/epub/__init__.py
+Filename: metadata_magic/archive/series_info.py
 Comment: 
 
-Filename: metadata_magic/main/epub/epub.py
+Filename: metadata_magic/error/__init__.py
 Comment: 
 
-Filename: metadata_magic/main/error_finding/__init__.py
+Filename: metadata_magic/error/missing_fields.py
 Comment: 
 
-Filename: metadata_magic/main/error_finding/missing_fields.py
+Filename: metadata_magic/error/missing_media.py
 Comment: 
 
-Filename: metadata_magic/main/error_finding/missing_media.py
+Filename: metadata_magic/error/missing_metadata.py
 Comment: 
 
-Filename: metadata_magic/main/error_finding/missing_metadata.py
+Filename: metadata_magic/rename/__init__.py
 Comment: 
 
-Filename: metadata_magic/main/file_tools/__init__.py
+Filename: metadata_magic/rename/meta_rename.py
 Comment: 
 
-Filename: metadata_magic/main/file_tools/file_tools.py
+Filename: metadata_magic/rename/rename_tools.py
 Comment: 
 
-Filename: metadata_magic/main/rename/__init__.py
+Filename: metadata_magic/rename/sort_rename.py
 Comment: 
 
-Filename: metadata_magic/main/rename/meta_rename.py
-Comment: 
-
-Filename: metadata_magic/main/rename/rename_tools.py
-Comment: 
-
-Filename: metadata_magic/main/rename/sort_rename.py
+Filename: metadata_magic/test/__init__.py
 Comment: 
 
-Filename: metadata_magic/test/__init__.py
+Filename: metadata_magic/test/test_file_tools.py
 Comment: 
 
 Filename: metadata_magic/test/test_meta_finder.py
 Comment: 
 
 Filename: metadata_magic/test/test_meta_reader.py
 Comment: 
 
-Filename: metadata_magic/test/comic_archive/__init__.py
-Comment: 
-
-Filename: metadata_magic/test/comic_archive/test_archive_all.py
-Comment: 
-
-Filename: metadata_magic/test/comic_archive/test_comic_archive.py
-Comment: 
-
-Filename: metadata_magic/test/comic_archive/test_comic_archive_update.py
+Filename: metadata_magic/test/archive/__init__.py
 Comment: 
 
-Filename: metadata_magic/test/comic_archive/test_comic_xml.py
+Filename: metadata_magic/test/archive/test_archive_all.py
 Comment: 
 
-Filename: metadata_magic/test/comic_archive/test_extract_all.py
+Filename: metadata_magic/test/archive/test_comic_archive.py
 Comment: 
 
-Filename: metadata_magic/test/comic_archive/test_series_info.py
+Filename: metadata_magic/test/archive/test_comic_archive_update.py
 Comment: 
 
-Filename: metadata_magic/test/epub/__init__.py
+Filename: metadata_magic/test/archive/test_comic_xml.py
 Comment: 
 
-Filename: metadata_magic/test/epub/test_epub.py
+Filename: metadata_magic/test/archive/test_epub.py
 Comment: 
 
-Filename: metadata_magic/test/error_finding/__init__.py
+Filename: metadata_magic/test/archive/test_extract_all.py
 Comment: 
 
-Filename: metadata_magic/test/error_finding/test_missing_fields.py
+Filename: metadata_magic/test/archive/test_series_info.py
 Comment: 
 
-Filename: metadata_magic/test/error_finding/test_missing_media.py
+Filename: metadata_magic/test/error/__init__.py
 Comment: 
 
-Filename: metadata_magic/test/error_finding/test_missing_metadata.py
+Filename: metadata_magic/test/error/test_missing_fields.py
 Comment: 
 
-Filename: metadata_magic/test/file_tools/__init__.py
+Filename: metadata_magic/test/error/test_missing_media.py
 Comment: 
 
-Filename: metadata_magic/test/file_tools/test_file_tools.py
+Filename: metadata_magic/test/error/test_missing_metadata.py
 Comment: 
 
 Filename: metadata_magic/test/rename/__init__.py
 Comment: 
 
 Filename: metadata_magic/test/rename/test_meta_rename.py
 Comment: 
 
 Filename: metadata_magic/test/rename/test_rename_tools.py
 Comment: 
 
 Filename: metadata_magic/test/rename/test_sort_rename.py
 Comment: 
 
-Filename: Metadata_Magic-0.6.2.dist-info/LICENSE
+Filename: Metadata_Magic-0.7.0.dist-info/LICENSE
 Comment: 
 
-Filename: Metadata_Magic-0.6.2.dist-info/METADATA
+Filename: Metadata_Magic-0.7.0.dist-info/METADATA
 Comment: 
 
-Filename: Metadata_Magic-0.6.2.dist-info/WHEEL
+Filename: Metadata_Magic-0.7.0.dist-info/WHEEL
 Comment: 
 
-Filename: Metadata_Magic-0.6.2.dist-info/entry_points.txt
+Filename: Metadata_Magic-0.7.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: Metadata_Magic-0.6.2.dist-info/top_level.txt
+Filename: Metadata_Magic-0.7.0.dist-info/top_level.txt
 Comment: 
 
-Filename: Metadata_Magic-0.6.2.dist-info/RECORD
+Filename: Metadata_Magic-0.7.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## metadata_magic/test/test_meta_finder.py

```diff
@@ -1,100 +1,98 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_finder import get_pairs
-from metadata_magic.main.meta_finder import separate_files
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import mkdir
+import os
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_finder as mm_meta_finder
 from os.path import abspath, basename, exists, join
 
 def test_separate_files():
     """
     Tests the separate_files function
     """
     # Test with an empty folder
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     assert exists(temp_dir)
-    jsons, media = separate_files(temp_dir)
+    jsons, media = mm_meta_finder.separate_files(temp_dir)
     assert jsons == []
     assert media == []
     # Test only in main directory
-    write_text_file(abspath(join(temp_dir, "main.json")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "other.json")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "image.png")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "thing.txt")), "BLAH")
-    jsons, media = separate_files(temp_dir)
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "main.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "other.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "image.png")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "thing.txt")), "BLAH")
+    jsons, media = mm_meta_finder.separate_files(temp_dir)
     assert len(jsons) == 2
     assert basename(jsons[0]) == "main.json"
     assert basename(jsons[1]) == "other.json"
     assert len(media) == 2
     assert basename(media[0]) == "image.png"
     assert basename(media[1]) == "thing.txt"
     # Test with sub-directories
     sub1 = abspath(join(temp_dir, "sub1"))
     sub2 = abspath(join(temp_dir, "sub2"))
-    mkdir(sub1)
-    mkdir(sub2)
+    os.mkdir(sub1)
+    os.mkdir(sub2)
     assert exists(sub1)
     assert exists(sub2)
-    write_text_file(abspath(join(sub1, "sub.json")), "BLAH")
-    write_text_file(abspath(join(sub2, "more.jpeg")), "BLAH")
-    jsons, media = separate_files(temp_dir)
+    mm_file_tools.write_text_file(abspath(join(sub1, "sub.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub2, "more.jpeg")), "BLAH")
+    jsons, media = mm_meta_finder.separate_files(temp_dir)
     assert len(jsons) == 3
     assert basename(jsons[0]) == "main.json"
     assert basename(jsons[1]) == "other.json"
     assert basename(jsons[2]) == "sub.json"
     assert len(media) == 3
     assert basename(media[0]) == "image.png"
     assert basename(media[1]) == "more.jpeg"
     assert basename(media[2]) == "thing.txt"
 
 def test_get_pairs():
     """
     Tests the get_pairs function.
     """
     # Test with an empty folder
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     assert exists(temp_dir)
-    assert get_pairs(temp_dir) == []
+    assert mm_meta_finder.get_pairs(temp_dir) == []
     # Test with unpaired files
-    write_text_file(abspath(join(temp_dir, "unlinked.json")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "thing.txt")), "BLAH")
-    assert get_pairs(temp_dir) == []
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "unlinked.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "thing.txt")), "BLAH")
+    assert mm_meta_finder.get_pairs(temp_dir) == []
     # Test paired JSONs with extensions in filename
     sub = abspath(join(temp_dir, "sub"))
-    mkdir(sub)
-    write_text_file(abspath(join(temp_dir, "linked.png.json")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "linked.png")), "BLAH")
-    write_text_file(abspath(join(sub, "other.txt.json")), "BLAH")
-    write_text_file(abspath(join(sub, "other.txt")), "BLAH")
-    pairs = get_pairs(temp_dir)
+    os.mkdir(sub)
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "linked.png.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "linked.png")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub, "other.txt.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub, "other.txt")), "BLAH")
+    pairs = mm_meta_finder.get_pairs(temp_dir)
     assert len(pairs) == 2
     assert basename(pairs[0]["media"]) == "linked.png"
     assert basename(pairs[0]["json"]) == "linked.png.json"
     assert basename(pairs[1]["media"]) == "other.txt"
     assert basename(pairs[1]["json"]) == "other.txt.json"
     # Test JSON with wrong extension in filename
-    write_text_file(abspath(join(sub, "unmatched.zip.json")), "BLAH")
-    write_text_file(abspath(join(sub, "unmatched.cbz")), "BLAH")
-    pairs = get_pairs(temp_dir)
+    mm_file_tools.write_text_file(abspath(join(sub, "unmatched.zip.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub, "unmatched.cbz")), "BLAH")
+    pairs = mm_meta_finder.get_pairs(temp_dir)
     assert len(pairs) == 2
     # Test paired JSONs without extensions in filename
-    write_text_file(abspath(join(temp_dir, "media.jpg")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "media.json")), "BLAH")
-    write_text_file(abspath(join(sub, "next thing.ogg")), "BLAH")
-    write_text_file(abspath(join(sub, "next thing.json")), "BLAH")
-    pairs = get_pairs(temp_dir)
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "media.jpg")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "media.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub, "next thing.ogg")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub, "next thing.json")), "BLAH")
+    pairs = mm_meta_finder.get_pairs(temp_dir)
     assert len(pairs) == 4
     assert basename(pairs[0]["media"]) == "linked.png"
     assert basename(pairs[0]["json"]) == "linked.png.json"
     assert basename(pairs[1]["media"]) == "media.jpg"
     assert basename(pairs[1]["json"]) == "media.json"
     assert basename(pairs[2]["media"]) == "next thing.ogg"
     assert basename(pairs[2]["json"]) == "next thing.json"
     assert basename(pairs[3]["media"]) == "other.txt"
     assert basename(pairs[3]["json"]) == "other.txt.json"
     # Test files with same names in different directories
-    write_text_file(abspath(join(sub, "different.json")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "different.gif")), "BLAH")
-    pairs = get_pairs(temp_dir)
+    mm_file_tools.write_text_file(abspath(join(sub, "different.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "different.gif")), "BLAH")
+    pairs = mm_meta_finder.get_pairs(temp_dir)
     assert len(pairs) == 4
```

## metadata_magic/test/test_meta_reader.py

```diff
@@ -1,30 +1,18 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.meta_reader import get_value_from_keylist
-from metadata_magic.main.meta_reader import load_metadata
-from metadata_magic.main.meta_reader import get_id
-from metadata_magic.main.meta_reader import get_title
-from metadata_magic.main.meta_reader import get_artist
-from metadata_magic.main.meta_reader import get_date
-from metadata_magic.main.meta_reader import get_description
-from metadata_magic.main.meta_reader import get_url
-from metadata_magic.main.meta_reader import get_tags
-from metadata_magic.main.meta_reader import get_publisher
-from metadata_magic.main.meta_reader import get_age_rating
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import write_json_file
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
 from os.path import abspath, exists, join
 
 def test_get_empty_metadata():
     """
     Tests the get_empty_metadata function.
     """
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     assert meta["title"] is None
     assert meta["series"] is None
     assert meta["series_number"] is None
     assert meta["series_total"] is None
     assert meta["description"] is None
     assert meta["date"] is None
     assert meta["writer"] is None
@@ -38,44 +26,44 @@
 
 def test_get_value_from_keylist():
     """
     Tests the get_value_from_keylist function.
     """
     dictionary = {"key":"Value", "next":None, "thing":54, "other":True, "inner":{"last":"Tag"}}
     # Test getting value from the first key
-    assert get_value_from_keylist(dictionary, [["key"]], str) == "Value"
-    assert get_value_from_keylist(dictionary, [["other"], ["blah"]], bool) is True
-    assert get_value_from_keylist(dictionary, [["thing"], ["key"], ["other"]], int) == 54
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["key"]], str) == "Value"
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["other"], ["blah"]], bool) is True
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["thing"], ["key"], ["other"]], int) == 54
     # Test getting value from secondary key
-    assert get_value_from_keylist(dictionary, [["nope"], ["thing"]], int) == 54
-    assert get_value_from_keylist(dictionary, [["next"], ["other"], ["blah"]], bool) == True
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["nope"], ["thing"]], int) == 54
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["next"], ["other"], ["blah"]], bool) == True
     # Test getting value from inner dictionary
-    assert get_value_from_keylist(dictionary, [["blah"], ["inner","last"]], str) == "Tag"
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["blah"], ["inner","last"]], str) == "Tag"
     # Test getting value when some are the wrong type
-    assert get_value_from_keylist(dictionary, [["key"], ["thing"]], int) == 54
-    assert get_value_from_keylist(dictionary, [["thing"], ["key"]], str) == "Value"
-    assert get_value_from_keylist(dictionary, [["inner"], ["key"]], str) == "Value"
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["key"], ["thing"]], int) == 54
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["thing"], ["key"]], str) == "Value"
+    assert mm_meta_reader.get_value_from_keylist(dictionary, [["inner"], ["key"]], str) == "Value"
     # Test getting value if no keys are valid
-    assert get_value_from_keylist(dictionary, ["nope"], str) is None
-    assert get_value_from_keylist(dictionary, ["nope", "not this either", ["or", "this"]], int) is None
+    assert mm_meta_reader.get_value_from_keylist(dictionary, ["nope"], str) is None
+    assert mm_meta_reader.get_value_from_keylist(dictionary, ["nope", "not this either", ["or", "this"]], int) is None
 
 def test_load_metadata():
     """
     Tests the load_metadata function.
     """
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_json = abspath(join(temp_dir, "empty.json"))
-    write_json_file(test_json, {"title":"test"})
+    mm_file_tools.write_json_file(test_json, {"title":"test"})
     assert exists(test_json)
     # Attempt to load the JSON file
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     # Test loading from an invalid path
-    meta = load_metadata("/not/real/directory/")
+    meta = mm_meta_reader.load_metadata("/not/real/directory/")
     assert not exists(meta["json_path"])
     assert meta["id"] is None
     assert meta["title"] is None
     assert meta["artist"] is None
     assert meta["writer"] is None
     assert meta["date"] is None
     assert meta["description"] is None
@@ -85,409 +73,409 @@
 
 def test_get_title():
     """
     Tests the get_title function.
     """
     # Test getting title from dictionary
     dictionary = {"thing":"blah", "inner":{"title":"Thing!"}, "title":"Bleh"}
-    assert get_title(dictionary) == "Bleh"
+    assert mm_meta_reader.get_title(dictionary) == "Bleh"
     dictionary = {"info":{"title": "New Title", "artists":["thing"]}}
-    assert get_title(dictionary) == "New Title"
+    assert mm_meta_reader.get_title(dictionary) == "New Title"
     # Test if there is no title
-    assert get_title({"no":"title"}) is None
+    assert mm_meta_reader.get_title({"no":"title"}) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_json = abspath(join(temp_dir, "title.json"))
-    write_json_file(test_json, {"thing":"other", "title":"Loaded!"})
+    mm_file_tools.write_json_file(test_json, {"thing":"other", "title":"Loaded!"})
     assert exists(test_json)
     # Test getting title when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["title"] == "Loaded!"
 
 def test_get_artist():
     """
     Tests the get_artist function.
     """
     # Test getting artist from dictionary
     dictionary = {"thing":50, "artist":"Artist", "author":"other"}
-    assert get_artist(dictionary) == "Artist"
+    assert mm_meta_reader.get_artist(dictionary) == "Artist"
     dictionary = {"uploader":"Person", "other":True, "innner":{"artist":"blah"}}
-    assert get_artist(dictionary) == "Person"
+    assert mm_meta_reader.get_artist(dictionary) == "Person"
     dictionary = {"thing":"Person", "user":"Third", "name":"blah"}
-    assert get_artist(dictionary) == "Third"
+    assert mm_meta_reader.get_artist(dictionary) == "Third"
     dictionary = {"author":"Person", "username":"another"}
-    assert get_artist(dictionary) == "another"
+    assert mm_meta_reader.get_artist(dictionary) == "another"
     dictionary = {"thing":"blah", "author":{"username":"Yep"}, "person":"Next"}
-    assert get_artist(dictionary) == "Yep"
+    assert mm_meta_reader.get_artist(dictionary) == "Yep"
     dictionary = {"user":{"name":"Cpt. Human"}, "artist":50, "owner":"thing"}
-    assert get_artist(dictionary) == "Cpt. Human"
+    assert mm_meta_reader.get_artist(dictionary) == "Cpt. Human"
     dictionary = {"owner":"New", "type":"other"}
-    assert get_artist(dictionary) == "New"
+    assert mm_meta_reader.get_artist(dictionary) == "New"
     dictionary = {"total":True, "creator":{"full_name":"Real Person"}}
-    assert get_artist(dictionary) == "Real Person"
-    assert get_artist(dictionary) == "Real Person"
+    assert mm_meta_reader.get_artist(dictionary) == "Real Person"
+    assert mm_meta_reader.get_artist(dictionary) == "Real Person"
     # Test getting artist from artist list in dictionary
     dictionary = {"artists":["New Person", "blah"], "type":"other"}
-    assert get_artist(dictionary) == "New Person"
+    assert mm_meta_reader.get_artist(dictionary) == "New Person"
     dictionary = {"info":{"artists":["ArtLass"], "title":"blah"}, "next":"this"}
-    assert get_artist(dictionary) == "ArtLass"
+    assert mm_meta_reader.get_artist(dictionary) == "ArtLass"
     # Test if there is no artist
-    assert get_artist({"no":"artist"}) is None
-    assert get_artist({"artists":[]}) is None
+    assert mm_meta_reader.get_artist({"no":"artist"}) is None
+    assert mm_meta_reader.get_artist({"artists":[]}) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_json = abspath(join(temp_dir, "artists.json"))
-    write_json_file(test_json, {"thing":"other", "uploader":"Name!!!"})
+    mm_file_tools.write_json_file(test_json, {"thing":"other", "uploader":"Name!!!"})
     assert exists(test_json)
     # Test getting artist when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["artist"] == "Name!!!"
     assert meta["writer"] == "Name!!!"
 
 def test_get_date():
     """
     Tests the get_date function.
     """
     # Test getting date from dictionary in YYYY-MM-DD format
     dictionary = {"thing":50, "date":"2022-12-25"}
-    assert get_date(dictionary) == "2022-12-25"
+    assert mm_meta_reader.get_date(dictionary) == "2022-12-25"
     dictionary = {"upload_date":"1983/07-14", "other":False, "new":"Thing"}
-    assert get_date(dictionary) == "1983-07-14"
+    assert mm_meta_reader.get_date(dictionary) == "1983-07-14"
     dictionary = {"published_at":"2019-05-01T00:31:00.000+00:00"}
-    assert get_date(dictionary) == "2019-05-01"
+    assert mm_meta_reader.get_date(dictionary) == "2019-05-01"
     dictionary = {"info":{"time":"2012/12/21|22:33"}}
-    assert get_date(dictionary) == "2012-12-21"
+    assert mm_meta_reader.get_date(dictionary) == "2012-12-21"
     # Test getting date from dictionary in YYYYMMDD format
     dictionary = {"date":"19990723", "next":24}
-    assert get_date(dictionary) == "1999-07-23"
+    assert mm_meta_reader.get_date(dictionary) == "1999-07-23"
     dictionary = {"thing":"other", "upload_date":"20041115", "date":{"other":23}}
-    assert get_date(dictionary) == "2004-11-15"
+    assert mm_meta_reader.get_date(dictionary) == "2004-11-15"
     dictionary = {"info":{"time":"20121221", "title":23}}
-    assert get_date(dictionary) == "2012-12-21"
+    assert mm_meta_reader.get_date(dictionary) == "2012-12-21"
     # Test getting invalid date
     dictionary = {"date":"2012-02-35"}
-    assert get_date(dictionary) is None
+    assert mm_meta_reader.get_date(dictionary) is None
     dictionary = {"upload_date":"thing"}
-    assert get_date(dictionary) is None
+    assert mm_meta_reader.get_date(dictionary) is None
     dictionary = {"thing":"blah"}
-    assert get_date(dictionary) is None
+    assert mm_meta_reader.get_date(dictionary) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_json = abspath(join(temp_dir, "date.json"))
-    write_json_file(test_json, {"thing":"other", "date":"20230513"})
+    mm_file_tools.write_json_file(test_json, {"thing":"other", "date":"20230513"})
     assert exists(test_json)
     # Test getting date when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["date"] == "2023-05-13"
 
 def test_get_description():
     """
     Tests the get_description function.
     """
     # Test getting description from dictionary
     dictionary = {"thing":"other", "description":"Some words.<br>Thing"}
-    assert get_description(dictionary) == "Some words.<br>Thing"
+    assert mm_meta_reader.get_description(dictionary) == "Some words.<br>Thing"
     dictionary = {"description":{"inner":"thing"}, "caption":"New", "content":False}
-    assert get_description(dictionary) == "New"
+    assert mm_meta_reader.get_description(dictionary) == "New"
     dictionary = {"other":"Key", "content":"More text"}
-    assert get_description(dictionary) == "More text"
+    assert mm_meta_reader.get_description(dictionary) == "More text"
     dictionary = {"thing":"other", "info":{"description":"New Text"}}
-    assert get_description(dictionary) == "New Text"
+    assert mm_meta_reader.get_description(dictionary) == "New Text"
     # Test if there is no description
     dictionary = {"no":"description"}
-    assert get_description(dictionary) is None
+    assert mm_meta_reader.get_description(dictionary) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_json = abspath(join(temp_dir, "description.json"))
-    write_json_file(test_json, {"thing":"other", "description":"New<br><br>Description!"})
+    mm_file_tools.write_json_file(test_json, {"thing":"other", "description":"New<br><br>Description!"})
     assert exists(test_json)
     # Test getting decscription when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["description"] == "New<br><br>Description!"
 
 def test_get_id():
     """
     Tests the get_id function.
     """
     # Test getting string ID
     dictionary = {"test":"thing", "id":"abc123"}
-    assert get_id(dictionary) == "abc123"
+    assert mm_meta_reader.get_id(dictionary) == "abc123"
     dictionary = {"test":"thing", "display_id":"thing", "id":{"inner":"thing"}}
-    assert get_id(dictionary) == "thing"
+    assert mm_meta_reader.get_id(dictionary) == "thing"
     dictionary = {"index":"New1"}
-    assert get_id(dictionary) == "New1"
+    assert mm_meta_reader.get_id(dictionary) == "New1"
     dictionary = {"submission_id":"Final", "other":23}
-    assert get_id(dictionary) == "Final"
+    assert mm_meta_reader.get_id(dictionary) == "Final"
     dictionary = {"submitid":"Other"}
-    assert get_id(dictionary) == "Other"
+    assert mm_meta_reader.get_id(dictionary) == "Other"
     # Test getting int ID
     dictionary = {"test":"thing", "id":4254}
-    assert get_id(dictionary) == "4254"
+    assert mm_meta_reader.get_id(dictionary) == "4254"
     dictionary = {"test":"thing", "display_id":3600, "id":{"inner":"thing"}}
-    assert get_id(dictionary) == "3600"
+    assert mm_meta_reader.get_id(dictionary) == "3600"
     dictionary = {"index":3}
-    assert get_id(dictionary) == "3"
+    assert mm_meta_reader.get_id(dictionary) == "3"
     dictionary = {"submission_id":58403, "other":23}
-    assert get_id(dictionary) == "58403"
+    assert mm_meta_reader.get_id(dictionary) == "58403"
     dictionary = {"submitid":483}
-    assert get_id(dictionary) == "483"
+    assert mm_meta_reader.get_id(dictionary) == "483"
     # Test getting old DVK ID format
     dictionary = {"id":"DVA48305"}
-    assert get_id(dictionary) == "48305"
+    assert mm_meta_reader.get_id(dictionary) == "48305"
     dictionary = {"index":"FAF29045"}
-    assert get_id(dictionary) == "29045"
+    assert mm_meta_reader.get_id(dictionary) == "29045"
     dictionary = {"display_id":"INK-1234"}
-    assert get_id(dictionary) == "1234"
+    assert mm_meta_reader.get_id(dictionary) == "1234"
     dictionary = {"display_id":"ink123"}
-    assert get_id(dictionary) == "ink123"
+    assert mm_meta_reader.get_id(dictionary) == "ink123"
     dictionary = {"id":"DVAV225"}
-    assert get_id(dictionary) == "DVAV225"
+    assert mm_meta_reader.get_id(dictionary) == "DVAV225"
     # Test adding file id, if necessary
     dictionary = {"id":"INK135", "file_id":"987"}
-    assert get_id(dictionary) == "135-987"
+    assert mm_meta_reader.get_id(dictionary) == "135-987"
     dictionary = {"index":"4829", "thing":54, "file_id":"27606"}
-    assert get_id(dictionary) == "4829-27606"
+    assert mm_meta_reader.get_id(dictionary) == "4829-27606"
     # Test if there is no ID
     dictionary = {"no":"id"}
-    assert get_id(dictionary) is None
+    assert mm_meta_reader.get_id(dictionary) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_json = abspath(join(temp_dir, "id.json"))
-    write_json_file(test_json, {"thing":"other", "id":"Blah"})
+    mm_file_tools.write_json_file(test_json, {"thing":"other", "id":"Blah"})
     assert exists(test_json)
     # Test getting ID when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["id"] == "Blah"
 
 def test_get_publisher():
     """
     Tests the get_publisher function.
     """
     # Test getting DeviantArt as publisher
     dictionary = {"url":"www.deviantart.com/person/art/thing20398462-183", "thing":"blah"}
-    assert get_publisher(dictionary) == "DeviantArt"
+    assert mm_meta_reader.get_publisher(dictionary) == "DeviantArt"
     dictionary = {"category":"DeviantArt", "url":{"inner":"thing"}}
-    assert get_publisher(dictionary) == "DeviantArt"
+    assert mm_meta_reader.get_publisher(dictionary) == "DeviantArt"
     # Test getting FurAffinity as publisher
     dictionary = {"a":"thing", "webpage_url":"www.furaffinity.net/art/091289023001290389012"}
-    assert get_publisher(dictionary) == "Fur Affinity"
+    assert mm_meta_reader.get_publisher(dictionary) == "Fur Affinity"
     dictionary = {"category":"FurAffinity", "some":292}
-    assert get_publisher(dictionary) == "Fur Affinity"
+    assert mm_meta_reader.get_publisher(dictionary) == "Fur Affinity"
     # Test getting Inkbunny as publisher
     dictionary = {"b":"thing", "post_url":"www.inkbunny.net/thing/", "a":"blah"}
-    assert get_publisher(dictionary) == "Inkbunny"
+    assert mm_meta_reader.get_publisher(dictionary) == "Inkbunny"
     dictionary = {"this":"thing", "category":"inkbunny"}
-    assert get_publisher(dictionary) == "Inkbunny"
+    assert mm_meta_reader.get_publisher(dictionary) == "Inkbunny"
     # Test getting Newgrounds as publisher
     dictionary = {"b":"thing", "post_url":"www.newgrounds.com/art/qojkadskljfd", "a":"blah"}
-    assert get_publisher(dictionary) == "Newgrounds"
+    assert mm_meta_reader.get_publisher(dictionary) == "Newgrounds"
     dictionary = {"this":"thing", "category":"newgrounds", "id":"other"}
-    assert get_publisher(dictionary) == "Newgrounds"
+    assert mm_meta_reader.get_publisher(dictionary) == "Newgrounds"
     # Test getting Patreon as publisher
     dictionary = {"thing":"Blah", "web":{"page_url":"www.patreon.com/test/url"}}
-    assert get_publisher(dictionary) == "Patreon"
+    assert mm_meta_reader.get_publisher(dictionary) == "Patreon"
     dictionary = {"category":"patreon"}
-    assert get_publisher(dictionary) == "Patreon"
+    assert mm_meta_reader.get_publisher(dictionary) == "Patreon"
     # Test getting pixiv as publisher
     dictionary = {"b":"blah", "url":"www.pixiv.net/thing", "2":2}
-    assert get_publisher(dictionary) == "pixiv"
+    assert mm_meta_reader.get_publisher(dictionary) == "pixiv"
     dictionary = {"category":"pixiv"}
-    assert get_publisher(dictionary) == "pixiv"
+    assert mm_meta_reader.get_publisher(dictionary) == "pixiv"
     # Test getting Weasyl as publisher
     dictionary = {"link":"www.weasyl.com", "url":"not-deviantart", "a":"blah"}
-    assert get_publisher(dictionary) == "Weasyl"
+    assert mm_meta_reader.get_publisher(dictionary) == "Weasyl"
     dictionary = {"category":"WEASYL", "other":True}
-    assert get_publisher(dictionary) == "Weasyl"
+    assert mm_meta_reader.get_publisher(dictionary) == "Weasyl"
     # Test getting YouTube as publisher
     dictionary = {"webpage_url":"www.youtube.com/thing/other", "a":"blah"}
-    assert get_publisher(dictionary) == "YouTube"
+    assert mm_meta_reader.get_publisher(dictionary) == "YouTube"
     dictionary = {"this":"thing", "category":"YouTube"}
-    assert get_publisher(dictionary) == "YouTube"
+    assert mm_meta_reader.get_publisher(dictionary) == "YouTube"
     # Test if there is no viable publisher
     dictionary = {"url":"none"}
-    assert get_publisher(dictionary) is None
+    assert mm_meta_reader.get_publisher(dictionary) is None
     dictionary = {"no":"URLS"}
-    assert get_publisher(dictionary) is None
+    assert mm_meta_reader.get_publisher(dictionary) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_json = abspath(join(temp_dir, "publisher.json"))
-    write_json_file(test_json, {"thing":"other", "url":"www.deviantart.com/art/blah"})
+    mm_file_tools.write_json_file(test_json, {"thing":"other", "url":"www.deviantart.com/art/blah"})
     assert exists(test_json)
     # Test getting publisher when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["publisher"] == "DeviantArt"
 
 def test_get_url():
     """
     Tests the get_url function.
     """
     # Test getting URL strictly from JSON dictionary
     dictionary = {"url":"www.thisisatest.pizza", "thing":True}
-    assert get_url(dictionary) == "www.thisisatest.pizza"
+    assert mm_meta_reader.get_url(dictionary) == "www.thisisatest.pizza"
     dictionary = {"link":"URL.thing", "id":"other"}
-    assert get_url(dictionary, "NotPublisher", "ID123") == "URL.thing"
+    assert mm_meta_reader.get_url(dictionary, "NotPublisher", "ID123") == "URL.thing"
     dictionary = {"total":124, "post_url":"New.url.thing"}
-    assert get_url(dictionary, None, "123") == "New.url.thing"
+    assert mm_meta_reader.get_url(dictionary, None, "123") == "New.url.thing"
     dictionary = {"webpage_url":"newthing.txt.thing", "id":"ABC"}
-    assert get_url(dictionary, "Fur Affinity", None) == "newthing.txt.thing"
+    assert mm_meta_reader.get_url(dictionary, "Fur Affinity", None) == "newthing.txt.thing"
     dictionary = {"web":{"page_url":"new/url/value"}, "id":"ABC"}
-    assert get_url(dictionary, "Deviantart", None) == "new/url/value"
+    assert mm_meta_reader.get_url(dictionary, "Deviantart", None) == "new/url/value"
     # Test getting Fur Affinity URL
-    assert get_url({"D":"M"}, "Fur Affinity", "ID123") == "https://www.furaffinity.net/view/ID123/"
-    assert get_url({"A":"B"}, "Fur Affinity", "Other") == "https://www.furaffinity.net/view/Other/"
+    assert mm_meta_reader.get_url({"D":"M"}, "Fur Affinity", "ID123") == "https://www.furaffinity.net/view/ID123/"
+    assert mm_meta_reader.get_url({"A":"B"}, "Fur Affinity", "Other") == "https://www.furaffinity.net/view/Other/"
     # Test getting Inkbunny URL
-    assert get_url({"D":"M"}, "Inkbunny", "ID123") == "https://inkbunny.net/s/ID123"
-    assert get_url({"A":"B"}, "Inkbunny", "Other") == "https://inkbunny.net/s/Other"
+    assert mm_meta_reader.get_url({"D":"M"}, "Inkbunny", "ID123") == "https://inkbunny.net/s/ID123"
+    assert mm_meta_reader.get_url({"A":"B"}, "Inkbunny", "Other") == "https://inkbunny.net/s/Other"
     # Test getting pixiv URL
-    assert get_url({"D":"M"}, "pixiv", "ID123") == "https://www.pixiv.net/en/artworks/ID123"
-    assert get_url({"A":"B"}, "pixiv", "Other") == "https://www.pixiv.net/en/artworks/Other"
+    assert mm_meta_reader.get_url({"D":"M"}, "pixiv", "ID123") == "https://www.pixiv.net/en/artworks/ID123"
+    assert mm_meta_reader.get_url({"A":"B"}, "pixiv", "Other") == "https://www.pixiv.net/en/artworks/Other"
     # Test when there is no URL
-    assert get_url({"no":"url"}) is None
+    assert mm_meta_reader.get_url({"no":"url"}) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     dictionary = {"url":"www.furaffinity.net/thing/", "id":"ID-ABC"}
     test_json = abspath(join(temp_dir, "url.json"))
-    write_json_file(test_json, dictionary)
+    mm_file_tools.write_json_file(test_json, dictionary)
     assert exists(test_json)
     # Test getting URL when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["id"] == "ID-ABC"
     assert meta["publisher"] == "Fur Affinity"
     assert meta["url"] == "https://www.furaffinity.net/view/ID-ABC/"
 
 def test_get_tags():
     """
     Tests the get_tags function.
     """
     # Test getting tags from only JSON lists
     dictionary = {"tags":["These", "are"], "categories":["some", "tags"]}
-    assert get_tags(dictionary) == ["These", "are", "some", "tags"]
+    assert mm_meta_reader.get_tags(dictionary) == ["These", "are", "some", "tags"]
     dictionary = {"categories":"blah", "tags":["New", "Tags"]}
-    assert get_tags(dictionary) == ["New", "Tags"]
+    assert mm_meta_reader.get_tags(dictionary) == ["New", "Tags"]
     # Test getting tags from only single strings
     dictionary = {"da_category":"Artwork", "theme":"Something", "thing":"other"}
-    assert get_tags(dictionary) == ["Artwork", "Something"]
+    assert mm_meta_reader.get_tags(dictionary) == ["Artwork", "Something"]
     dictionary = {"theme":234, "species":"Cat", "gender":"Female"}
-    assert get_tags(dictionary) == ["Cat", "Female"]
+    assert mm_meta_reader.get_tags(dictionary) == ["Cat", "Female"]
     # Test getting tags from internal parts of lists
     dictionary = {"tags":[{"name":"Thing"}, {"blah":"Thing"}, {"name":"other"}, {"no":"tags"}]}
-    assert get_tags(dictionary) == ["Thing", "other"]
+    assert mm_meta_reader.get_tags(dictionary) == ["Thing", "other"]
     dictionary = {"tags":[{"name":"Nope", "translated_name":"Over"}], "categories":[{"name":"blah"}, {"translated_name":"next"}]}
-    assert get_tags(dictionary) == ["Over", "blah", "next"]
+    assert mm_meta_reader.get_tags(dictionary) == ["Over", "blah", "next"]
     dictionary = {"tags":["blah"], "info":{"web_tags":["DVK", "Style", "Tags"]}}
-    assert get_tags(dictionary) == ["DVK", "Style", "Tags", "blah"]
+    assert mm_meta_reader.get_tags(dictionary) == ["DVK", "Style", "Tags", "blah"]
     # Test getting tags from multiple sources
     dictionary = {"tags":[{"name":"thing"}], "categories":["Tag", "Things"], "theme":"other", "species":["nope"]}
-    assert get_tags(dictionary) == ["thing", "Tag", "Things", "other"]
+    assert mm_meta_reader.get_tags(dictionary) == ["thing", "Tag", "Things", "other"]
     # Test with no tags
-    assert get_tags({"no":"tags"}) is None
-    assert get_tags({"tags":[{"nope":"nope"}]}) is None
+    assert mm_meta_reader.get_tags({"no":"tags"}) is None
+    assert mm_meta_reader.get_tags({"tags":[{"nope":"nope"}]}) is None
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     dictionary = {"tags":["These", "are", "some", "tags"]}
     test_json = abspath(join(temp_dir, "tags.json"))
-    write_json_file(test_json, dictionary)
+    mm_file_tools.write_json_file(test_json, dictionary)
     assert exists(test_json)
     # Test getting tags when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["tags"] == ["These", "are", "some", "tags"]
 
 def test_get_age_rating():
     """
     Tests the get_age_rating function.
     """
     # Test deviantart-style rating
     dictionary = {"is_mature":False, "thing":"blah"}
-    assert get_age_rating(dictionary, "DeviantArt") == "Everyone"
+    assert mm_meta_reader.get_age_rating(dictionary, "DeviantArt") == "Everyone"
     dictionary = {"is_mature":True, "mature_level":"moderate"}
-    assert get_age_rating(dictionary, "DeviantArt") == "Mature 17+"
+    assert mm_meta_reader.get_age_rating(dictionary, "DeviantArt") == "Mature 17+"
     dictionary = {"is_mature":True, "mature_level":"strict"}
-    assert get_age_rating(dictionary, "DeviantArt") == "X18+"
+    assert mm_meta_reader.get_age_rating(dictionary, "DeviantArt") == "X18+"
     dictionary = {"is_mature":True, "mature_level":"blah"}
-    assert get_age_rating(dictionary, "DeviantArt") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "DeviantArt") == "Unknown"
     dictionary = {"is_mature":"nope"}
-    assert get_age_rating(dictionary, "DeviantArt") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "DeviantArt") == "Unknown"
     dictionary = {"is_mature":True, "blah":"thing"}
-    assert get_age_rating(dictionary, "DeviantArt") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "DeviantArt") == "Unknown"
     dictionary = {"thing":False}
-    assert get_age_rating(dictionary, "DeviantArt") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "DeviantArt") == "Unknown"
     # Test Fur Affinity style ratings
     dictionary = {"rating":"General", "other":"thing"}
-    assert get_age_rating(dictionary, "Fur Affinity") == "Everyone"
+    assert mm_meta_reader.get_age_rating(dictionary, "Fur Affinity") == "Everyone"
     dictionary = {"rating":"Mature", "other":False}
-    assert get_age_rating(dictionary, "Fur Affinity") == "Mature 17+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Fur Affinity") == "Mature 17+"
     dictionary = {"3":True, "rating":"Adult"}
-    assert get_age_rating(dictionary, "Fur Affinity") == "X18+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Fur Affinity") == "X18+"
     dictionary = {"rating":"Who Knows?"}
-    assert get_age_rating(dictionary, "Fur Affinity") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Fur Affinity") == "Unknown"
     dictionary = {"thing":"Other"}
-    assert get_age_rating(dictionary, "Fur Affinity") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Fur Affinity") == "Unknown"
     # Test Inkbunny style ratings
     dictionary = {"rating_name":"General", "other":"thing"}
-    assert get_age_rating(dictionary, "Inkbunny") == "Everyone"
+    assert mm_meta_reader.get_age_rating(dictionary, "Inkbunny") == "Everyone"
     dictionary = {"rating_name":"Mature", "other":False}
-    assert get_age_rating(dictionary, "Inkbunny") == "Mature 17+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Inkbunny") == "Mature 17+"
     dictionary = {"3":True, "rating_name":"Adult"}
-    assert get_age_rating(dictionary, "Inkbunny") == "X18+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Inkbunny") == "X18+"
     dictionary = {"rating_name":"Who Knows?"}
-    assert get_age_rating(dictionary, "Inkbunny") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Inkbunny") == "Unknown"
     dictionary = {"thing":"Other"}
-    assert get_age_rating(dictionary, "Inkbunny") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Inkbunny") == "Unknown"
     # Test Newgrounds style ratings
     dictionary = {"rating":"e", "info":"other"}
-    assert get_age_rating(dictionary, "Newgrounds") == "Everyone"
+    assert mm_meta_reader.get_age_rating(dictionary, "Newgrounds") == "Everyone"
     dictionary = {"4":True, "rating":"T"}
-    assert get_age_rating(dictionary, "Newgrounds") == "Teen"
+    assert mm_meta_reader.get_age_rating(dictionary, "Newgrounds") == "Teen"
     dictionary = {"rating":"m", "Final":"Not"}
-    assert get_age_rating(dictionary, "Newgrounds") == "Mature 17+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Newgrounds") == "Mature 17+"
     dictionary = {"rating":"A"}
-    assert get_age_rating(dictionary, "Newgrounds") == "X18+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Newgrounds") == "X18+"
     dictionary = {"rating":"thing"}
-    assert get_age_rating(dictionary, "Newgrounds") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Newgrounds") == "Unknown"
     dictionary = {"blah":"thing"}
-    assert get_age_rating(dictionary, "Newgrounds") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Newgrounds") == "Unknown"
     # Test pixiv style ratings
     dictionary = {"rating":"General", "thing":12}
-    assert get_age_rating(dictionary, "pixiv") == "Everyone"
+    assert mm_meta_reader.get_age_rating(dictionary, "pixiv") == "Everyone"
     dictionary = {"true":False, "rating":"R-18"}
-    assert get_age_rating(dictionary, "pixiv") == "X18+"
+    assert mm_meta_reader.get_age_rating(dictionary, "pixiv") == "X18+"
     dictionary = {"rating":"blah"}
-    assert get_age_rating(dictionary, "pixiv") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "pixiv") == "Unknown"
     dictionary = {"blah":"blah"}
-    assert get_age_rating(dictionary, "pixiv") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "pixiv") == "Unknown"
     # Test Weasyl style ratings
     dictionary = {"rating":"General", "info":"other"}
-    assert get_age_rating(dictionary, "Weasyl") == "Everyone"
+    assert mm_meta_reader.get_age_rating(dictionary, "Weasyl") == "Everyone"
     dictionary = {"rating":"Mature", "Final":"Not"}
-    assert get_age_rating(dictionary, "Weasyl") == "Mature 17+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Weasyl") == "Mature 17+"
     dictionary = {"rating":"Explicit"}
-    assert get_age_rating(dictionary, "Weasyl") == "X18+"
+    assert mm_meta_reader.get_age_rating(dictionary, "Weasyl") == "X18+"
     dictionary = {"rating":"thing"}
-    assert get_age_rating(dictionary, "Weasyl") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Weasyl") == "Unknown"
     dictionary = {"blah":"thing"}
-    assert get_age_rating(dictionary, "Weasyl") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Weasyl") == "Unknown"
     # Test with invalid Publisher
     dictionary = {"rating":"General"}
-    assert get_age_rating(dictionary, "NotRecognized") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "NotRecognized") == "Unknown"
     dictionary = {"rating":"mature"}
-    assert get_age_rating(dictionary, "Other") == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, "Other") == "Unknown"
     dictionary = {"rating":"mature"}
-    assert get_age_rating(dictionary, None) == "Unknown"
+    assert mm_meta_reader.get_age_rating(dictionary, None) == "Unknown"
     # Create JSON to load
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     dictionary = {"url":"www.furaffinity.net/thing/", "rating":"Mature"}
     test_json = abspath(join(temp_dir, "url.json"))
-    write_json_file(test_json, dictionary)
+    mm_file_tools.write_json_file(test_json, dictionary)
     assert exists(test_json)
     # Test getting age rating when read directly from JSON
-    meta = load_metadata(test_json)
+    meta = mm_meta_reader.load_metadata(test_json)
     assert meta["json_path"] == test_json
     assert meta["publisher"] == "Fur Affinity"
     assert meta["age_rating"] == "Mature 17+"
```

## metadata_magic/test/rename/test_meta_rename.py

```diff
@@ -1,212 +1,208 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_archive import create_cbz
-from metadata_magic.main.rename.meta_rename import get_filename_from_metadata
-from metadata_magic.main.rename.meta_rename import rename_cbz_files
-from metadata_magic.main.rename.meta_rename import rename_json_pairs
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import write_json_file
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import listdir, mkdir, remove
+import os
+import shutil
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.rename.meta_rename as mm_meta_rename
+import metadata_magic.archive.comic_archive as mm_comic_archive
 from os.path import abspath, exists, join
-from shutil import copy
 
 def test_rename_cbz_files():
     """
     Tests the rename_cbz_files() function
     """
     # Write test media files
-    temp_dir = get_temp_dir("dvk_meta_cbz")
+    temp_dir = mm_file_tools.get_temp_dir("dvk_meta_cbz")
     sub_dir_1 = abspath(join(temp_dir, "sub1"))
     sub_dir_2 = abspath(join(temp_dir, "sub2"))
-    mkdir(sub_dir_1)
-    mkdir(sub_dir_2)
+    os.mkdir(sub_dir_1)
+    os.mkdir(sub_dir_2)
     text_file_1 = abspath(join(sub_dir_1, "file1.txt"))
     text_file_2 = abspath(join(sub_dir_2, "file2.txt"))
-    write_text_file(text_file_1, "Some Text.")
-    write_text_file(text_file_2, "Some Text.")
+    mm_file_tools.write_text_file(text_file_1, "Some Text.")
+    mm_file_tools.write_text_file(text_file_2, "Some Text.")
     assert exists(text_file_1)
     assert exists(text_file_2)
-    metadata1 = get_empty_metadata()
-    metadata2 = get_empty_metadata()
+    metadata1 = mm_meta_reader.get_empty_metadata()
+    metadata2 = mm_meta_reader.get_empty_metadata()
     metadata1["title"] = "Some Name"
     metadata1["artist"] = "Person"
     metadata1["date"] = "2020-05-30"
     metadata2["title"] = "Thing"
     metadata2["writer"] = "Dude"
     metadata2["date"] = "2018-11-15"
-    cbz1 = create_cbz(sub_dir_1, metadata=metadata1, remove_files=True)
-    cbz2 = create_cbz(sub_dir_2, metadata=metadata2, remove_files=True)
+    cbz1 = mm_comic_archive.create_cbz(sub_dir_1, metadata=metadata1, remove_files=True)
+    cbz2 = mm_comic_archive.create_cbz(sub_dir_2, metadata=metadata2, remove_files=True)
     assert exists(cbz1)
     assert exists(cbz2)
     # Test renaming cbz files
-    rename_cbz_files(temp_dir)
-    assert sorted(listdir(sub_dir_1)) == ["Some Name.cbz"]
-    assert sorted(listdir(sub_dir_2)) == ["Thing.cbz"]
+    mm_meta_rename.rename_cbz_files(temp_dir)
+    assert sorted(os.listdir(sub_dir_1)) == ["Some Name.cbz"]
+    assert sorted(os.listdir(sub_dir_2)) == ["Thing.cbz"]
     # Test renaming with added artist
-    rename_cbz_files(temp_dir, add_artist=True)
-    assert sorted(listdir(sub_dir_1)) == ["[Person] Some Name.cbz"]
-    assert sorted(listdir(sub_dir_2)) == ["[Dude] Thing.cbz"]
+    mm_meta_rename.rename_cbz_files(temp_dir, add_artist=True)
+    assert sorted(os.listdir(sub_dir_1)) == ["[Person] Some Name.cbz"]
+    assert sorted(os.listdir(sub_dir_2)) == ["[Dude] Thing.cbz"]
     # Test renaming with added date
-    rename_cbz_files(temp_dir, add_date=True)
-    assert sorted(listdir(sub_dir_1)) == ["[2020-05-30] Some Name.cbz"]
-    assert sorted(listdir(sub_dir_2)) == ["[2018-11-15] Thing.cbz"]
+    mm_meta_rename.rename_cbz_files(temp_dir, add_date=True)
+    assert sorted(os.listdir(sub_dir_1)) == ["[2020-05-30] Some Name.cbz"]
+    assert sorted(os.listdir(sub_dir_2)) == ["[2018-11-15] Thing.cbz"]
     # Test renaming with no title
-    new_metadata = get_empty_metadata()
-    new_cbz = create_cbz(temp_dir, metadata=new_metadata)
-    rename_cbz_files(temp_dir)
-    assert sorted(listdir(temp_dir)) == ["dvk_meta_cbz.cbz", "sub1", "sub2"]
+    new_metadata = mm_meta_reader.get_empty_metadata()
+    new_cbz = mm_comic_archive.create_cbz(temp_dir, metadata=new_metadata)
+    mm_meta_rename.rename_cbz_files(temp_dir)
+    assert sorted(os.listdir(temp_dir)) == ["dvk_meta_cbz.cbz", "sub1", "sub2"]
     # Test renaming files with identical names
     cbz1 = abspath(join(sub_dir_1, "Some Name.cbz"))
-    copy(cbz1, abspath(join(sub_dir_1, "newer_cbz.cbz")))
-    rename_cbz_files(temp_dir)
-    assert sorted(listdir(sub_dir_1)) == ["Some Name-2.cbz", "Some Name.cbz"]
+    shutil.copy(cbz1, abspath(join(sub_dir_1, "newer_cbz.cbz")))
+    mm_meta_rename.rename_cbz_files(temp_dir)
+    assert sorted(os.listdir(sub_dir_1)) == ["Some Name-2.cbz", "Some Name.cbz"]
 
 def test_rename_json_pairs():
     """
     Tests the rename_json_pairs function.
     """
     # Write test media files
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     image_file = abspath(join(temp_dir, "image.png"))
-    write_text_file(image_file, "Test")
+    mm_file_tools.write_text_file(image_file, "Test")
     text_file = abspath(join(temp_dir, "text.txt"))
-    write_text_file(text_file, "Test")
+    mm_file_tools.write_text_file(text_file, "Test")
     assert exists(image_file)
     assert exists(text_file)
     # Write test JSONS
     image_json = abspath(join(temp_dir, "image.json"))
-    write_json_file(image_json, {"title":"Picture!", "artist":"Person", "index":"abc", "date":"2020-01-01"})
+    mm_file_tools.write_json_file(image_json, {"title":"Picture!", "artist":"Person", "index":"abc", "date":"2020-01-01"})
     text_json = abspath(join(temp_dir, "text.json"))
-    write_json_file(text_json, {"title":"Totally Text", "artist":"Other", "id":"1234", "date":"2019-10-31"})
+    mm_file_tools.write_json_file(text_json, {"title":"Totally Text", "artist":"Other", "id":"1234", "date":"2019-10-31"})
     assert exists(image_json)
     assert exists(text_json)
     # Test renaming files
-    rename_json_pairs(temp_dir)
-    files = sorted(listdir(temp_dir))
+    mm_meta_rename.rename_json_pairs(temp_dir)
+    files = sorted(os.listdir(temp_dir))
     assert len(files) == 4
     assert files[0] == "Picture!.json"
     assert files[1] == "Picture!.png"
     assert files[2] == "Totally Text.json"
     assert files[3] == "Totally Text.txt"
     # Test renaming with added ID
-    rename_json_pairs(temp_dir, add_id=True)
-    files = sorted(listdir(temp_dir))
+    mm_meta_rename.rename_json_pairs(temp_dir, add_id=True)
+    files = sorted(os.listdir(temp_dir))
     assert len(files) == 4
     assert files[0] == "[1234] Totally Text.json"
     assert files[1] == "[1234] Totally Text.txt"
     assert files[2] == "[abc] Picture!.json"
     assert files[3] == "[abc] Picture!.png"
     # Test renaming with added Artist
-    rename_json_pairs(temp_dir, add_artist=True)
-    files = sorted(listdir(temp_dir))
+    mm_meta_rename.rename_json_pairs(temp_dir, add_artist=True)
+    files = sorted(os.listdir(temp_dir))
     assert len(files) == 4
     assert files[0] == "[Other] Totally Text.json"
     assert files[1] == "[Other] Totally Text.txt"
     assert files[2] == "[Person] Picture!.json"
     assert files[3] == "[Person] Picture!.png"
     # Test renaming with added Date
-    rename_json_pairs(temp_dir, add_date=True)
-    files = sorted(listdir(temp_dir))
+    mm_meta_rename.rename_json_pairs(temp_dir, add_date=True)
+    files = sorted(os.listdir(temp_dir))
     assert len(files) == 4
     assert files[0] == "[2019-10-31] Totally Text.json"
     assert files[1] == "[2019-10-31] Totally Text.txt"
     assert files[2] == "[2020-01-01] Picture!.json"
     assert files[3] == "[2020-01-01] Picture!.png"
     # Test renaming files with no title field
     new_file = abspath(join(temp_dir, "final.txt"))
     new_json = abspath(join(temp_dir, "final.txt.json"))
-    write_text_file(new_file, "Test")
-    write_json_file(new_json, {"thing":"other"})
+    mm_file_tools.write_text_file(new_file, "Test")
+    mm_file_tools.write_json_file(new_json, {"thing":"other"})
     assert exists(new_file)
     assert exists(new_json)
-    rename_json_pairs(temp_dir)
-    files = sorted(listdir(temp_dir))
+    mm_meta_rename.rename_json_pairs(temp_dir)
+    files = sorted(os.listdir(temp_dir))
     assert len(files) == 6
     assert files[0] == "Picture!.json"
     assert files[1] == "Picture!.png"
     assert files[2] == "Totally Text.json"
     assert files[3] == "Totally Text.txt"
     assert files[4] == "final.json"
     assert files[5] == "final.txt"
     # Test renaming files with identical names
     new_json = abspath(join(temp_dir, "Totally Text.json"))
-    write_json_file(new_json, {"title":"final"})
-    rename_json_pairs(temp_dir)
-    files = sorted(listdir(temp_dir))
+    mm_file_tools.write_json_file(new_json, {"title":"final"})
+    mm_meta_rename.rename_json_pairs(temp_dir)
+    files = sorted(os.listdir(temp_dir))
     assert len(files) == 6
     assert files[0] == "Picture!.json"
     assert files[1] == "Picture!.png"
     assert files[2] == "final-2.json"
     assert files[3] == "final-2.txt"
     assert files[4] == "final.json"
     assert files[5] == "final.txt"
     
 def test_get_filename_from_metadata():
     """
     Tests the get_filename_from_metadata.
     """
     # Test getting filename from JSON
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     json_file = abspath(join(temp_dir, "json.json"))
-    write_json_file(json_file, {"title":"This is a title!"})
+    mm_file_tools.write_json_file(json_file, {"title":"This is a title!"})
     assert exists(json_file)
-    assert get_filename_from_metadata(json_file) == "This is a title!"
+    assert mm_meta_rename.get_filename_from_metadata(json_file) == "This is a title!"
     # Test getting filename from CBZ
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "CBZ Time"
-    cbz_file = create_cbz(temp_dir, metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(temp_dir, metadata=metadata)
     assert exists(cbz_file)
-    assert get_filename_from_metadata(cbz_file) == "CBZ Time"
+    assert mm_meta_rename.get_filename_from_metadata(cbz_file) == "CBZ Time"
     # Test getting filename with no metadata
     text_file = abspath(join(temp_dir, "Nope!.txt"))
-    write_text_file(text_file, "Some Text!")
+    mm_file_tools.write_text_file(text_file, "Some Text!")
     assert exists(text_file)
-    assert get_filename_from_metadata(text_file) == "Nope!"
+    assert mm_meta_rename.get_filename_from_metadata(text_file) == "Nope!"
     # Test adding a date
-    write_json_file(json_file, {"title":"Thing", "date":"2020-03-01"})
-    assert get_filename_from_metadata(json_file, add_date=True) == "[2020-03-01] Thing"
+    mm_file_tools.write_json_file(json_file, {"title":"Thing", "date":"2020-03-01"})
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_date=True) == "[2020-03-01] Thing"
     metadata["date"] = "2017-08-05"
-    remove(cbz_file)
-    cbz_file = create_cbz(temp_dir, metadata=metadata)
-    assert get_filename_from_metadata(cbz_file, add_date=True) == "[2017-08-05] CBZ Time"
+    os.remove(cbz_file)
+    cbz_file = mm_comic_archive.create_cbz(temp_dir, metadata=metadata)
+    assert mm_meta_rename.get_filename_from_metadata(cbz_file, add_date=True) == "[2017-08-05] CBZ Time"
     # Test adding an artist/writer
-    write_json_file(json_file, {"title":"Other", "artist":"Person"})
-    assert get_filename_from_metadata(json_file, add_artist=True) == "[Person] Other"
+    mm_file_tools.write_json_file(json_file, {"title":"Other", "artist":"Person"})
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_artist=True) == "[Person] Other"
     metadata["writer"] = "Writer"
-    remove(cbz_file)
-    cbz_file = create_cbz(temp_dir, metadata=metadata)
-    assert get_filename_from_metadata(cbz_file, add_artist=True) == "[Writer] CBZ Time"
+    os.remove(cbz_file)
+    cbz_file = mm_comic_archive.create_cbz(temp_dir, metadata=metadata)
+    assert mm_meta_rename.get_filename_from_metadata(cbz_file, add_artist=True) == "[Writer] CBZ Time"
     # Test adding an ID
-    write_json_file(json_file, {"title":"Identifier", "id":"ID12345"})
-    assert get_filename_from_metadata(json_file, add_id=True) == "[ID12345] Identifier"
+    mm_file_tools.write_json_file(json_file, {"title":"Identifier", "id":"ID12345"})
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_id=True) == "[ID12345] Identifier"
     # Test adding multiple fields
-    write_json_file(json_file, {"title":"Title", "date":"2012-12-21", "id":"ID36", "artist":"Guy"})
-    title = get_filename_from_metadata(json_file, add_id=True, add_date=True)
+    mm_file_tools.write_json_file(json_file, {"title":"Title", "date":"2012-12-21", "id":"ID36", "artist":"Guy"})
+    title = mm_meta_rename.get_filename_from_metadata(json_file, add_id=True, add_date=True)
     assert title == "[2012-12-21_ID36] Title"
-    title = get_filename_from_metadata(cbz_file, add_artist=True, add_date=True)
+    title = mm_meta_rename.get_filename_from_metadata(cbz_file, add_artist=True, add_date=True)
     assert title == "[Writer_2017-08-05] CBZ Time"
-    title = get_filename_from_metadata(json_file, add_artist=True, add_date=True)
+    title = mm_meta_rename.get_filename_from_metadata(json_file, add_artist=True, add_date=True)
     assert title == "[Guy_2012-12-21] Title"
-    title = get_filename_from_metadata(json_file, add_artist=True, add_date=True, add_id=True)
+    title = mm_meta_rename.get_filename_from_metadata(json_file, add_artist=True, add_date=True, add_id=True)
     assert title == "[Guy_2012-12-21_ID36] Title"
     # Test if date is invalid
-    write_json_file(json_file, {"title":"New", "id":"Thing"})
-    assert get_filename_from_metadata(json_file, add_date=True) == "New"
-    assert get_filename_from_metadata(json_file, add_date=True, add_id=True) == "[Thing] New"
+    mm_file_tools.write_json_file(json_file, {"title":"New", "id":"Thing"})
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_date=True) == "New"
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_date=True, add_id=True) == "[Thing] New"
     # Test if artist is invalid
-    write_json_file(json_file, {"title":"No Artist", "id":"Thing"})
-    assert get_filename_from_metadata(json_file, add_artist=True) == "No Artist"
-    assert get_filename_from_metadata(json_file, add_artist=True, add_id=True) == "[Thing] No Artist"
+    mm_file_tools.write_json_file(json_file, {"title":"No Artist", "id":"Thing"})
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_artist=True) == "No Artist"
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_artist=True, add_id=True) == "[Thing] No Artist"
     # Test if ID is invalid
-    write_json_file(json_file, {"title":"No ID", "artist":"Lad"})
-    assert get_filename_from_metadata(json_file, add_id=True) == "No ID"
-    assert get_filename_from_metadata(json_file, add_artist=True, add_id=True) == "[Lad] No ID"
+    mm_file_tools.write_json_file(json_file, {"title":"No ID", "artist":"Lad"})
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_id=True) == "No ID"
+    assert mm_meta_rename.get_filename_from_metadata(json_file, add_artist=True, add_id=True) == "[Lad] No ID"
     # Test if title is invalid
-    write_json_file(json_file, {"blah":"blah"})
-    assert get_filename_from_metadata(json_file) == "json"
+    mm_file_tools.write_json_file(json_file, {"blah":"blah"})
+    assert mm_meta_rename.get_filename_from_metadata(json_file) == "json"
     new_json = abspath(join(temp_dir, "New JSON.txt.json"))
-    write_json_file(new_json, {"no":"title"})
+    mm_file_tools.write_json_file(new_json, {"no":"title"})
     assert exists(new_json)
-    assert get_filename_from_metadata(new_json) == "New JSON"
+    assert mm_meta_rename.get_filename_from_metadata(new_json) == "New JSON"
```

## metadata_magic/test/rename/test_rename_tools.py

```diff
@@ -1,213 +1,205 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.rename.rename_tools import compare_alphanum
-from metadata_magic.main.rename.rename_tools import sort_alphanum
-from metadata_magic.main.rename.rename_tools import compare_sections
-from metadata_magic.main.rename.rename_tools import get_section
-from metadata_magic.main.rename.rename_tools import create_filename
-from metadata_magic.main.rename.rename_tools import rename_file
-from metadata_magic.main.rename.rename_tools import get_available_filename
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import read_text_file
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import pardir
+import os
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.rename.rename_tools as mm_rename_tools
 from os.path import abspath, basename, exists, join
 
 def test_get_section():
     """
     Tests the get_section_function.
     """
     # Test getting number sections
-    assert get_section("12") == "12"
-    assert get_section("123 Thing!") == "123"
-    assert get_section("1.25Words") == "1.25"
-    assert get_section("1,000 Next") == "1,000"
-    assert get_section("1,523.26!Numbers") == "1,523.26"
+    assert mm_rename_tools.get_section("12") == "12"
+    assert mm_rename_tools.get_section("123 Thing!") == "123"
+    assert mm_rename_tools.get_section("1.25Words") == "1.25"
+    assert mm_rename_tools.get_section("1,000 Next") == "1,000"
+    assert mm_rename_tools.get_section("1,523.26!Numbers") == "1,523.26"
     # Test getting non-number sections
-    assert get_section("Just text.") == "Just text."
-    assert get_section("Text, then Numbers.137") == "Text, then Numbers."
+    assert mm_rename_tools.get_section("Just text.") == "Just text."
+    assert mm_rename_tools.get_section("Text, then Numbers.137") == "Text, then Numbers."
     # Test getting section from string that has none
-    assert get_section("") == ""
+    assert mm_rename_tools.get_section("") == ""
 
 def test_compare_sections():
     """
     Tests the compare_sections function.
     """
     # Test comparing just numbers
-    assert compare_sections("25", "0025") == 0
-    assert compare_sections("1,000", "1000") == 0
-    assert compare_sections("2", "2.000") == 0
-    assert compare_sections("2", "3") == -1
-    assert compare_sections("54", "023") == 1
-    assert compare_sections("1,200", "1250") == -1
-    assert compare_sections("3,500", "3,000") == 1
-    assert compare_sections("0105.3", "105.38") == -1
-    assert compare_sections("1.5", "1.25") == 1
+    assert mm_rename_tools.compare_sections("25", "0025") == 0
+    assert mm_rename_tools.compare_sections("1,000", "1000") == 0
+    assert mm_rename_tools.compare_sections("2", "2.000") == 0
+    assert mm_rename_tools.compare_sections("2", "3") == -1
+    assert mm_rename_tools.compare_sections("54", "023") == 1
+    assert mm_rename_tools.compare_sections("1,200", "1250") == -1
+    assert mm_rename_tools.compare_sections("3,500", "3,000") == 1
+    assert mm_rename_tools.compare_sections("0105.3", "105.38") == -1
+    assert mm_rename_tools.compare_sections("1.5", "1.25") == 1
     # Test comparing just text
-    assert compare_sections("text", "text") == 0
-    assert compare_sections("abc", "def") == -1
-    assert compare_sections("test", "blah") == 1
-    assert compare_sections("un", "unfinished") == -1
-    assert compare_sections("ending", "end") == 1
+    assert mm_rename_tools.compare_sections("text", "text") == 0
+    assert mm_rename_tools.compare_sections("abc", "def") == -1
+    assert mm_rename_tools.compare_sections("test", "blah") == 1
+    assert mm_rename_tools.compare_sections("un", "unfinished") == -1
+    assert mm_rename_tools.compare_sections("ending", "end") == 1
     # Test comparing text and numbers
-    assert compare_sections("43", "text") == -1
-    assert compare_sections("other", "5.8") == 1
+    assert mm_rename_tools.compare_sections("43", "text") == -1
+    assert mm_rename_tools.compare_sections("other", "5.8") == 1
     # Test with missing sections
-    assert compare_sections("", "540") == -1
-    assert compare_sections("0", "") == 1
-    assert compare_sections("", "word") == -1
-    assert compare_sections("other", "")
+    assert mm_rename_tools.compare_sections("", "540") == -1
+    assert mm_rename_tools.compare_sections("0", "") == 1
+    assert mm_rename_tools.compare_sections("", "word") == -1
+    assert mm_rename_tools.compare_sections("other", "")
 
 def test_compare_alphanum():
     """
     Tests the compare_alphanum function.
     """
     # Test identical strings
-    assert compare_alphanum("", "") == 0
-    assert compare_alphanum("23 test", "23 test") == 0
+    assert mm_rename_tools.compare_alphanum("", "") == 0
+    assert mm_rename_tools.compare_alphanum("23 test", "23 test") == 0
     # Test comparing by number
-    assert compare_alphanum("Test 4", "  test 10") == -1
-    assert compare_alphanum("  Thing 34.5 more",  "Thing 5") == 1
-    assert compare_alphanum("14 Name 1", "14   name 3") == -1
-    assert compare_alphanum("024 thing next 5", "24 thing next 2") == 1
+    assert mm_rename_tools.compare_alphanum("Test 4", "  test 10") == -1
+    assert mm_rename_tools.compare_alphanum("  Thing 34.5 more",  "Thing 5") == 1
+    assert mm_rename_tools.compare_alphanum("14 Name 1", "14   name 3") == -1
+    assert mm_rename_tools.compare_alphanum("024 thing next 5", "24 thing next 2") == 1
     # Test comparing by text
-    assert compare_alphanum("45 abc", "45 Test") == -1
-    assert compare_alphanum("987 banana", "0987   AAA") == 1
-    assert compare_alphanum("5 Thing 65 next", "5 thing 65.0 other") == -1
-    assert compare_alphanum("5.8 next 4 zzz", " 5.80 next 4 aaa") == 1
-    assert compare_alphanum("12 thing", "12 thing next") == -1
-    assert compare_alphanum("50 other next", "050 Other") == 1
+    assert mm_rename_tools.compare_alphanum("45 abc", "45 Test") == -1
+    assert mm_rename_tools.compare_alphanum("987 banana", "0987   AAA") == 1
+    assert mm_rename_tools.compare_alphanum("5 Thing 65 next", "5 thing 65.0 other") == -1
+    assert mm_rename_tools.compare_alphanum("5.8 next 4 zzz", " 5.80 next 4 aaa") == 1
+    assert mm_rename_tools.compare_alphanum("12 thing", "12 thing next") == -1
+    assert mm_rename_tools.compare_alphanum("50 other next", "050 Other") == 1
     # Test comparing that with identical sections
-    assert compare_alphanum("AAA", "aaa") == -1
-    assert compare_alphanum("1.0", "1") == 1
+    assert mm_rename_tools.compare_alphanum("AAA", "aaa") == -1
+    assert mm_rename_tools.compare_alphanum("1.0", "1") == 1
 
 def test_sort_alphanum():
     """
     Tests the sort_alphanum function.
     """
     lst = ["test 10", "test 1", "test 003", "3.5", "06 Next", "middle"]
-    sort = sort_alphanum(lst)
+    sort = mm_rename_tools.sort_alphanum(lst)
     assert sort == ["3.5", "06 Next", "middle", "test 1", "test 003", "test 10"]
 
 def test_create_filename():
     """
     Tests the create_filename function.
     """
     # Test replacing invalid characters
-    assert create_filename("**What?!?!") == "What-!-!"
-    assert create_filename(".This:That") == "This - That"
-    assert create_filename("Blah...") == "Blah…"
-    assert create_filename("<\"This/That\\Other\">") == "This-That-Other"
-    assert create_filename("(A|||B)") == "(A-B)"
-    assert create_filename("...Mr. Roboto.") == "…Mr. Roboto"
-    assert create_filename(" This    &    That ") == "This & That"
-    assert create_filename("thing--stuff  @*-   blah") == "thing-stuff @ blah"
-    assert create_filename("This..") == "This"
-    assert create_filename("..Dots.....") == "Dots…"
-    assert create_filename("Spaced .  .   .") == "Spaced …"
-    assert create_filename("  This is the end >.<  ") == "This is the end"
-    assert create_filename(" No, THIS is the end. -.-.. ") == "No, THIS is the end"
-    assert create_filename("A -> B") == "A to B"
-    assert create_filename("Thing ----> Other") == "Thing to Other"
+    assert mm_rename_tools.create_filename("**What?!?!") == "What-!-!"
+    assert mm_rename_tools.create_filename(".This:That") == "This - That"
+    assert mm_rename_tools.create_filename("Blah...") == "Blah…"
+    assert mm_rename_tools.create_filename("<\"This/That\\Other\">") == "This-That-Other"
+    assert mm_rename_tools.create_filename("(A|||B)") == "(A-B)"
+    assert mm_rename_tools.create_filename("...Mr. Roboto.") == "…Mr. Roboto"
+    assert mm_rename_tools.create_filename(" This    &    That ") == "This & That"
+    assert mm_rename_tools.create_filename("thing--stuff  @*-   blah") == "thing-stuff @ blah"
+    assert mm_rename_tools.create_filename("This..") == "This"
+    assert mm_rename_tools.create_filename("..Dots.....") == "Dots…"
+    assert mm_rename_tools.create_filename("Spaced .  .   .") == "Spaced …"
+    assert mm_rename_tools.create_filename("  This is the end >.<  ") == "This is the end"
+    assert mm_rename_tools.create_filename(" No, THIS is the end. -.-.. ") == "No, THIS is the end"
+    assert mm_rename_tools.create_filename("A -> B") == "A to B"
+    assert mm_rename_tools.create_filename("Thing ----> Other") == "Thing to Other"
     # Test removing hanging hyphens.
-    assert create_filename("Blah!- Thing") == "Blah! Thing"
-    assert create_filename("Other23- Item") == "Other23 Item"
-    assert create_filename("First -!Next") == "First !Next"
-    assert create_filename("None -Next") == "None Next"
+    assert mm_rename_tools.create_filename("Blah!- Thing") == "Blah! Thing"
+    assert mm_rename_tools.create_filename("Other23- Item") == "Other23 Item"
+    assert mm_rename_tools.create_filename("First -!Next") == "First !Next"
+    assert mm_rename_tools.create_filename("None -Next") == "None Next"
     # Test converting from non-standard latin characters
-    assert create_filename("ÀÁÂÃÄÅ") == "AAAAAA"
-    assert create_filename("ÈÉÊË") == "EEEE"
-    assert create_filename("ÌÍÎÏ") == "IIII"
-    assert create_filename("ÑÒÓÔÕÖ") == "NOOOOO"
-    assert create_filename("ÙÚÛÜÝ") == "UUUUY"
-    assert create_filename("àáâãäå") == "aaaaaa"
-    assert create_filename("èéêë") == "eeee"
-    assert create_filename("ìíîï") == "iiii"
-    assert create_filename("ñòóôõö") == "nooooo"
-    assert create_filename("ùúûüýÿ") == "uuuuyy"
+    assert mm_rename_tools.create_filename("ÀÁÂÃÄÅ") == "AAAAAA"
+    assert mm_rename_tools.create_filename("ÈÉÊË") == "EEEE"
+    assert mm_rename_tools.create_filename("ÌÍÎÏ") == "IIII"
+    assert mm_rename_tools.create_filename("ÑÒÓÔÕÖ") == "NOOOOO"
+    assert mm_rename_tools.create_filename("ÙÚÛÜÝ") == "UUUUY"
+    assert mm_rename_tools.create_filename("àáâãäå") == "aaaaaa"
+    assert mm_rename_tools.create_filename("èéêë") == "eeee"
+    assert mm_rename_tools.create_filename("ìíîï") == "iiii"
+    assert mm_rename_tools.create_filename("ñòóôõö") == "nooooo"
+    assert mm_rename_tools.create_filename("ùúûüýÿ") == "uuuuyy"
     # Test getting filename with no length
-    assert create_filename("") == "0"
-    assert create_filename("---") == "0"
+    assert mm_rename_tools.create_filename("") == "0"
+    assert mm_rename_tools.create_filename("---") == "0"
 
 def test_get_available_filename():
     """
     Tests the get_available_filename function.
     """
     # Test getting filename with unacceptable characters.
-    temp_dir = get_temp_dir()
-    assert get_available_filename("a.txt", "Name?", temp_dir) == "Name.txt"
-    assert get_available_filename("b.png", ".dat", temp_dir) == "dat.png"
+    temp_dir = mm_file_tools.get_temp_dir()
+    assert mm_rename_tools.get_available_filename("a.txt", "Name?", temp_dir) == "Name.txt"
+    assert mm_rename_tools.get_available_filename("b.png", ".dat", temp_dir) == "dat.png"
     # Test getting filename if desired filename already exists
     text_file = abspath(join(temp_dir, "name.txt"))
-    write_text_file(text_file, "some text")
+    mm_file_tools.write_text_file(text_file, "some text")
     assert exists(text_file)
-    assert get_available_filename("a.txt", "name", temp_dir) == "name-2.txt"
+    assert mm_rename_tools.get_available_filename("a.txt", "name", temp_dir) == "name-2.txt"
     # Test if filename exists with a different extension
-    assert get_available_filename("b.png", "name", temp_dir) == "name.png"
+    assert mm_rename_tools.get_available_filename("b.png", "name", temp_dir) == "name.png"
     # Test if filename alternate filename is also taken
     text_file_2 = abspath(join(temp_dir, "name-2.txt"))
     text_file_3 = abspath(join(temp_dir, "name-3.txt"))
-    write_text_file(text_file_2, "more")
-    write_text_file(text_file_3, "text")
+    mm_file_tools.write_text_file(text_file_2, "more")
+    mm_file_tools.write_text_file(text_file_3, "text")
     assert exists(text_file_2)
     assert exists(text_file_3)
-    assert get_available_filename("a.txt", "name", temp_dir) == "name-4.txt"
+    assert mm_rename_tools.get_available_filename("a.txt", "name", temp_dir) == "name-4.txt"
 
 def test_rename_file():
     """
     Tests the rename_file function.
     """
     # Create test file
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     file = abspath(join(temp_dir, "file.txt"))
-    write_text_file(file, "TEST")
+    mm_file_tools.write_text_file(file, "TEST")
     assert exists(file)
     # Test renaming file
-    new_file = rename_file(file, "Name?")
+    new_file = mm_rename_tools.rename_file(file, "Name?")
     assert exists(new_file)
-    assert abspath(join(new_file, pardir)) == temp_dir
+    assert abspath(join(new_file, os.pardir)) == temp_dir
     assert basename(new_file) == "Name.txt"
     # Test renaming file to its current name
     file = new_file
     new_file = None
     assert exists(file)
-    new_file = rename_file(file, "Name??????????????")
+    new_file = mm_rename_tools.rename_file(file, "Name??????????????")
     assert exists(new_file)
     assert file == new_file
     # Test renaming file to name of existing file
     file = abspath(join(temp_dir, "totally_new.txt"))
-    write_text_file(file, "NEW!")
+    mm_file_tools.write_text_file(file, "NEW!")
     assert exists(file)
-    new_file = rename_file(file, "Name")
+    new_file = mm_rename_tools.rename_file(file, "Name")
     assert exists(new_file)
-    assert abspath(join(new_file, pardir)) == temp_dir
+    assert abspath(join(new_file, os.pardir)) == temp_dir
     assert basename(new_file) == "Name-2.txt"
     # Test renaming same filename but different extension
     file = abspath(join(temp_dir, "Weeee!.png"))
-    write_text_file(file, "Not Actually PNG.")
+    mm_file_tools.write_text_file(file, "Not Actually PNG.")
     assert exists(file)
-    new_file = rename_file(file, ":Name:")
+    new_file = mm_rename_tools.rename_file(file, ":Name:")
     assert exists(new_file)
-    assert abspath(join(new_file, pardir)) == temp_dir
+    assert abspath(join(new_file, os.pardir)) == temp_dir
     assert basename(new_file) == "Name.png"
     # Test renaming a third time
     file = abspath(join(temp_dir, "next.txt"))
-    write_text_file(file, "Next")
+    mm_file_tools.write_text_file(file, "Next")
     assert exists(file)
-    new_file = rename_file(file, ":Name:")
+    new_file = mm_rename_tools.rename_file(file, ":Name:")
     assert exists(new_file)
-    assert abspath(join(new_file, pardir)) == temp_dir
+    assert abspath(join(new_file, os.pardir)) == temp_dir
     assert basename(new_file) == "Name-3.txt"
     # Test that renamed files still contain the correct data
     file = abspath(join(temp_dir, "Name.txt"))
-    assert read_text_file(file) == "TEST"
+    assert mm_file_tools.read_text_file(file) == "TEST"
     file = abspath(join(temp_dir, "Name-2.txt"))
-    assert read_text_file(file) == "NEW!"
+    assert mm_file_tools.read_text_file(file) == "NEW!"
     file = abspath(join(temp_dir, "Name.png"))
-    assert read_text_file(file) == "Not Actually PNG."
+    assert mm_file_tools.read_text_file(file) == "Not Actually PNG."
     file = abspath(join(temp_dir, "Name-3.txt"))
-    assert read_text_file(file) == "Next"
+    assert mm_file_tools.read_text_file(file) == "Next"
     # Test renaming invalid file
     file = abspath(join(temp_dir, "non-existant.txt"))
-    new_file = rename_file(file, "new")
+    new_file = mm_rename_tools.rename_file(file, "new")
     assert new_file is None
```

## metadata_magic/test/rename/test_sort_rename.py

```diff
@@ -1,126 +1,125 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.rename.sort_rename import sort_rename
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import listdir, mkdir
+import os
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.rename.sort_rename as mm_sort_rename
 from os.path import abspath, exists, isdir, join
 
 def test_sort_rename():
     """
     Tests the sort_rename function.
     """
     # Create test files
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     unlinked1 = abspath(join(temp_dir, "Unlinked 01.txt"))
     unlinked2 = abspath(join(temp_dir, "Unlinked 10.png"))
     unlinked3 = abspath(join(temp_dir, "Unlinked 120.jpg"))
-    write_text_file(unlinked1, "TEXT")
-    write_text_file(unlinked2, "TEXT")
-    write_text_file(unlinked3, "TEXT")
+    mm_file_tools.write_text_file(unlinked1, "TEXT")
+    mm_file_tools.write_text_file(unlinked2, "TEXT")
+    mm_file_tools.write_text_file(unlinked3, "TEXT")
     assert exists(unlinked1)
     assert exists(unlinked2)
     assert exists(unlinked3)
     # Test sorting unlinked files
-    sort_rename(temp_dir, "Renamed")
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "Renamed")
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 3
     assert filenames[0] == "Renamed 1.txt"
     assert filenames[1] == "Renamed 2.png"
     assert filenames[2] == "Renamed 3.jpg"
     # Create test JSON files
     json1 = abspath(join(temp_dir, "Renamed 1.json"))
     json2 = abspath(join(temp_dir, "Renamed 2.png.json"))
     json3 = abspath(join(temp_dir, "Renamed 3.json"))
-    write_text_file(json1, "JSON")
-    write_text_file(json2, "JSON")
-    write_text_file(json3, "JSON")
+    mm_file_tools.write_text_file(json1, "JSON")
+    mm_file_tools.write_text_file(json2, "JSON")
+    mm_file_tools.write_text_file(json3, "JSON")
     assert exists(json1)
     assert exists(json2)
     assert exists(json3)
     # Test sorting json-media pairs
-    sort_rename(temp_dir, "Paired!")
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "Paired!")
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 6
     assert filenames[0] == "Paired! 1.json"
     assert filenames[1] == "Paired! 1.txt"
     assert filenames[2] == "Paired! 2.json"
     assert filenames[3] == "Paired! 2.png"
     assert filenames[4] == "Paired! 3.jpg"
     assert filenames[5] == "Paired! 3.json"
     # Create more unlinked media
     unlinked1 = abspath(join(temp_dir, "Paired! 2.5.json"))
     unlinked2 = abspath(join(temp_dir, "Unlinked.zip"))
-    write_text_file(unlinked1, "TEST")
-    write_text_file(unlinked2, "TEST")
+    mm_file_tools.write_text_file(unlinked1, "TEST")
+    mm_file_tools.write_text_file(unlinked2, "TEST")
     assert exists(unlinked1)
     assert exists(unlinked2)
     # Test sorting combination of json pairs and standalone media
-    sort_rename(temp_dir, "combined")
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "combined")
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 8
     assert filenames[0] == "combined 1.json"
     assert filenames[1] == "combined 1.txt"
     assert filenames[2] == "combined 2.json"
     assert filenames[3] == "combined 2.png"
     assert filenames[4] == "combined 3.json"
     assert filenames[5] == "combined 4.jpg"
     assert filenames[6] == "combined 4.json"
     assert filenames[7] == "combined 5.zip"
     # Test number replacement
-    sort_rename(temp_dir, "[##] Thing")
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "[##] Thing")
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 8
     assert filenames[0] == "[01] Thing.json"
     assert filenames[1] == "[01] Thing.txt"
     assert filenames[2] == "[02] Thing.json"
     assert filenames[3] == "[02] Thing.png"
     assert filenames[4] == "[03] Thing.json"
     assert filenames[5] == "[04] Thing.jpg"
     assert filenames[6] == "[04] Thing.json"
     assert filenames[7] == "[05] Thing.zip"
     # Test number replacement when starting past 1
-    sort_rename(temp_dir, "New - P### - #2", 12)
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "New - P### - #2", 12)
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 8
     assert filenames[0] == "New - P012 - #2.json"
     assert filenames[1] == "New - P012 - #2.txt"
     assert filenames[2] == "New - P013 - #2.json"
     assert filenames[3] == "New - P013 - #2.png"
     assert filenames[4] == "New - P014 - #2.json"
     assert filenames[5] == "New - P015 - #2.jpg"
     assert filenames[6] == "New - P015 - #2.json"
     assert filenames[7] == "New - P016 - #2.zip"
-    sort_rename(temp_dir, "Different", 3)
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "Different", 3)
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 8
     assert filenames[0] == "Different 3.json"
     assert filenames[1] == "Different 3.txt"
     assert filenames[2] == "Different 4.json"
     assert filenames[3] == "Different 4.png"
     assert filenames[4] == "Different 5.json"
     assert filenames[5] == "Different 6.jpg"
     assert filenames[6] == "Different 6.json"
     assert filenames[7] == "Different 7.zip"
     # Test when directories are included
     directory1 = abspath(join(temp_dir, "AAA"))
     directory2 = abspath(join(temp_dir, "Sub"))
     directory3 = abspath(join(temp_dir, "different 5"))
-    mkdir(directory1)
-    mkdir(directory2)
-    mkdir(directory3)
+    os.mkdir(directory1)
+    os.mkdir(directory2)
+    os.mkdir(directory3)
     assert exists(directory1)
     assert exists(directory2)
     assert exists(directory3)
     assert isdir(directory1)
     assert isdir(directory2)
     assert isdir(directory3)
-    sort_rename(temp_dir, "Final")
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "Final")
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 11
     assert filenames[0] == "AAA"
     assert filenames[1] == "Final 1.json"
     assert filenames[2] == "Final 1.txt"
     assert filenames[3] == "Final 2.json"
     assert filenames[4] == "Final 2.png"
     assert filenames[5] == "Final 3.json"
@@ -128,42 +127,42 @@
     assert filenames[7] == "Final 4.json"
     assert filenames[8] == "Final 5.zip"
     assert filenames[9] == "Sub"
     assert filenames[10] == "different 5"
     # Test with pairs in subdirectories
     part1 = abspath(join(directory2, "pair.json"))
     part2 = abspath(join(directory2, "pair.jpg"))
-    write_text_file(part1, "Name")
-    write_text_file(part2, "Name")
+    mm_file_tools.write_text_file(part1, "Name")
+    mm_file_tools.write_text_file(part2, "Name")
     assert exists(part1)
     assert exists(part2)
-    sort_rename(temp_dir, "Middle")
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "Middle")
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 11
     assert filenames[0] == "AAA"
     assert filenames[1] == "Middle 1.json"
     assert filenames[2] == "Middle 1.txt"
     assert filenames[3] == "Middle 2.json"
     assert filenames[4] == "Middle 2.png"
     assert filenames[5] == "Middle 3.json"
     assert filenames[6] == "Middle 4.jpg"
     assert filenames[7] == "Middle 4.json"
     assert filenames[8] == "Middle 5.zip"
     assert filenames[9] == "Sub"
     assert filenames[10] == "different 5"
     # Test that ComicInfo.xml is not renamed
-    test_dir = get_temp_dir()
+    test_dir = mm_file_tools.get_temp_dir()
     xml_file = abspath(join(temp_dir, "ComicInfo.xml"))
     other_file = abspath(join(temp_dir, "blah.txt"))
     last_file = abspath(join(temp_dir, "final.png"))
-    write_text_file(xml_file, "Not")
-    write_text_file(other_file, "Actually")
-    write_text_file(last_file, "Important")
+    mm_file_tools.write_text_file(xml_file, "Not")
+    mm_file_tools.write_text_file(other_file, "Actually")
+    mm_file_tools.write_text_file(last_file, "Important")
     assert exists(xml_file)
     assert exists(other_file)
     assert exists(last_file)
-    sort_rename(temp_dir, "Not Comic [##]")
-    filenames = sorted(listdir(temp_dir))
+    mm_sort_rename.sort_rename(temp_dir, "Not Comic [##]")
+    filenames = sorted(os.listdir(temp_dir))
     assert len(filenames) == 3
     assert filenames[0] == "ComicInfo.xml"
     assert filenames[1] == "Not Comic [01].txt"
     assert filenames[2] == "Not Comic [02].png"
```

## Comparing `metadata_magic/main/meta_finder.py` & `metadata_magic/meta_finder.py`

 * *Files 10% similar despite different names*

```diff
@@ -1,50 +1,50 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.rename.rename_tools import sort_alphanum
-from html_string_tools.main.html_string_tools import get_extension
-from os import listdir, pardir
-from os.path import abspath, basename, exists, isdir, join
-from tqdm import tqdm
+import os
+import tqdm
+import html_string_tools.html
 from typing import List
+from os.path import abspath, basename, exists, isdir, join
+from .rename import rename_tools as mm_rename_tools
 
 def separate_files(path:str) -> tuple:
     """
     Returns a list of all files in a directory and sub_directories.
     Separated by JSON files and non-JSON files.
 
     :param path: Directory in which to search
     :type path: str, required
     :return: List of JSON files and non-JSONs, organized (jsons, media)
     :rtype: tuple
     """
     # Get all files in the given directory
     absolute_path = abspath(path)
-    all_files = listdir(absolute_path)
+    all_files = os.listdir(absolute_path)
     # Seperate JSON and non-JSON files
     media = []
     jsons = []
     directories = []
     for file in all_files:
         full_file = abspath(join(absolute_path, file))
-        extension = get_extension(full_file)
+        extension = html_string_tools.html.get_extension(full_file)
         if extension.lower() == ".json":
             jsons.append(full_file)
         elif not isdir(full_file):
             media.append(full_file)
         else:
             directories.append(full_file)
     # Append files in subdirectories
     for directory in directories:
         new_jsons, new_media = separate_files(directory)
         jsons.extend(new_jsons)
         media.extend(new_media)
     # Return JSON and media files separated
-    jsons = sort_alphanum(jsons)
-    media = sort_alphanum(media)
+    jsons = mm_rename_tools.sort_alphanum(jsons)
+    media = mm_rename_tools.sort_alphanum(media)
     return (jsons, media)
 
 def get_pairs(path:str) -> List[dict]:
     """
     Returns a list of media files paired with their corresponding JSON metadata file.
     Returned in dicts with "json" and "media" fields.
 
@@ -66,25 +66,25 @@
     :type media: List[str], required
     :return: List of media files paired with JSONs
     :rtype: List[dict]
     """
     # Get pairs
     pairs = []
     print("Finding JSON metadata:")
-    for file in tqdm(media):
+    for file in tqdm.tqdm(media):
         # Check if JSON with extension exists
         base = basename(file)
-        parent = abspath(join(file, pardir))
+        parent = abspath(join(file, os.pardir))
         json = abspath(join(parent, base + ".json"))
         if exists(json):
             pair = {"json": json, "media": file}
             pairs.append(pair)
             continue
         # Check if JSON without extension exists
-        extension = get_extension(file)
+        extension = html_string_tools.html.get_extension(file)
         base = base[:len(base)-len(extension)]
         json = abspath(join(parent, base + ".json"))
         if exists(json):
             pair = {"json": json, "media": file}
             pairs.append(pair)
             continue
     # Return pairs
```

## Comparing `metadata_magic/main/meta_reader.py` & `metadata_magic/meta_reader.py`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 #!/usr/bin/env python3
 
-from re import findall as re_find
-from metadata_magic.main.file_tools.file_tools import read_json_file
+import re
 from os.path import abspath
 from typing import List
+from . import file_tools as mm_file_tools
 
 def get_empty_metadata() -> dict:
     """
     Returns a dictionary with keys for multiple metadata fields, populated as None.
     """
     meta_dict = dict()
     meta_dict["title"] = None
@@ -70,15 +70,15 @@
     if value is None:
         value = get_value_from_keylist(json, keylist, str)
     # Return None if no ID value is found
     if value is None:
         return None
     # Strip out leading three letter ID tag if ID is from a DVK file
     try:
-        leader = re_find("^[A-Z]{3}[^0-9A-Z]*(?=[0-9])", value)
+        leader = re.findall("^[A-Z]{3}[^0-9A-Z]*(?=[0-9])", value)
         new_value = value[len(leader[0]):]
         value = new_value
     except (IndexError, TypeError): pass
     # Add file ID, if applicable
     file_id = get_value_from_keylist(json, [["file_id"]], str)
     if file_id is not None:
         value = f"{value}-{file_id}"
@@ -131,20 +131,20 @@
     keylist = [["date"], ["upload_date"], ["published_at"], ["info", "time"]]
     value = get_value_from_keylist(json, keylist, str)
     # Return None if no value can be found
     if value is None:
         return None
     # Format date into standard format
     regex = "(19[7-9][0-9]|2[0-1][0-9]{2})[\\-/](0[1-9]|1[0-2])[\\-/](0[1-9]|[1-2][0-9]|3[0-1])"
-    date = re_find(regex, value)
+    date = re.findall(regex, value)
     if len(date) > 0:
         year, month, day = date[0]
         return f"{year}-{month}-{day}"
     regex = "(19[7-9][0-9]|2[0-1][0-9]{2})(0[1-9]|1[0-2])(0[1-9]|[1-2][0-9]|3[0-1])"
-    date = re_find(regex, value)
+    date = re.findall(regex, value)
     if len(date) > 0:
         year, month, day = date[0]
         return f"{year}-{month}-{day}"
     return None
 
 def get_description(json:dict) -> str:
     """
@@ -311,15 +311,15 @@
     
     :param json_file: Path of the JSON file to read
     :type json_file: str, required
     :return: Dictionary containing the JSON's metadata using standardized keys
     :rtype: dict
     """
     # Load JSON into dictionary
-    json = read_json_file(json_file)
+    json = mm_file_tools.read_json_file(json_file)
     # Set the path of the JSON in the metadata
     meta_dict = {"json_path":abspath(json_file)}
     # Add internal metadata in standardized forms
     meta_dict["id"] = get_id(json)
     meta_dict["title"] = get_title(json)
     meta_dict["artist"] = get_artist(json)
     meta_dict["writer"] = meta_dict["artist"]
```

## Comparing `metadata_magic/main/comic_archive/archive_all.py` & `metadata_magic/archive/archive_all.py`

 * *Files 22% similar despite different names*

```diff
@@ -1,72 +1,74 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_finder import get_pairs
-from metadata_magic.main.comic_archive.comic_archive import create_cbz
-from metadata_magic.main.comic_archive.comic_xml import generate_info_from_jsons
-from metadata_magic.main.rename.rename_tools import get_available_filename
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from html_string_tools.main.html_string_tools import get_extension
-from argparse import ArgumentParser
-from os import getcwd, remove
+import os
+import tqdm
+import shutil
+import argparse
+import html_string_tools
+import python_print_tools.printer
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_finder as mm_meta_finder
+import metadata_magic.archive.comic_xml as mm_comic_xml
+import metadata_magic.archive.comic_archive as mm_comic_archive
+import metadata_magic.rename.rename_tools as mm_rename_tools
 from os.path import abspath, basename, exists, join
-from python_print_tools.main.python_print_tools import color_print
-from shutil import copy
-from tqdm import tqdm
+
+
 
 def archive_all(directory:str):
     """
     Attempts to turn every json-media pair into its own cbz archive.
     Only converts media pairs if they are image files.
     
     :param directory: Directory in which to archive files
     :type directory: str, required
     """
     # Get all JSON-Media pairs in the given directory
     full_directory = abspath(directory)
-    pairs = get_pairs(full_directory)
+    pairs = mm_meta_finder.get_pairs(full_directory)
     # Delete all media pairs that don't contain images
     for i in range(len(pairs)-1, -1, -1):
-        ext = get_extension(pairs[i]["media"]).lower()
+        ext = html_string_tools.html.get_extension(pairs[i]["media"]).lower()
         if not ext == ".jpg" and not ext == ".jpeg" and not ext == ".png":
             del pairs[i]
     # Run through each JSON-Media pair
-    for pair in tqdm(pairs):
+    for pair in tqdm.tqdm(pairs):
         # Copy JSON and media into temp directory
-        temp_dir = get_temp_dir("dvk_cbz_builder")
-        copy(pair["json"], abspath(join(temp_dir, basename(pair["json"]))))
-        copy(pair["media"], abspath(join(temp_dir, basename(pair["media"]))))
+        temp_dir = mm_file_tools.get_temp_dir("dvk_cbz_builder")
+        shutil.copy(pair["json"], abspath(join(temp_dir, basename(pair["json"]))))
+        shutil.copy(pair["media"], abspath(join(temp_dir, basename(pair["media"]))))
         # Get metadata from the JSON
-        metadata = generate_info_from_jsons(temp_dir)
+        metadata = mm_comic_xml.generate_info_from_jsons(temp_dir)
         # Create cbz file
-        cbz_file = create_cbz(temp_dir, metadata=metadata)
+        cbz_file = mm_comic_archive.create_cbz(temp_dir, metadata=metadata)
         assert exists(cbz_file)
         # Copy cbz to the original directory
         filename = basename(pair["json"])
         filename = filename[:len(filename) - 5]
-        filename = get_available_filename(cbz_file, filename, full_directory)
+        filename = mm_rename_tools.get_available_filename(cbz_file, filename, full_directory)
         new_cbz = abspath(join(full_directory, filename))
-        copy(cbz_file, new_cbz)
+        shutil.copy(cbz_file, new_cbz)
         assert exists(new_cbz)
         # Delete the original files
-        remove(pair["json"])
-        remove(pair["media"])
+        os.remove(pair["json"])
+        os.remove(pair["media"])
 
 def main():
     """
     Sets up the parser for archiving all JSON-image pairs.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "directory",
             help="Directory to search for media within.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     args = parser.parse_args()
     # Check that directory is valid
     directory = abspath(args.directory)
     if not exists(directory):
-        color_print("Invalid directory.", "red")
+        python_print_tools.printer.color_print("Invalid directory.", "red")
     else:
-        archive_all(directory)
+        archive_all(directory)
```

## Comparing `metadata_magic/main/comic_archive/comic_archive.py` & `metadata_magic/archive/comic_archive.py`

 * *Files 8% similar despite different names*

```diff
@@ -1,30 +1,20 @@
 #!/usr/bin/env python3
 
-from re import sub as re_sub
-from re import findall as re_find
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_xml import get_comic_xml
-from metadata_magic.main.comic_archive.comic_xml import read_comic_info
-from metadata_magic.main.comic_archive.comic_xml import generate_info_from_jsons
-from metadata_magic.main.rename.rename_tools import create_filename
-from metadata_magic.main.rename.rename_tools import get_available_filename
-from metadata_magic.main.rename.rename_tools import sort_alphanum
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import find_files_of_type
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from metadata_magic.main.file_tools.file_tools import create_zip
-from metadata_magic.main.file_tools.file_tools import extract_zip
-from metadata_magic.main.file_tools.file_tools import extract_file_from_zip
-from html_string_tools.main.html_string_tools import get_extension
-from argparse import ArgumentParser
-from os import getcwd, listdir, mkdir, remove
+import os
+import re
+import shutil
+import argparse
+import html_string_tools
+import python_print_tools.printer
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_xml as mm_comic_xml
+import metadata_magic.rename.rename_tools as mm_rename_tools
 from os.path import abspath, basename, exists, isdir, join
-from python_print_tools.main.python_print_tools import color_print
-from shutil import copy, move, rmtree
 
 def create_cbz(directory:str, name:str=None, metadata:dict=None, remove_files:bool=False) -> str:
     """
     Creates a cbz archive containing the files of a given directory.
     
     :param directory: Directory with files to archive
     :type directory: str, required
@@ -35,70 +25,71 @@
     :param remove_files: Whether to delete the files now in the archive once the CBZ is completed, defaults to False
     :type remove_files: bool, optional
     :return: Path of the newly created CBZ file
     :rtype: str
     """
     # Return None if directory is empty
     full_directory = abspath(directory)
-    if len(listdir(full_directory)) == 0:
+    if len(os.listdir(full_directory)) == 0:
         return None
     # Create CBZ filename
     filename = basename(full_directory) + ".cbz"
     if name is not None:
-        filename = create_filename(name) + ".cbz"
+        filename = mm_rename_tools.create_filename(name) + ".cbz"
     cbz_file = abspath(join(full_directory, filename))
     # Update CBZ if it already exists
     if exists(cbz_file):
         if metadata is not None:
             update_cbz_info(cbz_file, metadata)
         return cbz_file
     # Check if there are existing directories
     move_files = True
-    files = sort_alphanum(listdir(full_directory))
+    files = mm_rename_tools.sort_alphanum(os.listdir(full_directory))
     for file in files:
         if isdir(abspath(join(full_directory, file))):
             move_files = False
             break
     # Move files if required
     if move_files:
         # Create new folder to contain files
         folder_name = name
         if folder_name is None:
             try:
                 folder_name = metadata["title"]
                 assert folder_name is not None
             except (AssertionError, KeyError, TypeError):
-                folder_name = files[0][:len(files[0]) - len(get_extension(files[0]))]
-        folder_name = get_available_filename("AAAAAAAAAA", create_filename(folder_name), full_directory)
+                folder_name = files[0][:len(files[0]) - len(html_string_tools.html.get_extension(files[0]))]
+        folder_name = mm_rename_tools.create_filename(folder_name)
+        folder_name = mm_rename_tools.get_available_filename("AAAAAAAAAA", folder_name, full_directory)
         new_folder = abspath(join(full_directory, folder_name))
-        mkdir(new_folder)
+        os.mkdir(new_folder)
         # Move existing files to the new folder
         for file in files:
             if not file == "ComicInfo.xml":
                 current_file = abspath(join(full_directory, file))
                 new_file = abspath(join(new_folder, file))
-                move(current_file, new_file)
+                shutil.move(current_file, new_file)
     # Create metadata file, if specified
     meta_file = abspath(join(full_directory, "ComicInfo.xml"))
     if metadata is not None:
-        write_text_file(meta_file, get_comic_xml(metadata))
+        mm_file_tools.write_text_file(meta_file, mm_comic_xml.get_comic_xml(metadata))
     # Create cbz file
-    assert create_zip(full_directory, cbz_file)
+    assert mm_file_tools.create_zip(full_directory, cbz_file)
     # Remove all old files besides the CBZ, if specified.
     if remove_files:
-        files = listdir(full_directory)
+        files = os.listdir(full_directory)
         for file in files:
             full_file = abspath(join(full_directory, file))
             if isdir(full_file):
-                rmtree(full_file)
+                shutil.rmtree(full_file)
             elif not full_file == cbz_file:
-                remove(full_file)
+                os.remove(full_file)
     # Remove ComicInfo.xml file, if exists
     if exists(meta_file):
-        remove(meta_file)
+        os.remove(meta_file)
     # Return CBZ file
     return cbz_file
 
 def get_info_from_cbz(cbz_file:str, check_subdirectories:bool=True) -> dict:
     """
     Extracts ComicInfo.xml from a given .cbz file and returns the metadata as a dict.
     
@@ -107,47 +98,47 @@
     :param check_subdirectories: Whether to check subdirectories for metadata file, defaults to True
     :type check_subdirectories: bool, optional
     :return: Dictionary containing metadata from the .cbz file
     :rtype: dict
     """
     # Create temporary directory
     file = abspath(cbz_file)
-    extract_dir = get_temp_dir("dvk_meta_extract")
+    extract_dir = mm_file_tools.get_temp_dir("dvk_meta_extract")
     assert exists(extract_dir)
     # Extract ComicInfo.xml from given file
-    xml_file = extract_file_from_zip(cbz_file, extract_dir, "ComicInfo.xml", check_subdirectories)
+    xml_file = mm_file_tools.extract_file_from_zip(cbz_file, extract_dir, "ComicInfo.xml", check_subdirectories)
     if xml_file is None or not exists(xml_file):
-        return get_empty_metadata()
+        return mm_meta_reader.get_empty_metadata()
     # Read XML file
-    return read_comic_info(xml_file)
+    return mm_comic_xml.read_comic_info(xml_file)
 
 def update_cbz_info(cbz_file:str, metadata:dict):
     """
     Replaces the ComicInfo.xml file in a given .cbz file to reflect the given metadata
     
     :param cbz_file: Path of the .cbz file to update
     :type cbz_file: str, required
     :param metadata: Metadata to use for the new ComicInfo.xml file
     :type metadata: dict
     """
     # Extract cbz into temp file
     full_cbz_file = abspath(cbz_file)
-    temp_dir = get_temp_dir("dvk_comic_info")
-    if extract_zip(full_cbz_file, temp_dir):
+    temp_dir = mm_file_tools.get_temp_dir("dvk_comic_info")
+    if mm_file_tools.extract_zip(full_cbz_file, temp_dir):
         # Delete existing ComicInfo.xml files
-        xml_files = find_files_of_type(temp_dir, ".xml")
+        xml_files = mm_file_tools.find_files_of_type(temp_dir, ".xml")
         for xml_file in xml_files:
             if basename(xml_file) == "ComicInfo.xml":
-                remove(xml_file)
+                os.remove(xml_file)
         # Pack files into archive using new metadata
         new_cbz = create_cbz(temp_dir, name=metadata["title"], metadata=metadata)
         # Replace the old cbz file
-        remove(full_cbz_file)
-        copy(new_cbz, full_cbz_file)
-        remove(new_cbz)
+        os.remove(full_cbz_file)
+        shutil.copy(new_cbz, full_cbz_file)
+        os.remove(new_cbz)
     
 def create_comic_archive(path:str,
                 rp_description:bool=False,
                 rp_date:bool=False,
                 rp_artists:bool=False,
                 rp_publisher:bool=False,
                 rp_url:bool=False,
@@ -175,28 +166,28 @@
     :type rp_age: bool, optional
     :param rp_score: Whether to replace the score from gathered metadata, defaults to False
     :type rp_score: bool, optional
     """
     # Check if there is an existing .cbz file to update
     filename = None
     full_path = abspath(path)
-    files = listdir(full_path)
+    files = os.listdir(full_path)
     for i in range(len(files)-1,-1,-1):
         if files[i].startswith("."):
             del files[i]
-    if len(files) == 1 and get_extension(files[0]) == ".cbz":
+    if len(files) == 1 and html_string_tools.html.get_extension(files[0]) == ".cbz":
         # Get metadata from the .cbz file
         filename = files[0][:len(files[0])-4]
         metadata = get_info_from_cbz(abspath(join(full_path, files[0])))
     elif exists(abspath(join(full_path, "ComicInfo.xml"))):
         # Get metadata from ComicInfo
-        metadata = read_comic_info(abspath(join(full_path, "ComicInfo.xml")))
+        metadata = mm_comic_xml.read_comic_info(abspath(join(full_path, "ComicInfo.xml")))
     else:
         # Get metadata from any existing JSON files
-        metadata = generate_info_from_jsons(full_path)
+        metadata = mm_comic_xml.generate_info_from_jsons(full_path)
     # Remove metadata fields the user wishes to replace
     if rp_description:
         metadata["description"] = None
     if rp_date:
         metadata["date"] = None
     if rp_artists:
         metadata["artist"] = None
@@ -223,15 +214,15 @@
         description = str(input("Description: "))
         if not description == "":
             metadata["description"] = description
     # Get the date
     if metadata["date"] is None:
         date = ""
         regex = "(19[7-9][0-9]|2[0-1][0-9]{2})\\-(0[1-9]|1[0-2])\\-(0[1-9]|[1-2][0-9]|3[0-1])"
-        while len(re_find(regex, date)) == 0:
+        while len(re.findall(regex, date)) == 0:
             date = str(input("Date (YYYY-MM-DD): "))
         metadata["date"] = date
     # Get the Main Artist
     artist = metadata["artist"]
     if artist is None:
         artist = str(input("Artist: "))
         if not artist == "":
@@ -260,15 +251,15 @@
         url = str(input("URL: "))
         if not url == "":
             metadata["url"] = url
     # Get tags
     if metadata["tags"] is None:
         url = str(input("Tags: "))
         if not url == "":
-            metadata["tags"] = re_sub("\\s*,\\s*", ",", url)
+            metadata["tags"] = re.sub(r"\s*,\s*", ",", url)
     # Get age rating
     while metadata["age_rating"] is None:
         print("0) Unknown\n1) Everyone\n2) Teen\n3) Mature 17+\n4) X18+")
         age = str(input("Age Rating: "))
         if age == "0":
             metadata["age_rating"] = "Unknown"
         if age == "1":
@@ -288,21 +279,21 @@
     create_cbz(full_path, name=filename, metadata=metadata)
 
 def main():
     """
     Sets up the parser for creating a comic archive.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "path",
             help="Path to directory or existing .cbz file.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     parser.add_argument(
             "-s",
             "--summary",
             help="Use user summary instead of summary in metadata.",
             action="store_true")
     parser.add_argument(
             "-d",
@@ -339,15 +330,15 @@
             "--grade",
             help="Use user grade/score instead of score in metadata.",
             action="store_true")
     args = parser.parse_args()
     # Check that directory is valid
     path = abspath(args.path)
     if not exists(path):
-        color_print("Invalid path.", "red")
+        python_print_tools.printer.color_print("Invalid path.", "red")
     else:
         # Create the comic archive
         create_comic_archive(path,
                 rp_description=args.summary,
                 rp_date=args.date,
                 rp_artists=args.artists,
                 rp_publisher=args.publisher,
```

## Comparing `metadata_magic/main/comic_archive/comic_archive_update.py` & `metadata_magic/archive/comic_archive_update.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,50 +1,49 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_archive import get_info_from_cbz
-from metadata_magic.main.comic_archive.comic_archive import update_cbz_info
-from metadata_magic.main.file_tools.file_tools import find_files_of_type
-from argparse import ArgumentParser
-from python_print_tools.main.python_print_tools import color_print
-from os import getcwd
+import os
+import tqdm
+import argparse
+import python_print_tools.printer
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_archive as mm_comic_archive
 from os.path import abspath, exists, join
-from tqdm import tqdm
 
 def mass_update_cbzs(directory:str, metadata:dict):
     """
     Updates all the cbz files in a given directory to use new metadata.
     Uses artist, writer, cover_artist, publisher, age_rating, and score keys in a metadata dictionary.
     Any metadata fields with a value of None will be unaltered from the orignal cbz file.
     
     :param directory: Directory in which to look for cbz files, including subdirectories
     :type directory: str, required
     :param metadata: Metadata to update the cbz files with
     :type metadata: dict, required
     """
     # Get list of cbz files in the directory
-    cbz_files = find_files_of_type(directory, ".cbz")
-    for cbz_file in tqdm(cbz_files):
+    cbz_files = mm_file_tools.find_files_of_type(directory, ".cbz")
+    for cbz_file in tqdm.tqdm(cbz_files):
         # Get the existing info for the cbz file
-        new_metadata = get_info_from_cbz(cbz_file)
+        new_metadata = mm_comic_archive.get_info_from_cbz(cbz_file)
         # Update the metadata
         if metadata["artist"] is not None:
             new_metadata["artist"] = metadata["artist"]
         if metadata["writer"] is not None:
             new_metadata["writer"] = metadata["writer"]
         if metadata["cover_artist"] is not None:
             new_metadata["cover_artist"] = metadata["cover_artist"]
         if metadata["publisher"] is not None:
             new_metadata["publisher"] = metadata["publisher"]
         if metadata["age_rating"] is not None:
             new_metadata["age_rating"] = metadata["age_rating"]
         if metadata["score"] is not None:
             new_metadata["score"] = metadata["score"]
         # Update the cbz file with the new metadata
-        update_cbz_info(cbz_file, new_metadata)
+        mm_comic_archive.update_cbz_info(cbz_file, new_metadata)
 
 def user_mass_update_cbzs(path:str,
                 rp_artists:bool=False,
                 rp_publisher:bool=False,
                 rp_age:bool=False,
                 rp_score:bool=False):
     """
@@ -57,15 +56,15 @@
     :param rp_publisher: Whether to update publisher values, defaults to false
     :type rp_publisher: bool, optional
     :param rp_age: Whether to update age rating values, defaults to false
     :type rp_age: bool, optional
     :param rp_score: Whether to update scores/grades, defaults to false
     :type rp_score: bool, optional
     """
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     # Get Artists
     artist = None
     if rp_artists:
         # Get the main Artist
         artist = str(input("Artist: "))
         if not artist == "":
             metadata["artist"] = artist
@@ -109,21 +108,21 @@
     mass_update_cbzs(path, metadata)
 
 def main():
     """
     Sets up the parser for creating a comic archive.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "path",
             help="Path to directory or existing .cbz file.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     parser.add_argument(
             "-a",
             "--artists",
             help="Replace the artist values.",
             action="store_true")
     parser.add_argument(
             "-p",
@@ -140,15 +139,15 @@
             "--grade",
             help="Replace the grades/scores.",
             action="store_true")
     args = parser.parse_args()
     # Check that directory is valid
     path = abspath(args.path)
     if not exists(path):
-        color_print("Invalid path.", "red")
+        python_print_tools.printer.color_print("Invalid path.", "red")
     else:
         # Create the comic archive
         user_mass_update_cbzs(path,
                 rp_artists=args.artists,
                 rp_publisher=args.publisher,
                 rp_age=args.rating,
-                rp_score=args.grade)
+                rp_score=args.grade)
```

## Comparing `metadata_magic/main/comic_archive/comic_xml.py` & `metadata_magic/archive/comic_xml.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,20 +1,15 @@
 #!/usr/bin/env python3
 
-from re import sub as re_sub
-from xml.etree.ElementTree import indent as xml_indent
-from xml.etree.ElementTree import tostring as xml_to_string
-from xml.etree.ElementTree import parse as xml_parse
-from xml.etree.ElementTree import Element, SubElement, ParseError
-from metadata_magic.main.meta_finder import get_pairs
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.meta_reader import load_metadata
-from html_string_tools.main.html_string_tools import replace_entities
-from html_string_tools.main.html_string_tools import remove_whitespace
+import re
+import html_string_tools
+import metadata_magic.meta_finder as mm_meta_finder
+import metadata_magic.meta_reader as mm_meta_reader
 from os.path import abspath
+from xml.etree import ElementTree
 
 def get_comic_xml(metadata:dict, indent:bool=True) -> str:
     """
     Creates a ComicRack style ComicInfo XML string based on given metadata.
     
     :param metadata: Dict containing metadata to use in the XML
     :type metadata: dict, required
@@ -22,78 +17,78 @@
     :type indent: bool, optional
     :return: String with ComicRack style XML metadata
     :rtype: str
     """
     # Set the base element for a ComicInfo xml
     schemas = {"xmlns:xsi":"http://www.w3.org/2001/XMLSchema-instance"}
     schemas["xmlns:xsd"] = "http://www.w3.org/2001/XMLSchema"
-    base = Element("ComicInfo")
+    base = ElementTree.Element("ComicInfo")
     base.attrib = schemas
     # Set the title if applicable
     if metadata["title"] is not None:
-        title = SubElement(base, "Title")
+        title = ElementTree.SubElement(base, "Title")
         title.text = metadata["title"]
     # Set the series title if applicable
     if metadata["series"] is not None:
-        series = SubElement(base, "Series")
+        series = ElementTree.SubElement(base, "Series")
         series.text = metadata["series"]
     try:
         # Sets the series number if applicable
         series_number = str(float(metadata["series_number"]))
-        number = SubElement(base, "Number")
+        number = ElementTree.SubElement(base, "Number")
         number.text = series_number
         # Sets the series total if applicable
         total_number = str(int(metadata["series_total"]))
-        total = SubElement(base, "Count")
+        total = ElementTree.SubElement(base, "Count")
         total.text = total_number
     except (TypeError, ValueError): pass
     # Set description if applicable
     if metadata["description"] is not None:
-        summary = SubElement(base, "Summary")
+        summary = ElementTree.SubElement(base, "Summary")
         summary.text = metadata["description"]
     # Set the date if applicable
     if metadata["date"] is not None:
         # Set year
-        year = SubElement(base, "Year")
+        year = ElementTree.SubElement(base, "Year")
         year.text = metadata["date"][0:4]
         # Set month
-        month = SubElement(base, "Month")
+        month = ElementTree.SubElement(base, "Month")
         month.text = str(int(metadata["date"][5:7]))
         # Set day
-        day = SubElement(base, "Day")
+        day = ElementTree.SubElement(base, "Day")
         day.text = str(int(metadata["date"][8:10]))
     # Set the writer if applicable
     if metadata["writer"] is not None:
-        writer = SubElement(base, "Writer")
+        writer = ElementTree.SubElement(base, "Writer")
         writer.text = metadata["writer"]
     # Set all other artist categories if applicable
     if metadata["artist"] is not None:
-        penciller = SubElement(base, "Penciller")
-        inker = SubElement(base, "Inker")
-        colorist = SubElement(base, "Colorist")
+        penciller = ElementTree.SubElement(base, "Penciller")
+        inker = ElementTree.SubElement(base, "Inker")
+        colorist = ElementTree.SubElement(base, "Colorist")
         penciller.text = metadata["artist"]
         inker.text = metadata["artist"]
         colorist.text = metadata["artist"]
     # Set the cover artist if applicable
     if metadata["cover_artist"] is not None:
-        cover = SubElement(base, "CoverArtist")
+        cover = ElementTree.SubElement(base, "CoverArtist")
         cover.text = metadata["cover_artist"]
     # Set publisher if applicable
     if metadata["publisher"] is not None:
-        publisher = SubElement(base, "Publisher")
+        publisher = ElementTree.SubElement(base, "Publisher")
         publisher.text = metadata["publisher"]
     # Set URL if applicable
     if metadata["url"] is not None:
-        url = SubElement(base, "Web")
+        url = ElementTree.SubElement(base, "Web")
         url.text = metadata["url"]
     try:
         # Set the score
         score_number = int(metadata["score"])
         if score_number > -1 and score_number < 6:
-            score = SubElement(base, "CommunityRating")
+            score = ElementTree.SubElement(base, "CommunityRating")
             score.text = str(score_number)
     except (TypeError, ValueError): pass
     # Set tags if applicable
     tags = metadata["tags"]
     try:
         # Add score as star rating in tags
         score_number = int(metadata["score"])
@@ -103,62 +98,62 @@
                 stars = f"{stars}★"
             if tags is None or tags == "":
                 tags = stars
             else:
                 tags = f"{stars},{tags}"
     except (TypeError, ValueError): pass
     if tags is not None:
-        tag_element = SubElement(base, "Tags")
+        tag_element = ElementTree.SubElement(base, "Tags")
         tag_element.text = tags
     # Set the age rating
-    age_rating = SubElement(base, "AgeRating")
+    age_rating = ElementTree.SubElement(base, "AgeRating")
     age_rating.text = "Unknown"
     if metadata["age_rating"] is not None:
         age_rating.text = metadata["age_rating"]
     # Set indents to make the XML more readable
     if indent:
-        xml_indent(base, space="  ")
+        ElementTree.indent(base, space="  ")
     # Get xml as string
-    xml = xml_to_string(base).decode("UTF-8")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     # Return XML
     return f"<?xml version=\"1.0\"?>\n{xml}"
 
 def read_comic_info(xml_file:str) -> dict:
     """
     Reads metaata from a ComicInfo.xml file and stores it in dictionary like get_comic_xml.
     
     :param xml_file: Path of the XML file to read from
     :type xml_file: str, required
     :return: Dictionary containing ComicInfo metadata
     :rtype: dict
     """
     # Set up xml
     file = abspath(xml_file)
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     try:
-        tree = xml_parse(file)
+        tree = ElementTree.parse(file)
         base = tree.getroot()
-    except ParseError: return metadata
+    except ElementTree.ParseError: return metadata
     # Get metadata from XML
     metadata["title"] = base.findtext("Title")
     metadata["series"] = base.findtext("Series")
     metadata["series_number"] = base.findtext("Number")
     metadata["series_total"] = base.findtext("Count")
     metadata["description"] = base.findtext("Summary")
     metadata["writer"] = base.findtext("Writer")
     metadata["cover_artist"] = base.findtext("CoverArtist")
     metadata["publisher"] = base.findtext("Publisher")
     metadata["url"] = base.findtext("Web")
     metadata["age_rating"] = base.findtext("AgeRating")
     metadata["score"] = base.findtext("CommunityRating")
     # Get the tags, removing score tags if necessary
     try:
-        metadata["tags"] = re_sub("\\s*,+\\s*", ",", base.findtext("Tags"))
-        metadata["tags"] = re_sub("^\\s+|\\s+$|★{1,5},|,★{1,5}$", "", metadata["tags"])
-        metadata["tags"] = re_sub("^★{1,5}$", "", metadata["tags"])
+        metadata["tags"] = re.sub("\\s*,+\\s*", ",", base.findtext("Tags"))
+        metadata["tags"] = re.sub("^\\s+|\\s+$|★{1,5},|,★{1,5}$", "", metadata["tags"])
+        metadata["tags"] = re.sub("^★{1,5}$", "", metadata["tags"])
         if metadata["tags"] == "":
             metadata["tags"] = None
     except TypeError: metadata["tags"] = None
     # Get the main artist from XML
     metadata["artist"] = base.findtext("Penciller")
     if metadata["artist"] is None:
         metadata["artist"] = base.findtext("Colorist")
@@ -185,40 +180,40 @@
     
     :param path: Directory in which to search for JSON files
     :type path: str, required
     :return: Dictionary containing the metadata info
     :rtype: dict
     """
     # Get all the JSON pairs
-    pairs = get_pairs(path)
+    pairs = mm_meta_finder.get_pairs(path)
     # Read all JSON metadata
     json_metas = []
     for pair in pairs:
-        json_metas.append(load_metadata(pair["json"]))
+        json_metas.append(mm_meta_reader.load_metadata(pair["json"]))
     # Get first instance of JSON metadata
     try:
         main_meta = json_metas[0]
-    except IndexError: return get_empty_metadata()
+    except IndexError: return mm_meta_reader.get_empty_metadata()
     # Get most metadata from first JSON
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = main_meta["title"]
     metadata["date"] = main_meta["date"]
     metadata["writer"] = main_meta["writer"]
     metadata["artist"] = main_meta["artist"]
     metadata["cover_artist"] = main_meta["artist"]
     metadata["publisher"] = main_meta["publisher"]
     metadata["url"] = main_meta["url"]
     # Get description metadata
     description = main_meta["description"]
     if description is not None:
-        description = replace_entities(description)
-        description = re_sub("<a [^<>]*>|<\\/a[^<>]*>|<b>|<i>|</b>|</i>", "", description)
-        description = re_sub("<[^<>]*>", " ", description)
-        description = re_sub("\\s+", " ", description)
-        description = remove_whitespace(description)
+        description = html_string_tools.html.replace_entities(description)
+        description = re.sub("<a [^<>]*>|<\\/a[^<>]*>|<b>|<i>|</b>|</i>", "", description)
+        description = re.sub("<[^<>]*>", " ", description)
+        description = re.sub("\\s+", " ", description)
+        description = html_string_tools.regex.remove_whitespace(description)
     metadata["description"] = description
     # Get tag metadata
     tags = main_meta["tags"]
     if tags is not None and tags is not []:
         tag_string = tags[0]
         for i in range(1, len(tags)):
             tag_string = f"{tag_string},{tags[i]}"
```

## Comparing `metadata_magic/main/comic_archive/extract_all.py` & `metadata_magic/archive/extract_all.py`

 * *Files 26% similar despite different names*

```diff
@@ -1,16 +1,15 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.file_tools.file_tools import find_files_of_type
-from metadata_magic.main.file_tools.file_tools import extract_zip
-from argparse import ArgumentParser
-from os import getcwd, remove
-from os.path import abspath, basename, exists
-from python_print_tools.main.python_print_tools import color_print
-from tqdm import tqdm
+import os
+import tqdm
+import argparse
+import python_print_tools.printer
+import metadata_magic.file_tools as mm_file_tools
+from os.path import abspath, basename, exists, join
 
 def extract_all(directory:str, create_folders:bool=True, remove_internals:bool=True, remove_metadata:bool=False):
     """
     Extracts all CBZ archive files in a given directory.
     CBZ contents will be extracted into the directory in which they reside.
     
     :param directory: Directory in which to extract cbz archives
@@ -20,56 +19,56 @@
     :param remove_internals: Whether to remove redundant folders within the cbz when extracting, defaults to True
     :type remove_internals: bool, optional
     :param remove_metadata: Whether to remove the ComicInfo.xml file when extracting, defaults to False
     :type:remove_metadata: bool, optional
     """
     # Get a list of all the CBZ files in the given directory
     full_directory = abspath(directory)
-    cbz_files = find_files_of_type(full_directory, ".cbz")
+    cbz_files = mm_file_tools.find_files_of_type(full_directory, ".cbz")
     # Set to remove ComicInfo.xml if specified
     remove_list = []
     if remove_metadata or not create_folders:
         remove_list = ["ComicInfo.xml", "comicinfo.xml"]
     # Run through all cbz files
-    for cbz_file in tqdm(cbz_files):
+    for cbz_file in tqdm.tqdm(cbz_files):
         # Extract the cbz contents
-        extract_zip(cbz_file, full_directory, create_folders, remove_internals, remove_list)
+        mm_file_tools.extract_zip(cbz_file, full_directory, create_folders, remove_internals, remove_list)
         # Delete the original cbz file
-        remove(cbz_file)
+        os.remove(cbz_file)
 
 def main():
     """
     Sets up the parser for extracting all cbz files.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "directory",
             help="Directory to search for media within.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     parser.add_argument(
             "-d",
             "--direct_extract",
             help="Directly extracts all files without container folders",
             action="store_true")
     parser.add_argument(
             "-r",
             "--remove_metadata",
             help="Removes the ComicInfo.xml metadata",
             action="store_true")
     args = parser.parse_args()
     # Check that directory is valid
     directory = abspath(args.directory)
     if not exists(directory):
-        color_print("Invalid directory.", "red")
+        python_print_tools.printer.color_print("Invalid directory.", "red")
     else:
         # Ask whether or not to proceed
         proceed = "y"
         if args.direct_extract or args.remove_metadata:
             dir_name = basename(directory)
-            color_print("WARNING!", "red")
-            color_print(f"All comic book metadata in directory \"{dir_name}\" will be deleted!", "red")
+            python_print_tools.printer.color_print("WARNING!", "red")
+            python_print_tools.printer.color_print(f"All comic book metadata in directory \"{dir_name}\" will be deleted!", "red")
             proceed = input("Extract Comic Contents? (Y/N): ").lower()
         if proceed == "y":
-            extract_all(directory, create_folders=(not args.direct_extract), remove_internals=True, remove_metadata=args.remove_metadata)
+            extract_all(directory, create_folders=(not args.direct_extract), remove_internals=True, remove_metadata=args.remove_metadata)
```

## Comparing `metadata_magic/main/epub/epub.py` & `metadata_magic/archive/epub.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,33 +1,27 @@
 #!/usr/bin/env python3
 
-from re import sub as re_sub
-from re import findall as re_find
-from lxml.html import fromstring as html_from_string
-from lxml.etree import tostring as lxml_to_string
-from xml.etree.ElementTree import Element, SubElement
-from xml.etree.ElementTree import fromstring as xml_from_string
-from xml.etree.ElementTree import indent as xml_indent
-from xml.etree.ElementTree import tostring as xml_to_string
-from metadata_magic.main.comic_archive.comic_xml import generate_info_from_jsons
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import read_text_file
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from metadata_magic.main.rename.rename_tools import sort_alphanum
-from html_string_tools.main.html_string_tools import get_extension
-from html_string_tools.main.html_string_tools import regex_replace
-from argparse import ArgumentParser
-from os import getcwd, listdir, mkdir
+import re
+import os
+import shutil
+import zipfile
+import tqdm
+import argparse
+import lxml.html
+import lxml.etree
+import html_string_tools
+import python_print_tools.printer
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_xml as mm_comic_xml
+import metadata_magic.rename.rename_tools as mm_rename_tools
+from typing import List
+from xml.etree import ElementTree
 from os.path import abspath, basename, exists, isdir, join, relpath
-from python_print_tools.main.python_print_tools import color_print
 from PIL import Image, UnidentifiedImageError
-from shutil import copy
-from typing import List
-from tqdm import tqdm
-from zipfile import ZipFile, ZIP_DEFLATED, ZIP_STORED
 
 def newline_to_tag(lines:str) -> str:
     """
     Returns a string with number of <br/> tags equal to length of lines.
     <br/> tags are represented as "{{{br}}}" to be replaced in final XHTML.
     
     :param lines: String of new line characters
@@ -44,16 +38,16 @@
     """
     Gets an id/title for a file from the filename.
     :param file: File path or file name
     :type file: str, required
     :return: ID/title
     :rtype: str
     """
-    regex = "^\\s*\\[[^\\]]+\\]\\s*|\\s*\\.[^\\.]{1,5}$"
-    title = re_sub(regex, "", basename(file))
+    regex = r"^\s*\[[^\]]+\]\s*|\s*\.[^\.]{1,5}$"
+    title = re.sub(regex, "", basename(file))
     return title
 
 def format_xhtml(html:str, title:str, head_tags:List[dict]=[], indent:bool=True) -> str:
     """
     Creates text for an epub XHTML content file with given html string in the body
     
     :param html: String in HTML format
@@ -62,38 +56,38 @@
     :type title: str, required
     :param indent: Whether to add indents to the XHTML file, defaults to True
     :type indent: bool, optional
     :return: XHTML text
     :rtype: str
     """
     # Set the base element for the XHTML 
-    base = Element("html")
+    base = ElementTree.Element("html")
     base.attrib = {"xmlns":"http://www.w3.org/1999/xhtml"}
     # Create the head subelement
-    head = SubElement(base, "head")
-    title_element = SubElement(head, "title")
+    head = ElementTree.SubElement(base, "head")
+    title_element = ElementTree.SubElement(head, "title")
     title_element.text = title
-    meta = SubElement(head, "meta")
+    meta = ElementTree.SubElement(head, "meta")
     meta.attrib = {"charset":"utf-8"}
     # Add given elements to head
     for head_tag in head_tags:
-        head_element = SubElement(head, head_tag["type"])
+        head_element = ElementTree.SubElement(head, head_tag["type"])
         head_element.attrib = head_tag["params"]
     # Add stylesheet to head
-    link = SubElement(head, "link")
+    link = ElementTree.SubElement(head, "link")
     link.attrib = {"rel":"stylesheet", "href":"../style/epubstyle.css", "type":"text/css"}
     # Parse the given html text and add to body
-    final_html = re_sub("^\\s+|\\s+$|\\n", "", html)
-    body = xml_from_string(f"<body>{final_html}</body>")
+    final_html = re.sub("^\\s+|\\s+$|\\n", "", html)
+    body = ElementTree.fromstring(f"<body>{final_html}</body>")
     base.append(body)
     # Set indents to make the XML more readable
     if indent:
-        xml_indent(base, space="   ")
+        ElementTree.indent(base, space="   ")
     # Get xml as string
-    xml = xml_to_string(base).decode("UTF-8")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     return f"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n{xml}"
 
 def create_image_page(image_file, indent:bool=True) -> str:
     """
     Returns a epub formatted XHTML page containing a single full page image.
     
     :param image_file: Path to the image file to include on the page
@@ -106,25 +100,25 @@
     # Load image
     try:
         full_path = abspath(image_file)
         image = Image.open(full_path)
         width, height = image.size
     except (FileNotFoundError, UnidentifiedImageError): return None
     # Create image container
-    container = Element("div")
+    container = ElementTree.Element("div")
     container.attrib = {"class":"image-page-container"}
     # Create the image element
     filename = basename(full_path)
     title = get_title_from_file(full_path)
-    img_element = SubElement(container, "img")
+    img_element = ElementTree.SubElement(container, "img")
     attributes = {"class":"vertical-image-page", "src":f"../images/{filename}", "alt":title}
     if width > height:
         attributes["class"] = "horizontal-image-page"
     img_element.attrib = attributes
-    xml = xml_to_string(container).decode("UTF-8")
+    xml = ElementTree.tostring(container).decode("UTF-8")
     # Add size limited meta tag
     tag = {"type":"meta"}
     tag["params"] = {"content":f"width={width}, height={height}", "name":"viewport"}
     # Return EpubHtml
     return format_xhtml(xml, title, [tag], indent)
 
 def html_to_xhtml(html_file:str, indent:bool=False) -> str:
@@ -136,27 +130,25 @@
     :param indent: Whether to add indents to the XHTML file, defaults to True
     :type indent: bool, optional
     :return: XHTML text
     :rtype: str
     """
     # Read html file
     full_path = abspath(html_file)
-    content = read_text_file(full_path)
-    print(content)
+    content = mm_file_tools.read_text_file(full_path)
     # Parse as XML
-    root = html_from_string(content)
+    root = lxml.html.fromstring(content)
     # Extract body if necessary
     try:
         body = root.xpath("//body")[0]
-        body_text = lxml_to_string(body).decode("UTF-8")
-        print(lxml_to_string(root))
-        body_text = re_find("(?<=^<body>).+(?=<\\/body>$)", body_text)[0]
+        body_text = lxml.etree.tostring(body).decode("UTF-8")
+        body_text = re.findall("(?<=^<body>).+(?=<\\/body>$)", body_text)[0]
     except IndexError:
-        body_text = lxml_to_string(root).decode("UTF-8")
-        inner_text = re_find("(?<=^<div>).+(?=<\\/div>$)", body_text)
+        body_text = lxml.etree.tostring(root).decode("UTF-8")
+        inner_text = re.findall("(?<=^<div>).+(?=<\\/div>$)", body_text)
         if len(inner_text) == 1:
             body_text = inner_text[0]
     # Format html as xml
     body_text = f"<div class=\"text-container\">{body_text}</div>"
     return format_xhtml(body_text, get_title_from_file(full_path), indent=indent)
 
 def txt_to_xhtml(txt_file:str, indent:bool=True) -> str:
@@ -168,39 +160,39 @@
     :param indent: Whether to add indents to the XHTML file, defaults to True
     :type indent: bool, optional
     :return: XHTML text
     :rtype: str
     """
     # Read text file
     full_path = abspath(txt_file)
-    content = read_text_file(full_path)
+    content = mm_file_tools.read_text_file(full_path)
     # Replace long string of newlines
-    content = regex_replace(newline_to_tag, "\\n\\n\\n+", content)
+    content = html_string_tools.regex.regex_replace(newline_to_tag, "\\n\\n\\n+", content)
     # Split by new lines
     paragraphs = content.split("\n\n")
     # Create paragraph elements
-    text_container = Element("div")
+    text_container = ElementTree.Element("div")
     text_container.attrib = {"class":"text-container"}
     for paragraph in paragraphs:
-        p_element = SubElement(text_container, "p")
+        p_element = ElementTree.SubElement(text_container, "p")
         p_element.text = paragraph.replace("\n","{{{br}}}")
     # Get xml as string
-    xml = xml_to_string(text_container).decode("UTF-8")
+    xml = ElementTree.tostring(text_container).decode("UTF-8")
     # Remove misformatted tags
     xml = xml.replace("{{{br}}}", "<br/>")
     xml = xml.replace("{{br}}", "<br/>")
     xml = xml.replace("{{i}}", "<i>")
     xml = xml.replace("{{/i}}", "</i>")
     xml = xml.replace("{{b}}", "<b>")
     xml = xml.replace("{{/b}}", "</b>")
-    xml = re_sub("(<br\\/>|\\s)*<\\/p?>", "</p>", xml)
-    xml = re_sub("<\\/i>\\s+(?=[,.?!])", "</i>", xml)
-    xml = re_sub("<\\/b>\\s+(?=[,.?!])", "</b>", xml)
-    xml = re_sub("\\s+<\\/i>", "</i>", xml)
-    xml = re_sub("\\s+<\\/b>", "</b>", xml)
+    xml = re.sub("(<br\\/>|\\s)*<\\/p?>", "</p>", xml)
+    xml = re.sub("<\\/i>\\s+(?=[,.?!])", "</i>", xml)
+    xml = re.sub("<\\/b>\\s+(?=[,.?!])", "</b>", xml)
+    xml = re.sub("\\s+<\\/i>", "</i>", xml)
+    xml = re.sub("\\s+<\\/b>", "</b>", xml)
     # Return XHTML
     return format_xhtml(xml, get_title_from_file(full_path), indent=indent)
 
 def create_style_file(file_path:str):
     """
     Creates the default css stylesheet for the epub book.
     
@@ -249,15 +241,15 @@
     style = f"{style}}}\n\n"
     # Image Page Container
     style = f"{style}.image-page-container {{\n"
     style = f"{style}    height: 100vh;\n"
     style = f"{style}}}"
     # Create file
     full_path = abspath(file_path)
-    write_text_file(full_path, style)
+    mm_file_tools.write_text_file(full_path, style)
 
 def create_nav_file(xhtmls:List[str], file_path:str, title:str, indent:bool=True):
     """
     Creates the Table of Contents nav file for the epub file.
     
     :param xhtmls: List of XHTML files to include in the contents
     :type xhtmls: str, required
@@ -269,49 +261,49 @@
     :type indent: bool, optional
     """
     # Create base of navigation file
     attributes = {"xmlns":"http://www.w3.org/1999/xhtml"}
     attributes["xmlns:epub"] = "http://www.idpf.org/2007/ops"
     attributes["lang"] = "en"
     attributes["xml:lang"] = "en"
-    base = Element("html")
+    base = ElementTree.Element("html")
     base.attrib = attributes
     # Create navigation head
-    head = SubElement(base, "head")
-    meta = SubElement(head, "meta")
+    head = ElementTree.SubElement(base, "head")
+    meta = ElementTree.SubElement(head, "meta")
     meta.attrib = {"charset":"utf-8"}
-    title_element = SubElement(head, "title")
+    title_element = ElementTree.SubElement(head, "title")
     title_element.text = title
     # Create navigation body and header
-    body = SubElement(base, "body")
-    h1 = SubElement(body, "h1")
+    body = ElementTree.SubElement(base, "body")
+    h1 = ElementTree.SubElement(body, "h1")
     h1.text = title
     # Create nav element
-    nav = SubElement(body, "nav")
+    nav = ElementTree.SubElement(body, "nav")
     nav.attrib = {"epub:type":"toc", "id":"toc"}
-    ol = SubElement(nav, "ol")
+    ol = ElementTree.SubElement(nav, "ol")
     # Create entries for each XHTML file
     for xhtml in xhtmls:
         # Get title
         filename = basename(xhtml)
         name = get_title_from_file(filename)
         # Create list item
-        li = SubElement(ol, "li")
-        a = SubElement(li, "a")
+        li = ElementTree.SubElement(ol, "li")
+        a = ElementTree.SubElement(li, "a")
         a.text = name
         a.attrib = {"href":f"content/{filename}"}
     # Set indents to make the XML more readable
     if indent:
-        xml_indent(base, space="   ")
+        ElementTree.indent(base, space="   ")
     # Get xml as string
-    xml = xml_to_string(base).decode("UTF-8")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     xml = f"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n{xml}"
     # Write XML
     full_path = abspath(file_path)
-    write_text_file(full_path, xml)
+    mm_file_tools.write_text_file(full_path, xml)
 
 def create_ncx_file(xhtmls:List[str], file_path:str, title:str, uid:str, indent:bool=True):
     """
     Creates the Table of Contents ncx file for the epub file.
     
     :param xhtmls: List of XHTML files to include in the contents
     :type xhtmls: str, required
@@ -323,69 +315,69 @@
     :type uid: str, required
     :param indent: Whether to add indents to the XML file, defaults to True
     :type indent: bool, optional
     """
     # Create base of ncx file
     attributes = {"xmlns":"http://www.daisy.org/z3986/2005/ncx/"}
     attributes["version"] = "2005-1"
-    base = Element("ncx")
+    base = ElementTree.Element("ncx")
     base.attrib = attributes
     # Create ncx head
-    head = SubElement(base, "head")
-    uid_element = SubElement(head, "meta")
+    head = ElementTree.SubElement(base, "head")
+    uid_element = ElementTree.SubElement(head, "meta")
     uid_element.attrib = {"content":uid, "name":"dtb:uid"}
-    depth = SubElement(head, "meta")
+    depth = ElementTree.SubElement(head, "meta")
     depth.attrib = {"content":"0", "name":"dtb:depth"}
-    pcount = SubElement(head, "meta")
+    pcount = ElementTree.SubElement(head, "meta")
     pcount.attrib = {"content":"0", "name":"dtb:totalPageCount"}
-    number = SubElement(head, "meta")
+    number = ElementTree.SubElement(head, "meta")
     number.attrib = {"content":"0", "name":"dtb:maxPageNumber"}
     # Create title tag
-    title_element = SubElement(base, "docTitle")
-    title_text = SubElement(title_element, "text")
+    title_element = ElementTree.SubElement(base, "docTitle")
+    title_text = ElementTree.SubElement(title_element, "text")
     title_text.text = title
     # Create nav map
-    nav_map = SubElement(base, "navMap")
+    nav_map = ElementTree.SubElement(base, "navMap")
     for xhtml in xhtmls:
-        nav_point = SubElement(nav_map, "navPoint")
+        nav_point = ElementTree.SubElement(nav_map, "navPoint")
         nav_point.attrib = {"id":get_title_from_file(xhtml) + "-xhtml"}
-        nav_label = SubElement(nav_point, "navLabel")
-        nav_text = SubElement(nav_label, "text")
+        nav_label = ElementTree.SubElement(nav_point, "navLabel")
+        nav_text = ElementTree.SubElement(nav_label, "text")
         nav_text.text = get_title_from_file(xhtml)
-        content = SubElement(nav_point, "content")
+        content = ElementTree.SubElement(nav_point, "content")
         content.text = "content/" + str(basename(xhtml))
     # Set indents to make the XML more readable
     if indent:
-        xml_indent(base, space="   ")
+        ElementTree.indent(base, space="   ")
     # Get xml as string
-    xml = xml_to_string(base).decode("UTF-8")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     xml = f"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n{xml}"
     # Write XML
     full_path = abspath(file_path)
-    write_text_file(full_path, xml)
+    mm_file_tools.write_text_file(full_path, xml)
 
 def create_manifest(files:List[str]) -> str:
     """
     Create the manifest section for the epub package file.
     Uses all given files, and adds nav file by default.
     
     :param files: List of files to link in the manifest section
     :type files: list[str], required
     :return: Manifest section in xml format
     :rtype: str
     """
     # Create the manifest base
-    base = Element("manifest")
+    base = ElementTree.Element("manifest")
     # Add the nav file as item
-    nav_item = SubElement(base, "item")
+    nav_item = ElementTree.SubElement(base, "item")
     nav_item.attrib = {"href":"nav.xhtml", "id":"toc", "media-type":"application/xhtml+xml", "properties":"nav"}
     # Add files as items
     for file in files:
         filename = basename(file)
-        extension = get_extension(filename)
+        extension = html_string_tools.html.get_extension(filename)
         media_type = ""
         # Get the file mimetype
         if extension == ".xhtml":
             media_type = "application/xhtml+xml"
             attributes = {"href":f"content/{filename}"}
         elif extension == ".jpeg" or extension == ".jpg":
             media_type = "image/jpeg"
@@ -395,117 +387,117 @@
             attributes = {"href":f"images/{filename}"}
         elif extension == ".svg":
             media_type = "image/svg+xml"
             attributes = {"href":f"images/{filename}"}
         # Create item
         attributes["id"] = get_title_from_file(filename) + "-" + extension[1:]
         attributes["media-type"] = media_type
-        item = SubElement(base, "item")
+        item = ElementTree.SubElement(base, "item")
         item.attrib = attributes
     # Add css file
-    css_item = SubElement(base, "item")
+    css_item = ElementTree.SubElement(base, "item")
     css_item.attrib = {"href":"style/epubstyle.css", "id":"epubstyle-css", "media-type":"text/css"}
     # Get xml as string
-    xml = xml_to_string(base).decode("UTF-8")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     return xml
 
 def create_metadata_xml(metadata:dict) -> str:
     """
     Creates the metadata section for the epub package file based on given metadata.
     
     :param metadata: Metadata dict, same as given for cbz ComicInfo functions
     :type metadata: dict, required
     :return: Metadata section in xml format
     :rtype: str
     """
     # Create the metadata base
-    base = Element("metadata")
+    base = ElementTree.Element("metadata")
     base.attrib = {"xmlns:dc":"http://purl.org/dc/elements/1.1/"}
     # Set the language
-    language = SubElement(base, "dc:language")
+    language = ElementTree.SubElement(base, "dc:language")
     language.text = "en"
     # Set the identifier
-    identifier = SubElement(base, "dc:identifier")
+    identifier = ElementTree.SubElement(base, "dc:identifier")
     if metadata["url"] is not None:
         identifier.text = metadata["url"]
     else:
         identifier.text = metadata["title"].lower()
     # Set the title
-    title = SubElement(base, "dc:title")
+    title = ElementTree.SubElement(base, "dc:title")
     title.text = metadata["title"]
     # Add author(s)
     try:
         authors = metadata["writer"].split(",")
     except AttributeError: authors = []
     for i in range(0, len(authors)):
         # Add creator tag
         author_id = "author" + str(i+1)
-        creator = SubElement(base, "dc:creator")
+        creator = ElementTree.SubElement(base, "dc:creator")
         creator.attrib = {"id":author_id}
         creator.text = authors[i]
         # Add role tag
-        role = SubElement(base, "meta")
+        role = ElementTree.SubElement(base, "meta")
         role.attrib = {"refines":f"#{author_id}", "property":"role", "scheme":"marc:relators"}
         role.text = "aut"
     # Add illustrator(s)
     try:
         illustrators = metadata["artist"].split(",")
     except AttributeError: illustrators = []
     for i in range(0, len(illustrators)):
         # Add creator tag
         illustrator_id = "illustrator" + str(i+1)
-        creator = SubElement(base, "dc:creator")
+        creator = ElementTree.SubElement(base, "dc:creator")
         creator.attrib = {"id":illustrator_id}
         creator.text = illustrators[i]
         # Add role tag
-        role = SubElement(base, "meta")
+        role = ElementTree.SubElement(base, "meta")
         role.attrib = {"refines":f"#{illustrator_id}", "property":"role", "scheme":"marc:relators"}
         role.text = "ill"
     # Add cover artist(s)
     try:
         covartists = metadata["cover_artist"].split(",")
     except AttributeError: covartists = []
     for i in range(0, len(covartists)):
         # Add creator tag
         cover_id = "covartist" + str(i+1)
-        creator = SubElement(base, "dc:creator")
+        creator = ElementTree.SubElement(base, "dc:creator")
         creator.attrib = {"id":cover_id}
         creator.text = covartists[i]
         # Add role tag
-        role = SubElement(base, "meta")
+        role = ElementTree.SubElement(base, "meta")
         role.attrib = {"refines":f"#{cover_id}", "property":"role", "scheme":"marc:relators"}
         role.text = "cov"
     # Set the description
     if metadata["description"] is not None:
-        description = SubElement(base, "dc:description")
+        description = ElementTree.SubElement(base, "dc:description")
         description.text = metadata["description"]
     # Set the publisher
     if metadata["publisher"] is not None:
-        publisher = SubElement(base, "dc:publisher")
+        publisher = ElementTree.SubElement(base, "dc:publisher")
         publisher.text = metadata["publisher"]
     # Set the series info
     if metadata["series"] is not None:
-        series_title = SubElement(base, "meta")
+        series_title = ElementTree.SubElement(base, "meta")
         series_title.attrib = {"property":"belongs-to-collection", "id":"series-title"}
         series_title.text = metadata["series"]
-        collection_type = SubElement(base, "meta")
+        collection_type = ElementTree.SubElement(base, "meta")
         collection_type.attrib = {"refines":"series-title", "property":"collection-type"}
         collection_type.text = "series"
         try:
             num = float(metadata["series_number"])
-            series_number = SubElement(base, "meta")
+            series_number = ElementTree.SubElement(base, "meta")
             series_number.attrib = {"refines":"series-title", "property":"group-position"}
             series_number.text = metadata["series_number"]
         except (TypeError, ValueError): pass
     # Set the score
     tag_string = metadata["tags"]
     try:
         score = int(metadata["score"])
         if score > -1 and score < 6:
-            score_element = SubElement(base, "meta")
+            score_element = ElementTree.SubElement(base, "meta")
             score_element.attrib = {"property":"calibre:rating"}
             score_element.text = str(float(score * 2))
     except (TypeError, ValueError): pass
     # Set the tags
     tag_string = metadata["tags"]
     try:
         # Add score as star rating in tags
@@ -519,27 +511,27 @@
             else:
                 tag_string = f"{stars},{tag_string}"
     except (TypeError, ValueError): pass
     try:
         tags = tag_string.split(",")
     except AttributeError: tags = []
     for tag in tags:
-        subject = SubElement(base, "dc:subject")
+        subject = ElementTree.SubElement(base, "dc:subject")
         subject.text = tag
     # Set the date
     date = "0000-00-00T00:00:00+00:00"
     if metadata["date"] is not None:
         date = metadata["date"] + "T00:00:00+00:00"
-    modified = SubElement(base, "meta")
+    modified = ElementTree.SubElement(base, "meta")
     modified.attrib = {"property":"dcterms:modified"}
     modified.text = date
-    date_element = SubElement(base, "dc:date")
+    date_element = ElementTree.SubElement(base, "dc:date")
     date_element.text = date
     # Get xml as string
-    xml = xml_to_string(base).decode("UTF-8")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     return xml
 
 def create_epub_files(directory:str, metadata:dict):
     """
     Creates the nav.xhtml and package.opf files required for an epub archive.
     Saves files in the given directory.
     Searches for files to include in spine and manifest from ./content directory within given directory.
@@ -548,18 +540,18 @@
     :type directory: str, required
     :param metadata: Metadata to use when creating the file
     :type metadata: dict, required
     """
     # Get list of files in the content directory
     full_directory = abspath(directory)
     content_dir = abspath(join(directory, "content"))
-    content_files = sort_alphanum(listdir(content_dir))
+    content_files = mm_rename_tools.sort_alphanum(os.listdir(content_dir))
     # Get list of files in the images directory
     image_dir = abspath(join(directory, "images"))
-    image_files = sort_alphanum(listdir(image_dir))
+    image_files = mm_rename_tools.sort_alphanum(os.listdir(image_dir))
     # Get the manifest and metadata sections
     files = []
     files.extend(content_files)
     files.extend(image_files)
     manifest = create_manifest(files)
     meta_xml = create_metadata_xml(metadata)
     # Create nav file
@@ -568,53 +560,53 @@
     # Create ncx file
     uid = metadata["url"]
     if uid is None:
         uid = metadata["title"]
     ncx_file = abspath(join(full_directory, "toc.ncx"))
     create_ncx_file(content_files, ncx_file, metadata["title"], uid, True)
     # Create the content xml contents
-    base = Element("package")
+    base = ElementTree.Element("package")
     base.attrib = {"xmlns":"http://www.idpf.org/2007/opf", "unique-identifier":"uid", "version":"3.0"}
-    base.append(xml_from_string(meta_xml))
-    base.append(xml_from_string(manifest))
-    spine = SubElement(base, "spine")
+    base.append(ElementTree.fromstring(meta_xml))
+    base.append(ElementTree.fromstring(manifest))
+    spine = ElementTree.SubElement(base, "spine")
     for file in content_files:
         # Create spine items
-        itemref = SubElement(spine, "itemref")
+        itemref = ElementTree.SubElement(spine, "itemref")
         itemref.attrib = {"idref":get_title_from_file(file) + "-xhtml"}
     # Save content xml to file
-    xml_indent(base, space="   ")
-    xml = xml_to_string(base).decode("UTF-8")
+    ElementTree.indent(base, space="   ")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     xml = f"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n{xml}"
     package_file = abspath(join(full_directory, "content.opf"))
-    write_text_file(package_file, xml)
+    mm_file_tools.write_text_file(package_file, xml)
 
 def zip_epub(directory:str, epub_file):
     try:
         # Get list of files in the directory
         full_directory = abspath(directory)
-        files = listdir(full_directory)
+        files = os.listdir(full_directory)
         for i in range(0, len(files)):
             files[i] = abspath(join(full_directory, files[i]))
         # Expand list of files to include subdirectories
         for file in files:
             if isdir(file):
-                sub_files = listdir(file)
+                sub_files = os.listdir(file)
                 for i in range(0, len(sub_files)):
                     files.append(abspath(join(file, sub_files[i])))
         # Create empty epub file
-        with ZipFile(epub_file, "w", compression=ZIP_DEFLATED, compresslevel=8) as out_file:
-            out_file.writestr('mimetype', 'application/epub+zip', compress_type=ZIP_STORED)
+        with zipfile.ZipFile(epub_file, "w", compression=zipfile.ZIP_DEFLATED, compresslevel=8) as out_file:
+            out_file.writestr('mimetype', 'application/epub+zip', compress_type=zipfile.ZIP_STORED)
         assert exists(epub_file)
         # Write contents of directory to epub file
-        for file in tqdm(files):
+        for file in tqdm.tqdm(files):
             relative = relpath(file, full_directory)
-            with ZipFile(epub_file, "a", compression=ZIP_DEFLATED, compresslevel=8) as out_file:
+            with zipfile.ZipFile(epub_file, "a", compression=zipfile.ZIP_DEFLATED, compresslevel=8) as out_file:
                 if not isdir(file):
-                    out_file.write(file, relative, compress_type=ZIP_DEFLATED, compresslevel=8)
+                    out_file.write(file, relative, compress_type=zipfile.ZIP_DEFLATED, compresslevel=8)
         # Return the path of the written epub archive
         return epub_file
     except FileNotFoundError:
         return None
 
 def create_epub(directory:str, metadata:dict) -> str:
     """
@@ -627,68 +619,68 @@
     :return: Path to the newly created epub file
     :rtype: str
     """
     # Get the path of the epub file to create
     input_directory = abspath(directory)
     epub_file = abspath(join(input_directory, basename(input_directory)+".epub"))
     # Create temporary directory to save contents into
-    temp_dir = get_temp_dir("dvk-metamagic-epub")
+    temp_dir = mm_file_tools.get_temp_dir("dvk-metamagic-epub")
     # Create container
     meta_dir = abspath(join(temp_dir, "META-INF"))
-    mkdir(meta_dir)
-    base = Element("container")
+    os.mkdir(meta_dir)
+    base = ElementTree.Element("container")
     base.attrib = {"xmlns":"urn:oasis:names:tc:opendocument:xmlns:container", "version":"1.0"}
-    rootfiles = SubElement(base, "rootfiles")
-    rootfile = SubElement(rootfiles, "rootfile")
+    rootfiles = ElementTree.SubElement(base, "rootfiles")
+    rootfile = ElementTree.SubElement(rootfiles, "rootfile")
     rootfile.attrib = {"media-type":"application/oebps-package+xml", "full-path":"EPUB/content.opf"}
-    xml_indent(base, space="   ")
-    xml = xml_to_string(base).decode("UTF-8")
+    ElementTree.indent(base, space="   ")
+    xml = ElementTree.tostring(base).decode("UTF-8")
     xml = f"<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n{xml}"
     container_file = abspath(join(meta_dir, "container.xml"))
-    write_text_file(container_file, xml)
+    mm_file_tools.write_text_file(container_file, xml)
     # Get list of all contents of the given directory
-    files = listdir(input_directory)
+    files = os.listdir(input_directory)
     for i in range(0, len(files)):
         files[i] = abspath(join(input_directory, files[i]))
     # Copy all files into folder to contain all original unaltered files
     epub_folder = abspath(join(temp_dir, "EPUB"))
-    mkdir(epub_folder)
+    os.mkdir(epub_folder)
     original_folder = abspath(join(epub_folder, "original"))
-    mkdir(original_folder)
+    os.mkdir(original_folder)
     for file in files:
-        copy(file, abspath(join(original_folder, basename(file))))
+        shutil.copy(file, abspath(join(original_folder, basename(file))))
     # Create style sheet
     style_folder = abspath(join(epub_folder, "style"))
-    mkdir(style_folder)
+    os.mkdir(style_folder)
     create_style_file(abspath(join(style_folder, "epubstyle.css")))
     # Copy all images and convert all text to XHTML for the content folder
     content_folder = abspath(join(epub_folder, "content"))
-    mkdir(content_folder)
+    os.mkdir(content_folder)
     image_folder = abspath(join(epub_folder, "images"))
-    mkdir(image_folder)
+    os.mkdir(image_folder)
     for file in files:
         filename = basename(file)
-        extension = get_extension(filename)
+        extension = html_string_tools.html.get_extension(filename)
         if extension == ".txt":
             # Create text extension
             filename = filename[:len(filename) - len(extension)] + ".xhtml"
             xml = txt_to_xhtml(file, True)
-            write_text_file(abspath(join(content_folder, filename)), xml)
+            mm_file_tools.write_text_file(abspath(join(content_folder, filename)), xml)
         if extension == ".html" or extension == ".htm" or extension == ".xhtml":
             # Create text extension
             filename = filename[:len(filename) - len(extension)] + ".xhtml"
             xml = html_to_xhtml(file, True)
-            write_text_file(abspath(join(content_folder, filename)), xml)
+            mm_file_tools.write_text_file(abspath(join(content_folder, filename)), xml)
         if extension == ".png" or extension == ".jpg" or extension == ".jpeg" or extension == ".svg":
             # Copy image file
-            copy(file, abspath(join(image_folder, filename)))
+            shutil.copy(file, abspath(join(image_folder, filename)))
             # Create image page
             filename = filename[:len(filename) - len(extension)] + ".xhtml"
             xml = create_image_page(file)
-            write_text_file(abspath(join(content_folder, filename)), xml)
+            mm_file_tools.write_text_file(abspath(join(content_folder, filename)), xml)
     # Create the package and nav files
     create_epub_files(epub_folder, metadata)
     # Zip files and copy to epub
     zip_epub(temp_dir, epub_file)
     return epub_file
     
 def user_create_epub(path:str,
@@ -718,16 +710,16 @@
     :type rp_tags: bool, optional
     :param rp_score: Whether to replace the score from gathered metadata, defaults to False
     :type rp_score: bool, optional
     """
     # Get default metadata
     full_path = abspath(path)
     try:
-        metadata = generate_info_from_jsons(full_path)
-    except FileNotFoundError: metadata = get_empty_metadata()
+        metadata = mm_comic_xml.generate_info_from_jsons(full_path)
+    except FileNotFoundError: metadata = mm_meta_reader.get_empty_metadata()
     # Remove metadata fields the user wishes to replace
     if rp_description:
         metadata["description"] = None
     if rp_date:
         metadata["date"] = None
     if rp_artists:
         metadata["artist"] = None
@@ -752,15 +744,15 @@
         description = str(input("Description: "))
         if not description == "":
             metadata["description"] = description
     # Get the date
     if metadata["date"] is None:
         date = ""
         regex = "(19[7-9][0-9]|2[0-1][0-9]{2})\\-(0[1-9]|1[0-2])\\-(0[1-9]|[1-2][0-9]|3[0-1])"
-        while len(re_find(regex, date)) == 0:
+        while len(re.findall(regex, date)) == 0:
             date = str(input("Date (YYYY-MM-DD): "))
         metadata["date"] = date
     # Get the Writer
     if metadata["writer"] is None:
         writer = str(input(f"Writer: "))
         if not writer == "":
             metadata["writer"] = writer
@@ -785,35 +777,35 @@
         url = str(input("URL: "))
         if not url == "":
             metadata["url"] = url
     # Get tags
     if metadata["tags"] is None:
         url = str(input("Tags: "))
         if not url == "":
-            metadata["tags"] = re_sub("\\s*,\\s*", ",", url)
+            metadata["tags"] = re.sub(r"\s*,\s*", ",", url)
     # Get score
     if rp_score:
         score = str(input("Score (Range 0-5): "))
         if not score == "":
             metadata["score"] = score
     # Create/Update .cbz
     create_epub(full_path, metadata)
 
 def main():
     """
     Sets up the parser for creating an epub file.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "path",
             help="Path to directory for creating epub.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     parser.add_argument(
             "-s",
             "--summary",
             help="Use user summary instead of summary in metadata.",
             action="store_true")
     parser.add_argument(
             "-d",
@@ -845,15 +837,15 @@
             "--grade",
             help="Use user grade/score instead of score in metadata.",
             action="store_true")
     args = parser.parse_args()
     # Check that directory is valid
     path = abspath(args.path)
     if not exists(path):
-        color_print("Invalid path.", "red")
+        python_print_tools.printer.color_print("Invalid path.", "red")
     else:
         # Create the epub
         user_create_epub(path,
                 rp_description=args.summary,
                 rp_date=args.date,
                 rp_artists=args.artists,
                 rp_publisher=args.publisher,
```

## Comparing `metadata_magic/main/error_finding/missing_fields.py` & `metadata_magic/error/missing_fields.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,40 +1,39 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_archive import get_info_from_cbz
-from metadata_magic.main.file_tools.file_tools import find_files_of_type
-from argparse import ArgumentParser
-from os import getcwd
-from os.path import abspath, exists
-from python_print_tools.main.python_print_tools import color_print
-from python_print_tools.main.python_print_tools import print_files
+import os
+import tqdm
+import argparse
+import python_print_tools.printer
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_archive as mm_comic_archive
 from typing import List
-from tqdm import tqdm
+from os.path import abspath, exists, join
 
 def find_missing_comic_info(path:str) -> List[str]:
     """
     Finds .cbz archives that have no attached metadata.
     Includes .cbz archives where the ComicInfo.xml file is not in the base directory.
     
     :param path: Directory in which to search for files
     :type path: str, required
     :return: List of .cbz archives with no metadata
     :rtype: list[str]
     """
     # Find all the .cbz files in the given path
-    empty_metadata = get_empty_metadata()
+    empty_metadata = mm_meta_reader.get_empty_metadata()
     empty_metadata["age_rating"] = "Unknown"
-    cbz_files = find_files_of_type(abspath(path), ".cbz")
+    cbz_files = mm_file_tools.find_files_of_type(abspath(path), ".cbz")
     # Check the metadata of each CBZ file
     missing = []
-    for cbz_file in tqdm(cbz_files):
+    for cbz_file in tqdm.tqdm(cbz_files):
         # Check if metadata is empty
-        metadata = get_info_from_cbz(cbz_file, False)
-        if metadata == get_empty_metadata() or metadata == empty_metadata:
+        metadata = mm_comic_archive.get_info_from_cbz(cbz_file, False)
+        if metadata == mm_meta_reader.get_empty_metadata() or metadata == empty_metadata:
             missing.append(cbz_file)
     # Return .cbz files with missing comic info
     return missing
 
 def find_missing_fields(path:str, fields:List[str], null_value:str=None) -> List[str]:
     """
     Finds .cbz archives with certain missing fields in their metadata.
@@ -46,20 +45,20 @@
     :type fields: list[str], required
     :param null_value: An optional additional value to be considered as None, defaults to None
     :type null_value: str, optional
     :return: List of .cbz archive files missing the given fields
     :rtype: list[str]
     """
     # Find all the .cbz files in the given path
-    cbz_files = find_files_of_type(abspath(path), ".cbz", include_subdirectories=True)
+    cbz_files = mm_file_tools.find_files_of_type(abspath(path), ".cbz", include_subdirectories=True)
     # Check the metadata of each CBZ file
     missing = []
-    for cbz_file in tqdm(cbz_files):
+    for cbz_file in tqdm.tqdm(cbz_files):
         include = True
-        metadata = get_info_from_cbz(cbz_file)
+        metadata = mm_comic_archive.get_info_from_cbz(cbz_file)
         # Check if the given metadata is None
         for field in fields:
             if metadata[field] is not None and not metadata[field] == null_value:
                 include = False
                 break
         # Add to the list of cbzs with a missing field if applicable
         if include:
@@ -68,26 +67,26 @@
     return missing
 
 def main():
     """
     Sets up the parser for finding files with missing metadata fields.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "directory",
             help="Directory in which to search for media with missing metadata.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     args = parser.parse_args()
     # Check that directory is valid
     path = abspath(args.directory)
     if not exists(path):
-        color_print("Invalid path.", "red")
+        python_print_tools.printer.color_print("Invalid path.", "red")
     else:
         # Ask the user for what type of missing field to search for
         print("[M] Missing metadata")
         print("[T] Missing title")
         print("[A] Missing artist")
         print("[D] Missing date")
         print("[S] Missing summary")
@@ -144,13 +143,13 @@
             # Missing summary
             label = "series"
             missing = find_missing_fields(path, ["series"])
         # Print results
         if label is not None:
             length = len(missing)
             if length > 0:
-                print_files(path, missing)
-                color_print(f"{length} files with missing {label}.", "red")
+                python_print_tools.printer.print_files(path, missing)
+                python_print_tools.printer.color_print(f"{length} files with missing {label}.", "red")
             else:
-                color_print(f"No files with missing {label}.", "green")
+                python_print_tools.printer.color_print(f"No files with missing {label}.", "green")
         else:
-            color_print("Invalid response.", "red")
+            python_print_tools.printer.color_print("Invalid response.", "red")
```

## Comparing `metadata_magic/main/error_finding/missing_media.py` & `metadata_magic/error/missing_media.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,61 +1,59 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_finder import get_pairs_from_lists
-from metadata_magic.main.meta_finder import separate_files
-from argparse import ArgumentParser
-from os import getcwd
-from os.path import abspath, exists
-from python_print_tools.main.python_print_tools import color_print
-from python_print_tools.main.python_print_tools import print_files
+import os
+import tqdm
+import argparse
+import python_print_tools.printer
+import metadata_magic.meta_finder as mm_meta_finder
+from os.path import abspath, exists, join
 from typing import List
-from tqdm import tqdm
 
 def find_missing_media(path:str) -> List[str]:
     """
     Returns a list of JSON metadata files without corresponding media.
 
     :param path: Directory in which to search
     :type path: str, required
     :return: List of JSON files with missing media
     :rtype: list[str]
     """
     # Separate JSON and media files and get proper metadata pairs
-    jsons, media = separate_files(path)
-    pairs = get_pairs_from_lists(media)
+    jsons, media = mm_meta_finder.separate_files(path)
+    pairs = mm_meta_finder.get_pairs_from_lists(media)
     # Remove paired JSON files
     print("Finding JSONs with missing media:")
-    for pair in tqdm(pairs):
+    for pair in tqdm.tqdm(pairs):
         try:
             index = jsons.index(pair["json"])
             del jsons[index]
         except ValueError: pass
     # Return list of JSON files without media
     return jsons
 
 def main():
     """
     Sets up the parser for the user to find JSONs with missing media files.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "directory",
             help="Directory to search for JSONs within.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     args = parser.parse_args()
     # Check that directory is valid
     directory = abspath(args.directory)
     if not exists(directory):
-        color_print("Invalid directory.", "red")
+        python_print_tools.printer.color_print("Invalid directory.", "red")
     else:
         # Get list of JSONs with missing media
         missing = find_missing_media(directory)
         length = len(missing)
         # Print list of missing media
         if length > 0:
-            print_files(directory, missing)
-            color_print(f"{length} JSONs with missing media.", "red")
+            python_print_tools.printer.print_files(directory, missing)
+            python_print_tools.printer.color_print(f"{length} JSONs with missing media.", "red")
         else:
-            color_print("No JSONs with missing media found.", "green")
+            python_print_tools.printer.color_print("No JSONs with missing media found.", "green")
```

## Comparing `metadata_magic/main/error_finding/missing_metadata.py` & `metadata_magic/error/missing_metadata.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,61 +1,59 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_finder import get_pairs_from_lists
-from metadata_magic.main.meta_finder import separate_files
-from argparse import ArgumentParser
-from os import getcwd
-from os.path import abspath, exists
-from python_print_tools.main.python_print_tools import color_print
-from python_print_tools.main.python_print_tools import print_files
+import os
+import tqdm
+import argparse
+import python_print_tools.printer
+import metadata_magic.meta_finder as mm_meta_finder
+from os.path import abspath, exists, join
 from typing import List
-from tqdm import tqdm
 
 def find_missing_metadata(path:str) -> List[str]:
     """
     Returns a list of media files without corresponding JSON metadata.
 
     :param path: Directory in which to search
     :type path: str, required
     :return: List of media files with missing metadata
     :rtype: list[str]
     """
     # Separate JSON and media files and get proper metadata pairs
-    jsons, media = separate_files(path)
-    pairs = get_pairs_from_lists(media)
+    jsons, media = mm_meta_finder.separate_files(path)
+    pairs = mm_meta_finder.get_pairs_from_lists(media)
     # Remove paired JSON files
     print("Finding media with missing metadata:")
-    for pair in tqdm(pairs):
+    for pair in tqdm.tqdm(pairs):
         try:
             index = media.index(pair["media"])
             del media[index]
         except ValueError: pass
     # Return list of media without metadata
     return media
 
 def main():
     """
     Sets up the parser for the user to find media with missing metadata files.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "directory",
             help="Directory to search for media within.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     args = parser.parse_args()
     # Check that directory is valid
     directory = abspath(args.directory)
     if not exists(directory):
-        color_print("Invalid directory.", "red")
+        python_print_tools.printer.color_print("Invalid directory.", "red")
     else:
         # Get list of media with missing metadata
         missing = find_missing_metadata(directory)
         length = len(missing)
         # Print list of missing metadata
         if length > 0:
-            print_files(directory, missing)
-            color_print(f"{length} media files with missing metadata.", "red")
+            python_print_tools.printer.print_files(directory, missing)
+            python_print_tools.printer.color_print(f"{length} media files with missing metadata.", "red")
         else:
-            color_print("No missing metadata found.", "green")
+            python_print_tools.printer.color_print("No missing metadata found.", "green")
```

## Comparing `metadata_magic/main/file_tools/file_tools.py` & `metadata_magic/file_tools.py`

 * *Files 5% similar despite different names*

```diff
@@ -1,35 +1,33 @@
 #!/usr/bin/env python3
 
-from json import dump as dump_json
-from json import load as load_json
-from json import JSONDecodeError
-from html_string_tools.main.html_string_tools import get_extension
-from metadata_magic.main.rename.rename_tools import get_available_filename
-from metadata_magic.main.rename.rename_tools import sort_alphanum
-from os import listdir, mkdir, remove
-from os.path import abspath, basename, exists, isdir, join, relpath
-from shutil import copy, copytree, rmtree
-from tempfile import gettempdir
+import os
+import json
+import shutil
+import zipfile
+import tempfile
+import html_string_tools
 from typing import List
-from zipfile import BadZipFile, ZipFile, ZIP_DEFLATED
+from os.path import abspath, basename, exists, isdir, join, relpath
+from .rename import rename_tools as mm_rename_tools
 
 def get_temp_dir(folder_name:str="dvk_meta_magic") -> str:
     """
     Creates and returns test directory.
 
     :param folder_name: Name to give the temporary directory, defaults to "dvk_meta_magic"
     :type folder_name: str, optional
     :return: File path of the test directory
     :rtype: str
     """
-    temp_dir = abspath(join(abspath(gettempdir()), folder_name))
+    base_temp_dir = abspath(tempfile.gettempdir())
+    temp_dir = abspath(join(base_temp_dir, folder_name))
     if(exists(temp_dir)):
-        rmtree(temp_dir)
-    mkdir(temp_dir)
+        shutil.rmtree(temp_dir)
+    os.mkdir(temp_dir)
     return temp_dir
 
 def write_text_file(file:str, text:str):
     """
     Writes a file containing the given text.
     Will overwrite existing files
     
@@ -67,31 +65,31 @@
     :type file: str, required
     :param text: Contents to save as JSON
     :type text: str, required
     """
     try:
         full_path = abspath(file)
         with open(full_path, "w") as out_file:
-            dump_json(contents, out_file)
+            json.dump(contents, out_file)
     except FileNotFoundError: pass
 
 def read_json_file(file:str) -> dict:
     """
     Returns the contents of a given JSON file as a dictionary.
     
     :param file: JSON file to read.
     :type file: str, required
     :return: Contents of the JSON file
     :rtype: dict
     """
     try:
         full_path = abspath(file)
         with open(full_path) as in_file:
-            return load_json(in_file)
-    except (FileNotFoundError, IsADirectoryError, JSONDecodeError): return {}
+            return json.load(in_file)
+    except (FileNotFoundError, IsADirectoryError, json.decoder.JSONDecodeError): return {}
 
 def find_files_of_type(directory:str, extension:str, include_subdirectories:bool=True, inverted:bool=False) -> List[str]:
     """
     Returns a list of files in a given directory that match a given file extension.
     
     :param directory: Directory in which to search for files
     :type directory: str, required
@@ -105,76 +103,76 @@
     :rtype: list[str]
     """
     files = []
     directories = [abspath(directory)]
     # Run through all directories
     while len(directories) > 0:
         # Get list of all files in the current directory
-        current_files = sort_alphanum(listdir(directories[0]))
+        current_files = mm_rename_tools.sort_alphanum(os.listdir(directories[0]))
         for filename in current_files:
             # Find file properties
             full_file = abspath(join(directories[0], filename))
-            has_extension = get_extension(full_file) == extension
+            has_extension = html_string_tools.html.get_extension(full_file) == extension
             # Add directory to the list
             if isdir(full_file):
                 if include_subdirectories:
                     directories.append(full_file)
                 continue
             # Add if the extension matches properly
             if (has_extension and not inverted) or (not has_extension and inverted):
                 files.append(full_file)
         # Delete directory entry
         del directories[0]
     # Return found files
     return files
 
-def create_zip(directory:str, zip_file:str, compress_level:int=9) -> bool:
+def create_zip(directory:str, zip_path:str, compress_level:int=9) -> bool:
     """
     Creates a zip file with all the files and subdirectories within a given directory.
     
     :param directory: Directory with files to archive into a zip file
     :type directory: str, required
-    :param zip_file: Path of the zip file to be created
-    :type zip_file: str, required
+    :param zip_path: Path of the zip file to be created
+    :type zip_path: str, required
     :param compress_level: Level of compression from min 0 to max 9, defaults to 9
     :type compress_level: int, optional
     :return: Whether a zip file was successfully created
     :rtype: bool
     """
     # Get list of files in the directory
     full_directory = abspath(directory)
-    files = listdir(full_directory)
+    files = os.listdir(full_directory)
     for i in range(0, len(files)):
         files[i] = abspath(join(full_directory, files[i]))
     # Expand list of files to include subdirectories
     for file in files:
         if isdir(file):
-            sub_files = listdir(file)
+            sub_files = os.listdir(file)
             for i in range(0, len(sub_files)):
                 files.append(abspath(join(file, sub_files[i])))
     # Create empty zip file
-    with ZipFile(zip_file, "w", compression=ZIP_DEFLATED, compresslevel=compress_level) as out_file: pass
-    if not exists(zip_file):
+    with zipfile.ZipFile(zip_path, "w", compression=zipfile.ZIP_DEFLATED, compresslevel=compress_level) as out_file: pass
+    if not exists(zip_path):
         return False
     # Write contents of directory to zip file
     for file in files:
         if not basename(file).startswith("."):
             relative = relpath(file, full_directory)
-            with ZipFile(zip_file, "a", compression=ZIP_DEFLATED, compresslevel=compress_level) as out_file:
+            with zipfile.ZipFile(zip_path, "a", compression=zipfile.ZIP_DEFLATED, compresslevel=compress_level) as out_file:
                 out_file.write(file, relative)
     # Return if the zip file was successfully created
-    return exists(zip_file)
+    return exists(zip_path)
 
-def extract_zip(zip_file:str, extract_directory:str, create_folder:bool=False,
+def extract_zip(zip_path:str, extract_directory:str, create_folder:bool=False,
                 remove_internal:bool=False, delete_files:List[str]=[]) -> bool:
     """
     Extracts a ZIP file into a given directory.
     
-    :param zip_file: Path to ZIP file to extract
-    :type zip_file: str, required
+    :param zip_path: Path to ZIP file to extract
+    :type zip_path: str, required
     :param extract_directory: Directory in which to extract ZIP contents
     :type extract_directory: str, required
     :param create_folder: Whether to create a folder within the given directory to hold contents, defaults to False
     :type create_folder: bool, optional
     :param remove_internal: Whether to remove redundant internal folder, defaults to False
     :type remove_internal: bool, optional
     :param delete_files: List of filenames to delete if desired, defaults to []
@@ -182,81 +180,83 @@
     :return: Whether the files were extracted successfully
     :rtype: bool
     """
     # Get temporary directory
     temp_dir = get_temp_dir("dvk-unzip")
     # Unzip files into temp directory
     try:
-        with ZipFile(zip_file, mode="r") as file:
+        with zipfile.ZipFile(zip_path, mode="r") as file:
             file.extractall(path=temp_dir)
-    except BadZipFile: return False
+    except zipfile.BadZipFile: return False
     # Create new extraction subfolder if specified
     main_dir = abspath(extract_directory)
     new_dir = abspath(extract_directory)
     if create_folder:
-        filename = basename(zip_file)
-        filename = filename[:len(filename) - len(get_extension(filename))]
-        filename = get_available_filename("AAAAAAAAAA", filename, main_dir)
+        filename = basename(zip_path)
+        extension = html_string_tools.html.get_extension(filename)
+        filename = filename[:len(filename) - len(extension)]
+        filename = mm_rename_tools.get_available_filename("AAAAAAAAAA", filename, main_dir)
         new_dir = abspath(join(main_dir, filename))
-        mkdir(new_dir)
+        os.mkdir(new_dir)
     # Delete listed files
     for file in delete_files:
         full_file = abspath(join(temp_dir, file))
         if exists(full_file):
-            remove(full_file)
+            os.remove(full_file)
     # Remove internal folder if specified
-    if remove_internal and len(listdir(temp_dir)) == 1:
-        full_file = abspath(join(temp_dir, listdir(temp_dir)[0]))
+    if remove_internal and len(os.listdir(temp_dir)) == 1:
+        full_file = abspath(join(temp_dir, os.listdir(temp_dir)[0]))
         if isdir(full_file):
             temp_dir = full_file
     # Copy files to new directory
-    files = listdir(temp_dir)
+    files = os.listdir(temp_dir)
     for file in files:
-        filename = file[:len(file) - len(get_extension(file))]
-        filename = get_available_filename(file, filename, new_dir)
+        filename = file[:len(file) - len(html_string_tools.html.get_extension(file))]
+        filename = mm_rename_tools.get_available_filename(file, filename, new_dir)
         current_file = abspath(join(temp_dir, file))
         new_file = abspath(join(new_dir, filename))
         if isdir(current_file):
-            copytree(current_file, new_file)
+            shutil.copytree(current_file, new_file)
         else:
-            copy(current_file, new_file)
+            shutil.copy(current_file, new_file)
     return True
 
-def extract_file_from_zip(zip_file:str, extract_directory:str, extract_file:str, check_subdirectories:bool=False) -> str:
+def extract_file_from_zip(zip_path:str, extract_directory:str, extract_file:str, check_subdirectories:bool=False) -> str:
     """
     Attempts to extract a single file from a ZIP archive given a filename.
     
-    :param zip_file: ZIP archive to extract a file from.
-    :type zip_file: str, required
+    :param zip_path: ZIP archive to extract a file from.
+    :type zip_path: str, required
     :param extract_directory: Directory in which to extract the file.
     :type extract_directory: str, required
     :param extract_file: Filename of the file to be extracted
     :type extract_file: str, required
     :param check_subdirectories: Whether to check subdirectories for the given file as well, defaults to False
     :type check_subdirectories: bool, optional
     :return: Path of the extracted file, None if file couldn't be extracted
     :rtype: str
     """
     # Get temporary directory
     temp_dir = get_temp_dir("dvk_unzip_single")
     # Extract into temporary directory
     try:
-        with ZipFile(zip_file, mode="r") as zfile:
+        with zipfile.ZipFile(zip_path, mode="r") as zfile:
             # Get the correct file to extract
             internal_file = None
             info_list = zfile.infolist()
             for info in info_list:
                 if info.filename == extract_file or (check_subdirectories and basename(info.filename) == extract_file):
                     internal_file = info.filename
             # Attempt extracting the file
             zfile.extract(internal_file, path=temp_dir)
             extracted = abspath(join(temp_dir, internal_file))
             new_file = abspath(join(extract_directory, extract_file))
             # Update file if it already exists
             if exists(new_file):
-                filename = extract_file[:len(extract_file) - len(get_extension(extract_file))]
-                filename = get_available_filename(extracted, filename, extract_directory)
+                extension = html_string_tools.html.get_extension(extract_file)
+                filename = extract_file[:len(extract_file) - len(extension)]
+                filename = mm_rename_tools.get_available_filename(extracted, filename, extract_directory)
                 new_file = abspath(join(extract_directory, filename))
             # Copy file to new location
-            copy(extracted, new_file)
+            shutil.copy(extracted, new_file)
             return new_file
-    except (BadZipFile, KeyError): return None
+    except (zipfile.BadZipFile, KeyError): return None
```

## Comparing `metadata_magic/main/rename/meta_rename.py` & `metadata_magic/rename/meta_rename.py`

 * *Files 4% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 #!/usr/bin/env python3
 
-from re import sub as re_sub
-from metadata_magic.main.meta_finder import get_pairs
-from metadata_magic.main.meta_reader import load_metadata as get_info_from_json
-from metadata_magic.main.comic_archive.comic_archive import get_info_from_cbz
-from metadata_magic.main.rename.rename_tools import rename_file
-from metadata_magic.main.file_tools.file_tools import find_files_of_type
-from json.decoder import JSONDecodeError
-from html_string_tools.main.html_string_tools import get_extension
-from argparse import ArgumentParser
-from os import listdir, getcwd
-from os.path import abspath, basename, exists, isdir, join
-from python_print_tools.main.python_print_tools import color_print
-from tqdm import tqdm
+import os
+import re
+import tqdm
+import argparse
+import json.decoder
+import html_string_tools
+import python_print_tools.printer
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_finder as mm_meta_finder
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.rename.rename_tools as mm_rename_tools
+import metadata_magic.archive.comic_archive as mm_comic_archive
+from os.path import abspath, basename, exists, join
 
 def rename_cbz_files(path:str,
             add_artist:bool=False,
             add_date:bool=False):
     """
     Renames all CBZ files based on metadata.
 
@@ -27,56 +27,20 @@
     :param add_date: Whether to add publication date, defaults to False
     :type add_date: bool, optional
     :param add_id: Whether to add media ID, defaults to False
     :type add_id: bool, optional
     """
     # Get list of CBZ files
     print("Renaming CBZ files:")
-    cbz_files = find_files_of_type(abspath(path), ".cbz")
+    cbz_files = mm_file_tools.find_files_of_type(abspath(path), ".cbz")
     # Rename all CBZ files
-    for cbz_file in tqdm(cbz_files):
+    for cbz_file in tqdm.tqdm(cbz_files):
         filename = get_filename_from_metadata(
             cbz_file, add_artist=add_artist, add_date=add_date)
-        rename_file(cbz_file, filename)
-
-def rename_json_pairs(path:str,
-            add_artist:bool=False,
-            add_date:bool=False,
-            add_id:bool=False):
-    """
-    Renames all JSON files and their associated media based on JSON metadata.
-
-    :param path: Path of directory containing JSON files
-    :type path: str, required
-    :param add_artist: Whether to add artist's name, defaults to False
-    :type add_artist: bool, optional
-    :param add_date: Whether to add publication date, defaults to False
-    :type add_date: bool, optional
-    :param add_id: Whether to add media ID, defaults to False
-    :type add_id: bool, optional
-    """
-    # Get JSON pairs
-    pairs = get_pairs(path)
-    # Rename each pair
-    print("Renaming JSON and media files:")
-    for pair in tqdm(pairs):
-        # Get paths from the pair
-        json = pair["json"]
-        media = pair["media"]
-        # Get filename
-        filename = get_filename_from_metadata(
-                json, add_artist=add_artist, add_date=add_date, add_id=add_id)
-        # Rename JSON
-        new_file = rename_file(json, filename)
-        # Rename media
-        try:
-            filename = basename(new_file)
-            filename = filename[:len(filename) - len(get_extension(filename))]
-            rename_file(media, filename)
-        except TypeError: pass
+        mm_rename_tools.rename_file(cbz_file, filename)
 
 def get_filename_from_metadata(file:str,
             add_artist:bool=False,
             add_date:bool=False,
             add_id:bool=False) -> str:
     """
     Returns a filename based on metadata for a given file.
@@ -92,23 +56,23 @@
     :type add_id: bool, optional
     :return: Filename based on metadata, not including extension
     :rtype: str
     """
     full_file = abspath(file)
     try:
         # Load JSON metadata if applicable
-        metadata = get_info_from_json(full_file)
-    except (JSONDecodeError, UnicodeDecodeError):
+        metadata = mm_meta_reader.load_metadata(full_file)
+    except (json.decoder.JSONDecodeError, UnicodeDecodeError):
         # Load CBZ metadata if applicable
-        metadata = get_info_from_cbz(full_file)
+        metadata = mm_comic_archive.get_info_from_cbz(full_file)
     # Return filename if metadata could not be found
     if metadata["title"] is None:
         filename = basename(full_file)
-        filename = re_sub("\\.json$", "", filename)
-        return filename[:len(filename) - len(get_extension(filename))]
+        filename = re.sub("\\.json$", "", filename)
+        return filename[:len(filename) - len(html_string_tools.html.get_extension(filename))]
     # Get title
     title = metadata["title"]
     # Get ID if applicable
     header = ""
     identifier = None
     if add_id:
         try:
@@ -129,32 +93,69 @@
             artist = metadata["writer"]
             assert artist is not None
         except (AssertionError, KeyError):
             artist = metadata["artist"]
     if artist is not None:
         header = f"{artist}_{header}"
     # Add header to title
-    header = re_sub("[-_\\s]+$", "", header)
+    header = re.sub("[-_\\s]+$", "", header)
     if not header == "":
         title = f"[{header}] {title}"
     # Return title
     return title
 
+def rename_json_pairs(path:str,
+            add_artist:bool=False,
+            add_date:bool=False,
+            add_id:bool=False):
+    """
+    Renames all JSON files and their associated media based on JSON metadata.
+
+    :param path: Path of directory containing JSON files
+    :type path: str, required
+    :param add_artist: Whether to add artist's name, defaults to False
+    :type add_artist: bool, optional
+    :param add_date: Whether to add publication date, defaults to False
+    :type add_date: bool, optional
+    :param add_id: Whether to add media ID, defaults to False
+    :type add_id: bool, optional
+    """
+    # Get JSON pairs
+    pairs = mm_meta_finder.get_pairs(path)
+    # Rename each pair
+    print("Renaming JSON and media files:")
+    for pair in tqdm.tqdm(pairs):
+        # Get paths from the pair
+        json = pair["json"]
+        media = pair["media"]
+        # Get filename
+        filename = get_filename_from_metadata(
+                json, add_artist=add_artist, add_date=add_date, add_id=add_id)
+        # Rename JSON
+        new_file = mm_rename_tools.rename_file(json, filename)
+        # Rename media
+        try:
+            filename = basename(new_file)
+            extension = html_string_tools.html.get_extension(filename)
+            filename = filename[:len(filename) - len(extension)]
+            mm_rename_tools.rename_file(media, filename)
+        except TypeError: pass
+
 def main():
     """
     Sets up the parser for the user to rename JSON files.
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "directory",
             help="Directory in which to rename files.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     parser.add_argument(
             "-a",
             "--artist",
             help="Add media artist to the beginning of renamed files.",
             action="store_true")
     parser.add_argument(
             "-d",
@@ -166,13 +167,13 @@
             "--id",
             help="Add media ID to the beginning of renamed files.",
             action="store_true")
     args = parser.parse_args()
     # Check that directory is valid
     directory = abspath(args.directory)
     if not exists(directory):
-        color_print("Invalid directory.", "red")
+        python_print_tools.printer.color_print("Invalid directory.", "red")
     else:
         rename_json_pairs(directory, add_artist=args.artist, add_id=args.id, add_date=args.date)
         print()
         rename_cbz_files(directory, add_artist=args.artist, add_date=args.date)
-        color_print("Finished renaming.", "green")
+        python_print_tools.printer.color_print("Finished renaming.", "green")
```

## Comparing `metadata_magic/main/rename/rename_tools.py` & `metadata_magic/rename/rename_tools.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,33 +1,32 @@
 #!/usr/bin/env python3
 
-from _functools import cmp_to_key
-from re import sub as re_sub
-from re import findall as re_find
-from html_string_tools.main.html_string_tools import get_extension
-from os import pardir, rename
-from os.path import abspath, basename, exists, join
+import os
+import re
+import _functools
+import html_string_tools.html
 from typing import List
+from os.path import abspath, basename, exists, join
 
 def get_section(string:str) -> str:
     """
     Gets the first "section" of a given string.
     A section should contain either only text or only a number.
     
     :param string: String to get section from
     :type string: str, required
     :return: The first "section" of the given string
     :rtype: str
     """
     # Check if string starts with a number
-    if len(re_find("^[0-9]", string)) > 0:
+    if len(re.findall("^[0-9]", string)) > 0:
         # Return number section if string starts with a number
-        return re_find("[0-9]+[0-9,\\.]*", string)[0]
+        return re.findall(r"[0-9]+[0-9,\.]*", string)[0]
     # Return non-number section if string doesn't start with number
-    sections = re_find("[^0-9]+", string)
+    sections = re.findall("[^0-9]+", string)
     if len(sections) > 0:
         return sections[0]
     # Return empty string if no sections could be found
     return ""
 
 def compare_sections(section1:str, section2:str) -> int:
     """
@@ -99,57 +98,57 @@
     Sorts a given list alphanumerically.
     
     :param lst: List to sort
     :type lst: list[str], required
     :return: Sorted list
     :rtype: list[str]
     """
-    comparator = cmp_to_key(compare_alphanum)
+    comparator = _functools.cmp_to_key(compare_alphanum)
     return sorted(lst, key=comparator)
 
 def create_filename(string:str) -> str:
     """
     Creates a string suitable for a filename from a given string.
     :param string: Any string to convert into filename
     :type string: str, required
     :return: String with all invalid characters removed or replaced
     :rtype: str
     """
     # Replace colons
     new_text = string.replace(":", " - ")
     # Replace elipses
-    new_text = re_sub("\\.\\s*\\.\\s*\\.", "…", new_text)
+    new_text = re.sub(r"\.\s*\.\s*\.", "…", new_text)
     # Replace special latin characters
-    new_text = re_sub("[À-Å]", "A", new_text)
-    new_text = re_sub("[È-Ë]", "E", new_text)
-    new_text = re_sub("[Ì-Ï]", "I", new_text)
-    new_text = re_sub("[Ò-Ö]", "O", new_text)
-    new_text = re_sub("[Ù-Ü]", "U", new_text)
-    new_text = re_sub("[à-å]", "a", new_text)
-    new_text = re_sub("[è-ë]", "e", new_text)
-    new_text = re_sub("[ì-ï]", "i", new_text)
-    new_text = re_sub("[ò-ö]", "o", new_text)
-    new_text = re_sub("[ù-ü]", "u", new_text)
-    new_text = re_sub("[ýÿ]", "y", new_text)
+    new_text = re.sub("[À-Å]", "A", new_text)
+    new_text = re.sub("[È-Ë]", "E", new_text)
+    new_text = re.sub("[Ì-Ï]", "I", new_text)
+    new_text = re.sub("[Ò-Ö]", "O", new_text)
+    new_text = re.sub("[Ù-Ü]", "U", new_text)
+    new_text = re.sub("[à-å]", "a", new_text)
+    new_text = re.sub("[è-ë]", "e", new_text)
+    new_text = re.sub("[ì-ï]", "i", new_text)
+    new_text = re.sub("[ò-ö]", "o", new_text)
+    new_text = re.sub("[ù-ü]", "u", new_text)
+    new_text = re.sub("[ýÿ]", "y", new_text)
     new_text = new_text.replace("Ñ", "N")
     new_text = new_text.replace("Ý", "Y")
     new_text = new_text.replace("ñ", "n")
     # Replace -> Arrow with "to"
-    new_text = re_sub("(?<=\\s)-+>(?=\\s)", "to", new_text)
+    new_text = re.sub(r"(?<=\s)-+>(?=\s)", "to", new_text)
     # Replace all invalid characters
-    new_text = re_sub("<|>|\"|\\/|\\\\|\\||\\?|\\*|\\.+$", "-", new_text)
+    new_text = re.sub(r'<|>|\"|\/|\\|\||\?|\*|\.+$', "-", new_text)
     # Remove whitespace and hyphens at begining and end of text
-    new_text = re_sub("^[\\s-]+|[\\s-]+$", "", new_text)
+    new_text = re.sub(r"^[\s-]+|[\s-]+$", "", new_text)
     # Remove duplicate spacers
-    new_text = re_sub("-{2,}", "-", new_text)
-    new_text = re_sub(" {2,}", " ", new_text)
+    new_text = re.sub("-{2,}", "-", new_text)
+    new_text = re.sub(" {2,}", " ", new_text)
     # Remove hanging hyphens
-    new_text = re_sub("(?<= )-(?=[^ \\-])|(?<=[^ \\-])-(?= )", "", new_text)
+    new_text = re.sub(r"(?<= )-(?=[^ \-])|(?<=[^ \-])-(?= )", "", new_text)
     # Remove any remaining whitespace & heading/trailing periods
-    new_text = re_sub("^[\\s\\.\\-]+|[\\s\\.\\-]+$", "", new_text)
+    new_text = re.sub(r"^[\s\.\-]+|[\s\.\-]+$", "", new_text)
     # Return "0" if there is no text
     if new_text == "":
         return "0"
     # Return modified string
     return new_text
 
 def get_available_filename(file:str, new_filename:str, end_path:str) -> str:
@@ -164,15 +163,15 @@
     :param end_path: Path to check for already existing files within
     :type end_path: str, required
     :return: Name of the new filename
     :rtype: str
     """
     # Get the prefered new filename
     full_file = abspath(file)
-    extension = get_extension(file)
+    extension = html_string_tools.html.get_extension(file)
     filename = create_filename(new_filename)
     # Update name if the filename already exists
     file_num = 1
     base_filename = filename
     full_end_path = abspath(end_path)
     while exists(abspath(join(full_end_path, f"{filename}{extension}"))):
         file_num += 1
@@ -191,22 +190,22 @@
     :param new_filename: Filename to set new file to
     :type new_filename: str, required
     :return: Path of the file after being renamed, None if rename failed
     :rtype: str
     """
     # Get the prefered new filename
     path = abspath(file)
-    extension = get_extension(file)
+    extension = html_string_tools.html.get_extension(file)
     filename = create_filename(new_filename)
     # Do nothing if the filename is already accurate
     if basename(path) == f"{filename}{extension}":
         return path
     # Update filename if file already exists
-    parent_dir = abspath(join(path, pardir))
+    parent_dir = abspath(join(path, os.pardir))
     filename = get_available_filename(file, new_filename, parent_dir)
     # Rename file
     try:
         new_file = abspath(join(parent_dir, filename))
-        rename(path, new_file)
+        os.rename(path, new_file)
         return new_file
     except FileNotFoundError:
         return None
```

## Comparing `metadata_magic/main/rename/sort_rename.py` & `metadata_magic/rename/sort_rename.py`

 * *Files 9% similar despite different names*

```diff
@@ -1,19 +1,17 @@
 #!/usr/bin/env python3
 
-from re import sub as re_sub
-from re import findall as re_find
-from metadata_magic.main.meta_finder import get_pairs
-from metadata_magic.main.rename.rename_tools import rename_file
-from metadata_magic.main.rename.rename_tools import sort_alphanum
-from argparse import ArgumentParser
-from os import getcwd, listdir, pardir
+import os
+import re
+import tqdm
+import argparse
+import python_print_tools.printer
+import metadata_magic.meta_finder as mm_meta_finder
+import metadata_magic.rename.rename_tools as mm_rename_tools
 from os.path import abspath, basename, exists, isdir, join
-from python_print_tools.main.python_print_tools import color_print
-from tqdm import tqdm
 
 def sort_rename(path:str, name:str, start_index:int=1):
     """
     Renames all files in a given path to a common title, sequenced in order with numbers.
     JSON-media pairs are renamed to the same name, all other files named separately.
     "#" Characters in name are converted to actual index number when renaming.
     Number of "#" characters corresponds to the number of padded digits for the index.
@@ -23,24 +21,24 @@
     :param name: Common title for renaming files
     :type name: str, required
     :param start_index: The first number to start with when renaming, defaults to 1
     :type start_index: int, optional
     """
     # Get sorted list of files
     base = abspath(path)
-    filenames = sort_alphanum(listdir(base))
+    filenames = mm_rename_tools.sort_alphanum(os.listdir(base))
     # Get JSON pairs
-    pairs = get_pairs(base)
+    pairs = mm_meta_finder.get_pairs(base)
     sort_pairs = []
     for i in range(0, len(filenames)):
         sort_pairs.append(None)
     # Add pairs to sorted list in order
     for pair in pairs:
         # Skip pair if not in the right directory
-        if not abspath(join(pair["json"], pardir)) == base:
+        if not abspath(join(pair["json"], os.pardir)) == base:
             continue
         # Add pair to sorted pair list
         index = filenames.index(basename(pair["media"]))
         filenames[index] = None
         sort_pairs[index] = pair
         index = filenames.index(basename(pair["json"]))
         filenames[index] = None
@@ -52,46 +50,46 @@
             sort_pairs[i] = pair
     # Delete empty entries in the sort_pairs list
     for i in range(len(sort_pairs)-1,-1,-1):
         if sort_pairs[i] is None:
             del sort_pairs[i]
     # Rename files in order
     pad_num = 0
-    name_num = re_find("#+", name)
+    name_num = re.findall("#+", name)
     if len(name_num) > 0:
         pad_num = len(name_num[0])
     print("Renaming Files:")
-    for i in tqdm(range(0, len(sort_pairs))):
+    for i in tqdm.tqdm(range(0, len(sort_pairs))):
         # Set the filename
         filename = str(i+start_index)
         if pad_num == 0:
             filename = f"{name} {filename}"
         else:
             # Replace # with item number
             while len(filename) < pad_num:
                 filename = f"0{filename}"
-            filename = re_sub("#+", filename, name, 1)
+            filename = re.sub("#+", filename, name, 1)
         # Rename media file
-        rename_file(sort_pairs[i]["media"], filename)
+        mm_rename_tools.rename_file(sort_pairs[i]["media"], filename)
         # Rename json file, if it exits
         if sort_pairs[i]["json"] is not None:
-            rename_file(sort_pairs[i]["json"], filename)
+            mm_rename_tools.rename_file(sort_pairs[i]["json"], filename)
 
 def main():
     """
     Sets up the parser for renaming files in a sorted order
     """
     # Set up argument parser
-    parser = ArgumentParser()
+    parser = argparse.ArgumentParser()
     parser.add_argument(
             "directory",
             help="Directory to search for JSONs within.",
             nargs="?",
             type=str,
-            default=str(getcwd()))
+            default=str(os.getcwd()))
     parser.add_argument(
             "-n",
             "--name",
             help="Base name for renaming files.",
             nargs="?",
             type=str,
             default=None)
@@ -102,15 +100,15 @@
             nargs="?",
             type=str,
             default=None)
     args = parser.parse_args()
     # Check that directory is valid
     directory = abspath(args.directory)
     if not exists(directory):
-        color_print("Invalid directory.", "red")
+        python_print_tools.printer.color_print("Invalid directory.", "red")
     else:
         # Get name if not already given
         name = args.name
         if name is None:
             name = str(input("Rename Title: "))
         # Get index number
         try:
```

## Comparing `metadata_magic/test/comic_archive/test_comic_archive.py` & `metadata_magic/test/archive/test_comic_archive.py`

 * *Files 27% similar despite different names*

```diff
@@ -1,309 +1,302 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_archive import create_cbz
-from metadata_magic.main.comic_archive.comic_archive import update_cbz_info
-from metadata_magic.main.comic_archive.comic_archive import get_info_from_cbz
-from metadata_magic.main.comic_archive.comic_xml import get_comic_xml
-from metadata_magic.main.comic_archive.comic_xml import read_comic_info
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import create_zip
-from metadata_magic.main.file_tools.file_tools import extract_zip
-from metadata_magic.main.file_tools.file_tools import read_text_file
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import listdir, mkdir, remove
+import os
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_xml as mm_comic_xml
+import metadata_magic.archive.comic_archive as mm_comic_archive
 from os.path import abspath, basename, exists, join
 
 def test_create_cbz():
     """
     Tests the create_cbz function.
     """
     # Test creating a CBZ with loose files and no name
-    cbz_directory = get_temp_dir("dvk_cbz_test")
+    cbz_directory = mm_file_tools.get_temp_dir("dvk_cbz_test")
     text_file = abspath(join(cbz_directory, "text.txt"))
     media_file = abspath(join(cbz_directory, "other.txt"))
-    write_text_file(text_file, "TEXT!")
-    write_text_file(media_file, "Yet more text.")
+    mm_file_tools.write_text_file(text_file, "TEXT!")
+    mm_file_tools.write_text_file(media_file, "Yet more text.")
     assert exists(text_file)
     assert exists(media_file)
-    cbz_file = create_cbz(cbz_directory)
+    cbz_file = mm_comic_archive.create_cbz(cbz_directory)
     assert basename(cbz_file) == "dvk_cbz_test.cbz"
     assert exists(cbz_file)
-    assert sorted(listdir(cbz_directory)) == ["dvk_cbz_test.cbz", "other"]
+    assert sorted(os.listdir(cbz_directory)) == ["dvk_cbz_test.cbz", "other"]
     sub_directory = abspath(join(cbz_directory, "other"))
-    assert sorted(listdir(sub_directory)) == ["other.txt", "text.txt"]
-    extract_directory = get_temp_dir("dvk_extract_test")
-    assert extract_zip(cbz_file, extract_directory)
-    assert sorted(listdir(extract_directory)) == ["other"]
+    assert sorted(os.listdir(sub_directory)) == ["other.txt", "text.txt"]
+    extract_directory = mm_file_tools.get_temp_dir("dvk_extract_test")
+    assert mm_file_tools.extract_zip(cbz_file, extract_directory)
+    assert sorted(os.listdir(extract_directory)) == ["other"]
     sub_directory = abspath(join(extract_directory, "other"))
-    assert sorted(listdir(sub_directory)) == ["other.txt", "text.txt"]
+    assert sorted(os.listdir(sub_directory)) == ["other.txt", "text.txt"]
     # Test creating CBZ with existing directories and a Name
-    cbz_directory = get_temp_dir("dvk_cbz_test")
+    cbz_directory = mm_file_tools.get_temp_dir("dvk_cbz_test")
     directory_a = abspath(join(cbz_directory, "AA"))
     directory_b = abspath(join(cbz_directory, "BB"))
     text_file = abspath(join(directory_a, "text.txt"))
     media_file = abspath(join(directory_b, "media.png"))
-    mkdir(directory_a)
-    mkdir(directory_b)
-    write_text_file(text_file, "Text in A")
-    write_text_file(media_file, "Not actually png")
+    os.mkdir(directory_a)
+    os.mkdir(directory_b)
+    mm_file_tools.write_text_file(text_file, "Text in A")
+    mm_file_tools.write_text_file(media_file, "Not actually png")
     assert exists(text_file)
     assert exists(media_file)
-    cbz_file = create_cbz(cbz_directory, "Totally Cool!")
+    cbz_file = mm_comic_archive.create_cbz(cbz_directory, "Totally Cool!")
     assert basename(cbz_file) == "Totally Cool!.cbz"
     assert exists(cbz_file)
     assert exists(directory_a)
     assert exists(directory_b)
-    extract_directory = get_temp_dir("dvk_extract_test")
-    assert extract_zip(cbz_file, extract_directory)
-    assert sorted(listdir(extract_directory)) == ["AA", "BB"]
+    extract_directory = mm_file_tools.get_temp_dir("dvk_extract_test")
+    assert mm_file_tools.extract_zip(cbz_file, extract_directory)
+    assert sorted(os.listdir(extract_directory)) == ["AA", "BB"]
     directory_a = abspath(join(extract_directory, "AA"))
     directory_b = abspath(join(extract_directory, "BB"))
-    assert listdir(directory_a) == ["text.txt"]
-    assert listdir(directory_b) == ["media.png"]
+    assert os.listdir(directory_a) == ["text.txt"]
+    assert os.listdir(directory_b) == ["media.png"]
     # Test creating CBZ with metadata
-    remove(cbz_file)
-    metadata = get_empty_metadata()
+    os.remove(cbz_file)
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "What Fun!"
     metadata["artist"] = "Person"
-    cbz_file = create_cbz(cbz_directory, "New", metadata=metadata)
-    assert sorted(listdir(cbz_directory)) == ["AA", "BB", "New.cbz"]
-    extract_directory = get_temp_dir("dvk_extract_test")
-    assert extract_zip(cbz_file, extract_directory)
-    assert sorted(listdir(extract_directory)) == ["AA", "BB", "ComicInfo.xml"]
-    read_meta = read_comic_info(abspath(join(extract_directory, "ComicInfo.xml")))
+    cbz_file = mm_comic_archive.create_cbz(cbz_directory, "New", metadata=metadata)
+    assert sorted(os.listdir(cbz_directory)) == ["AA", "BB", "New.cbz"]
+    extract_directory = mm_file_tools.get_temp_dir("dvk_extract_test")
+    assert mm_file_tools.extract_zip(cbz_file, extract_directory)
+    assert sorted(os.listdir(extract_directory)) == ["AA", "BB", "ComicInfo.xml"]
+    read_meta = mm_comic_xml.read_comic_info(abspath(join(extract_directory, "ComicInfo.xml")))
     assert read_meta["title"] == "What Fun!"
     assert read_meta["artist"] == "Person"
     # Test creating CBZ while removing remaining files
-    remove(cbz_file)
+    os.remove(cbz_file)
     media_file = abspath(join(cbz_directory, "Another_one.txt"))
-    write_text_file(media_file, "Some more text.")
+    mm_file_tools.write_text_file(media_file, "Some more text.")
     assert exists(media_file)
-    cbz_file = create_cbz(cbz_directory, "Another", metadata=metadata, remove_files=True)
-    assert listdir(cbz_directory) == ["Another.cbz"]
-    extract_directory = get_temp_dir("dvk_extract_test")
-    assert extract_zip(cbz_file, extract_directory)
-    assert sorted(listdir(extract_directory)) == ["AA", "Another_one.txt", "BB", "ComicInfo.xml"]
+    cbz_file = mm_comic_archive.create_cbz(cbz_directory, "Another", metadata=metadata, remove_files=True)
+    assert os.listdir(cbz_directory) == ["Another.cbz"]
+    extract_directory = mm_file_tools.get_temp_dir("dvk_extract_test")
+    assert mm_file_tools.extract_zip(cbz_file, extract_directory)
+    assert sorted(os.listdir(extract_directory)) == ["AA", "Another_one.txt", "BB", "ComicInfo.xml"]
     # Test creating CBZ with metadata and no subdirectories
-    cbz_directory = get_temp_dir("dvk_cbz_test")
+    cbz_directory = mm_file_tools.get_temp_dir("dvk_cbz_test")
     text_file = abspath(join(cbz_directory, "new"))
     media_file = abspath(join(cbz_directory, "things.txt"))
-    write_text_file(text_file, "NEWER")
-    write_text_file(media_file, "More things")
+    mm_file_tools.write_text_file(text_file, "NEWER")
+    mm_file_tools.write_text_file(media_file, "More things")
     assert exists(text_file)
     assert exists(media_file)
-    cbz_file = create_cbz(cbz_directory, "new", metadata=metadata, remove_files=True)
-    assert listdir(cbz_directory) == ["new.cbz"]
-    extract_directory = get_temp_dir("dvk_extract_test")
-    assert extract_zip(cbz_file, extract_directory)
-    assert sorted(listdir(extract_directory)) == ["ComicInfo.xml", "new-2"]
+    cbz_file = mm_comic_archive.create_cbz(cbz_directory, "new", metadata=metadata, remove_files=True)
+    assert os.listdir(cbz_directory) == ["new.cbz"]
+    extract_directory = mm_file_tools.get_temp_dir("dvk_extract_test")
+    assert mm_file_tools.extract_zip(cbz_file, extract_directory)
+    assert sorted(os.listdir(extract_directory)) == ["ComicInfo.xml", "new-2"]
     sub_directory = abspath(join(extract_directory, "new-2"))
-    assert sorted(listdir(sub_directory)) == ["new", "things.txt"]
+    assert sorted(os.listdir(sub_directory)) == ["new", "things.txt"]
     # Test that CBZ is only updated with new metadata if CBZ already exists
     metadata["title"] = "New!"
     metadata["tags"] = "Some, More, Stuff"
-    cbz_file = create_cbz(cbz_directory, "new", metadata=metadata)
-    assert listdir(cbz_directory) == ["new.cbz"]
-    extract_directory = get_temp_dir("dvk_extract_test")
-    assert extract_zip(cbz_file, extract_directory)
-    assert sorted(listdir(extract_directory)) == ["ComicInfo.xml", "new-2"]
+    cbz_file = mm_comic_archive.create_cbz(cbz_directory, "new", metadata=metadata)
+    assert os.listdir(cbz_directory) == ["new.cbz"]
+    extract_directory = mm_file_tools.get_temp_dir("dvk_extract_test")
+    assert mm_file_tools.extract_zip(cbz_file, extract_directory)
+    assert sorted(os.listdir(extract_directory)) == ["ComicInfo.xml", "new-2"]
     sub_directory = abspath(join(extract_directory, "new-2"))
-    assert sorted(listdir(sub_directory)) == ["new", "things.txt"]
-    read_meta = read_comic_info(abspath(join(extract_directory, "ComicInfo.xml")))
+    assert sorted(os.listdir(sub_directory)) == ["new", "things.txt"]
+    read_meta = mm_comic_xml.read_comic_info(abspath(join(extract_directory, "ComicInfo.xml")))
     assert read_meta["title"] == "New!"
     assert read_meta["tags"] == "Some,More,Stuff"
     assert read_meta["artist"] == "Person"
     # Test extra ComicInfo.xml file is not created
-    cbz_directory = get_temp_dir("dvk_cbz_test")
+    cbz_directory = mm_file_tools.get_temp_dir("dvk_cbz_test")
     text_file = abspath(join(cbz_directory, "text.txt"))
     metadata_file = abspath(join(cbz_directory, "ComicInfo.xml"))
-    write_text_file(text_file, "This is text.")
-    write_text_file(metadata_file, "metadata")
+    mm_file_tools.write_text_file(text_file, "This is text.")
+    mm_file_tools.write_text_file(metadata_file, "metadata")
     assert exists(text_file)
     assert exists(metadata_file)
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "New Metadata"
-    cbz_file = create_cbz(cbz_directory, "Meta", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_directory, "Meta", metadata=metadata)
     assert exists(cbz_file)
-    extract_directory = get_temp_dir("dvk_extract_test")
-    assert extract_zip(cbz_file, extract_directory)
-    assert sorted(listdir(extract_directory)) == ["ComicInfo.xml", "Meta"]
+    extract_directory = mm_file_tools.get_temp_dir("dvk_extract_test")
+    assert mm_file_tools.extract_zip(cbz_file, extract_directory)
+    assert sorted(os.listdir(extract_directory)) == ["ComicInfo.xml", "Meta"]
     sub_dir = abspath(join(extract_directory, "Meta"))
-    assert sorted(listdir(sub_dir)) == ["text.txt"]    
-    read_meta = get_info_from_cbz(cbz_file)
+    assert sorted(os.listdir(sub_dir)) == ["text.txt"]    
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] == "New Metadata"
     assert read_meta["artist"] is None
     # Test creating a CBZ with no files
-    cbz_directory = get_temp_dir("dvk_cbz_test")
-    assert create_cbz(cbz_directory) is None
+    cbz_directory = mm_file_tools.get_temp_dir("dvk_cbz_test")
+    assert mm_comic_archive.create_cbz(cbz_directory) is None
 
 def test_get_info_from_cbz():
     """
     Tests the get_info_from_cbz file
     """
     # Create test cbz file.
-    temp_dir = get_temp_dir()
-    metadata = get_empty_metadata()
+    temp_dir = mm_file_tools.get_temp_dir()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "CBZ Title!"
     metadata["tags"] = "Some,Tags"
     text_file = abspath(join(temp_dir, "text.txt"))
-    write_text_file(text_file, "Text")
+    mm_file_tools.write_text_file(text_file, "Text")
     assert exists(text_file)
-    cbz_file = create_cbz(temp_dir, metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(temp_dir, metadata=metadata)
     assert exists(cbz_file)
     # Test extracting the ComicInfo from .cbz file
-    read_meta = get_info_from_cbz(cbz_file)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] == "CBZ Title!"
     assert read_meta["tags"] == "Some,Tags"
     # Test trying to get ComicInfo when not present in .cbz file
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     text_file = abspath(join(temp_dir, "text.txt"))
-    write_text_file(text_file, "Total Text")
+    mm_file_tools.write_text_file(text_file, "Total Text")
     assert exists(text_file)
-    cbz_file = create_cbz(temp_dir)
-    assert len(listdir(temp_dir)) == 2
+    cbz_file = mm_comic_archive.create_cbz(temp_dir)
+    assert len(os.listdir(temp_dir)) == 2
     assert exists(cbz_file)
-    read_meta = get_info_from_cbz(cbz_file)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] is None
     assert read_meta["artist"] is None
     # Test if file is not cbz
     text_file = abspath(join(temp_dir, "text.txt"))
-    write_text_file(text_file, "Text")
-    read_meta = get_info_from_cbz(text_file)
+    mm_file_tools.write_text_file(text_file, "Text")
+    read_meta = mm_comic_archive.get_info_from_cbz(text_file)
     assert read_meta["title"] is None
     assert read_meta["artist"] is None
     # Test if ComicInfo.xml is not in the home directory
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     sub_dir = abspath(join(temp_dir, "Internal"))
     text_file = abspath(join(sub_dir, "Thing.txt"))
     metadata_file = abspath(join(sub_dir, "ComicInfo.xml"))
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Internal!"
     metadata["artist"] = "New Person"
     metadata["description"] = "Some words."
-    mkdir(sub_dir)
-    write_text_file(text_file, "Text")
-    write_text_file(metadata_file, get_comic_xml(metadata))
+    os.mkdir(sub_dir)
+    mm_file_tools.write_text_file(text_file, "Text")
+    mm_file_tools.write_text_file(metadata_file, mm_comic_xml.get_comic_xml(metadata))
     assert exists(text_file)
     assert exists(metadata_file)
     cbz_file = abspath(join(temp_dir, "manual.cbz"))
-    assert create_zip(temp_dir, cbz_file)
+    assert mm_file_tools.create_zip(temp_dir, cbz_file)
     assert exists(cbz_file)
-    read_meta = get_info_from_cbz(cbz_file)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] == "Internal!"
     assert read_meta["artist"] == "New Person"
     assert read_meta["description"] == "Some words."
     assert read_meta["publisher"] is None
     # Test getting metadata if instructed to not search subdirectories
-    assert get_info_from_cbz(cbz_file, False) == get_empty_metadata()
+    assert mm_comic_archive.get_info_from_cbz(cbz_file, False) == mm_meta_reader.get_empty_metadata()
     
 
 def test_update_cbz_info():
     """
     Tests the update_cbz_info function.
     """
     # Create a test cbz file
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     text_file = abspath(join(temp_dir, "other.txt"))
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Old Title."
     metadata["tags"] = "Some,Tags"
-    write_text_file(text_file, "This is text!")
+    mm_file_tools.write_text_file(text_file, "This is text!")
     assert exists(text_file)
-    cbz_file = create_cbz(temp_dir, metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(temp_dir, metadata=metadata)
     assert exists(cbz_file)
     # Update cbz with new info
     metadata["title"] = "New Title!!!"
     metadata["artist"] = "Dude"
     metadata["tags"] = "Something,Else"
-    update_cbz_info(cbz_file, metadata)
-    read_meta = get_info_from_cbz(cbz_file)
+    mm_comic_archive.update_cbz_info(cbz_file, metadata)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] == "New Title!!!"
     assert read_meta["artist"] == "Dude"
     assert read_meta["tags"] == "Something,Else"
     # Test that all other archived files are still present
     extract_dir = abspath(join(temp_dir, "ext"))
-    mkdir(extract_dir)
-    assert extract_zip(cbz_file, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["ComicInfo.xml", "Old Title"]
-    assert listdir(abspath(join(extract_dir, "Old Title"))) == ["other.txt"]
+    os.mkdir(extract_dir)
+    assert mm_file_tools.extract_zip(cbz_file, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["ComicInfo.xml", "Old Title"]
+    assert os.listdir(abspath(join(extract_dir, "Old Title"))) == ["other.txt"]
     # Test updating cbz that had no comic info in the first place
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     text_file = abspath(join(temp_dir, "text.txt"))
     other_file = abspath(join(temp_dir, "other.txt"))
-    write_text_file(text_file, "This is text!")
-    write_text_file(other_file, "More text!")
+    mm_file_tools.write_text_file(text_file, "This is text!")
+    mm_file_tools.write_text_file(other_file, "More text!")
     assert exists(text_file)
     assert exists(other_file)
-    cbz_file = create_cbz(temp_dir)
+    cbz_file = mm_comic_archive.create_cbz(temp_dir)
     assert exists(cbz_file)
-    read_meta = get_info_from_cbz(cbz_file)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] is None
-    update_cbz_info(cbz_file, metadata)
-    read_meta = get_info_from_cbz(cbz_file)
+    mm_comic_archive.update_cbz_info(cbz_file, metadata)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] == "New Title!!!"
     assert read_meta["artist"] == "Dude"
     assert read_meta["tags"] == "Something,Else"
     # Test that files are present
     extract_dir = abspath(join(temp_dir, "ext"))
-    mkdir(extract_dir)
-    assert extract_zip(cbz_file, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["ComicInfo.xml", "other"]
-    assert sorted(listdir(abspath(join(extract_dir, "other")))) == ["other.txt", "text.txt"]
+    os.mkdir(extract_dir)
+    assert mm_file_tools.extract_zip(cbz_file, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["ComicInfo.xml", "other"]
+    assert sorted(os.listdir(abspath(join(extract_dir, "other")))) == ["other.txt", "text.txt"]
     # Test trying to update non-cbz file
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     text_file = abspath(join(temp_dir, "text.txt"))
-    write_text_file(text_file, "Some text")
-    update_cbz_info(text_file, metadata)
+    mm_file_tools.write_text_file(text_file, "Some text")
+    mm_comic_archive.update_cbz_info(text_file, metadata)
     assert exists(text_file)
-    assert read_text_file(text_file) == "Some text"
+    assert mm_file_tools.read_text_file(text_file) == "Some text"
     # Test updating cbz with ComicInfo.xml mixed in with media files
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     sub_dir = abspath(join(temp_dir, "Internal"))
     text_file = abspath(join(sub_dir, "Thing.txt"))
     media_file = abspath(join(temp_dir, "Other.png"))
     metadata_file = abspath(join(sub_dir, "ComicInfo.xml"))
-    mkdir(sub_dir)
-    write_text_file(text_file, "Text")
-    write_text_file(media_file, "This is media")
-    write_text_file(metadata_file, get_comic_xml(metadata))
+    os.mkdir(sub_dir)
+    mm_file_tools.write_text_file(text_file, "Text")
+    mm_file_tools.write_text_file(media_file, "This is media")
+    mm_file_tools.write_text_file(metadata_file, mm_comic_xml.get_comic_xml(metadata))
     assert exists(text_file)
     assert exists(media_file)
     assert exists(metadata_file)
     cbz_file = abspath(join(temp_dir, "manual.cbz"))
-    assert create_zip(temp_dir, cbz_file)
+    assert mm_file_tools.create_zip(temp_dir, cbz_file)
     assert exists(cbz_file)
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Updated!"
     metadata["artist"] = "New"
-    update_cbz_info(cbz_file, metadata)
-    read_meta = get_info_from_cbz(cbz_file)
+    mm_comic_archive.update_cbz_info(cbz_file, metadata)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] == "Updated!"
     assert read_meta["artist"] == "New"
     assert read_meta["description"] is None
     extract_dir = abspath(join(temp_dir, "extracted"))
-    mkdir(extract_dir)
-    assert extract_zip(cbz_file, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["ComicInfo.xml", "Internal", "Other.png"]
+    os.mkdir(extract_dir)
+    assert mm_file_tools.extract_zip(cbz_file, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["ComicInfo.xml", "Internal", "Other.png"]
     sub_dir = abspath(join(extract_dir, "Internal"))
-    assert listdir(sub_dir) == ["Thing.txt"]
+    assert os.listdir(sub_dir) == ["Thing.txt"]
     # Test that updating adds the correctly named internal folder
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     text_file = abspath(join(temp_dir, "text.txt"))
-    write_text_file(text_file, "text")
+    mm_file_tools.write_text_file(text_file, "text")
     assert exists(text_file)
     cbz_file = abspath(join(temp_dir, "internal.cbz"))
-    assert create_zip(temp_dir, cbz_file)
+    assert mm_file_tools.create_zip(temp_dir, cbz_file)
     assert exists(cbz_file)
     metadata["title"] = "Should Reflect Inside."
-    update_cbz_info(cbz_file, metadata)
-    read_meta = get_info_from_cbz(cbz_file)
+    mm_comic_archive.update_cbz_info(cbz_file, metadata)
+    read_meta = mm_comic_archive.get_info_from_cbz(cbz_file)
     assert read_meta["title"] == "Should Reflect Inside."
     assert read_meta["artist"] == "New"
     assert read_meta["description"] is None
     extract_dir = abspath(join(temp_dir, "extracted"))
-    mkdir(extract_dir)
-    assert extract_zip(cbz_file, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["ComicInfo.xml", "Should Reflect Inside"]
+    os.mkdir(extract_dir)
+    assert mm_file_tools.extract_zip(cbz_file, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["ComicInfo.xml", "Should Reflect Inside"]
     sub_dir = abspath(join(extract_dir, "Should Reflect Inside"))
-    assert listdir(sub_dir) == ["text.txt"]
+    assert os.listdir(sub_dir) == ["text.txt"]
```

## Comparing `metadata_magic/test/comic_archive/test_comic_xml.py` & `metadata_magic/test/archive/test_comic_xml.py`

 * *Files 20% similar despite different names*

```diff
@@ -1,455 +1,451 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_xml import generate_info_from_jsons
-from metadata_magic.main.comic_archive.comic_xml import get_comic_xml
-from metadata_magic.main.comic_archive.comic_xml import read_comic_info
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import write_json_file
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import mkdir
+import os
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_xml as mm_comic_xml
 from os.path import abspath, exists, join
 
 def test_get_comic_xml():
     """
     Tests the get_comic_xml function.
     """
     start = "<?xml version=\"1.0\"?>\n<ComicInfo xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" "
     start = f"{start}xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\">"
     end = "<AgeRating>Unknown</AgeRating></ComicInfo>"
     # Test setting title in the XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["title"] = "This's a title\\'"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Title>This's a title\\'</Title>{end}"
     # Test setting series info in the XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["series"] = "Name!!"
     meta["series_number"] = "2.5"
     meta["series_total"] = "5"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Series>Name!!</Series><Number>2.5</Number><Count>5</Count>{end}"
     # Test setting invalid series number and total
     meta["series_number"] = "NotNumber"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Series>Name!!</Series>{end}"
     meta["series_number"] = "5.0"
     meta["series_total"] = "AlsoNotNumber"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Series>Name!!</Series><Number>5.0</Number>{end}"
     # Test setting description in the XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["description"] = "Description of the thing."
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Summary>Description of the thing.</Summary>{end}"
     meta["description"] = "'Tis this & That's >.<"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Summary>'Tis this &amp; That's &gt;.&lt;</Summary>{end}"
     # Test setting date in the XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["date"] = "2023-01-15"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Year>2023</Year><Month>1</Month><Day>15</Day>{end}"
     meta["date"] = "2014-12-08"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Year>2014</Year><Month>12</Month><Day>8</Day>{end}"
     # Test setting writer in XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["writer"] = "Person!"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Writer>Person!</Writer>{end}"
     # Test setting cover artist in XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["cover_artist"] = "Guest"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<CoverArtist>Guest</CoverArtist>{end}"
     # Test setting main artists in XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["artist"] = "Bleh"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Penciller>Bleh</Penciller><Inker>Bleh</Inker><Colorist>Bleh</Colorist>{end}"
     # Test setting publisher in XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["publisher"] = "Company"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Publisher>Company</Publisher>{end}"
     # Test setting tags in XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["tags"] = "Some,Tags,&,stuff"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Tags>Some,Tags,&amp;,stuff</Tags>{end}"
     # Test setting URL in XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["url"] = "www.ihopethisisntarealsite.com"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Web>www.ihopethisisntarealsite.com</Web>{end}"
     # Test setting the score in the XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["score"] = "0"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<CommunityRating>0</CommunityRating>{end}"
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["score"] = "2"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<CommunityRating>2</CommunityRating><Tags>&#9733;&#9733;</Tags>{end}"
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["score"] = "5"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<CommunityRating>5</CommunityRating><Tags>&#9733;&#9733;&#9733;&#9733;&#9733;</Tags>{end}"
     # Test setting invalid score in XML file
     meta["title"] = "Thing!"
     meta["score"] = "Blah"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Title>Thing!</Title>{end}"
     meta["score"] = "6"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Title>Thing!</Title>{end}"
     meta["score"] = "-3"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<Title>Thing!</Title>{end}"
     # Test adding score as tags
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["tags"] = "These,are,things"
     meta["score"] = "3"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<CommunityRating>3</CommunityRating><Tags>&#9733;&#9733;&#9733;,These,are,things</Tags>{end}"
     meta["score"] = "5"
     meta["tags"] = None
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<CommunityRating>5</CommunityRating><Tags>&#9733;&#9733;&#9733;&#9733;&#9733;</Tags>{end}"
     meta["score"] = "0"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<CommunityRating>0</CommunityRating>{end}"
     # Test setting the age rating in the XML file
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["age_rating"] = "Everyone"
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<AgeRating>Everyone</AgeRating></ComicInfo>"
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["age_rating"] = None
-    xml = get_comic_xml(meta, False)
+    xml = mm_comic_xml.get_comic_xml(meta, False)
     assert xml == f"{start}<AgeRating>Unknown</AgeRating></ComicInfo>"
     # Test getting XML with indents
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["title"] = "Name!"
-    xml = get_comic_xml(meta, True)
+    xml = mm_comic_xml.get_comic_xml(meta, True)
     result = "<?xml version=\"1.0\"?>\n"
     result = f"{result}<ComicInfo xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" "
     result = f"{result}xmlns:xsd=\"http://www.w3.org/2001/XMLSchema\">"
     result = f"{result}\n  <Title>Name!</Title>"
     result = f"{result}\n  <AgeRating>Unknown</AgeRating>\n</ComicInfo>"
     assert xml == result
 
 def test_read_comic_info():
     """
     Tests the read_comic_info function.
     """
     # Test getting title from ComicInfo
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     xml_file = abspath(join(temp_dir, "ComicInfo.xml"))
-    meta_write = get_empty_metadata()
+    meta_write = mm_meta_reader.get_empty_metadata()
     meta_write["title"] = "This is a title!"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
     assert exists(xml_file)
-    meta_read = read_comic_info(xml_file)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["series"] is None
     # Test getting series info from ComicInfo.xml
     meta_write["series"] = "The Thing"
     meta_write["series_number"] = "3.0"
     meta_write["series_total"] = "4"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["series"] == "The Thing"
     assert meta_read["series_number"] == "3.0"
     assert meta_read["series_total"] == "4"
     assert meta_read["description"] is None
     # Test getting description from ComicInfo.xml
     meta_write["description"] = "Some words and such."
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["description"] == "Some words and such."
     assert meta_read["date"] is None
     meta_write["description"] = "'Tis this & That\\Other >.<"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["description"] == "'Tis this & That\\Other >.<"
     assert meta_read["date"] is None
     # Test getting date from ComicInfo.xml
     meta_write["date"] = "2012-03-09"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["date"] == "2012-03-09"
     assert meta_read["writer"] is None
     meta_write["date"] = "2021-12-12"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["date"] == "2021-12-12"
     assert meta_read["writer"] is None
     # Test getting writer from ComicInfo.xml
     meta_write["writer"] = "Author Dude"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["writer"] == "Author Dude"
     assert meta_read["cover_artist"] is None
     # Test getting cover artist from ComicInfo.xml
     meta_write["cover_artist"] = "Person"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["cover_artist"] == "Person"
     assert meta_read["artist"] is None
     # Test getting main artist from ComicInfo.xml
     meta_write["artist"] = "ArtGirl"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["artist"] == "ArtGirl"
     assert meta_read["publisher"] is None
     # Test getting the publisher from ComicInfo.xml
     meta_write["publisher"] = "Website"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["publisher"] == "Website"
     assert meta_read["url"] is None
     # Test getting url from ComicInfo.xml
     meta_write["url"] = "/web/page/"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["url"] == "/web/page/"
     assert meta_read["tags"] is None
     assert meta_read["age_rating"] == "Unknown"
     # Test getting age rating from ComicInfo.xml
     meta_write["age_rating"] = "Everyone"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["age_rating"] == "Everyone"
     assert meta_read["tags"] is None
     # Test getting score from ComicInfo.xml
     meta_write["score"] = "4"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "This is a title!"
     assert meta_read["score"] == "4"
     assert meta_read["tags"] == None
     # Test getting tags from ComicInfo.xml
     meta_write["title"] = None
     meta_write["tags"] = " these, are , some tags  "
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["tags"] == "these,are,some tags"
     assert meta_read["title"] is None
     # Test that any star score tags are removed
     meta_write["title"] = "Hooray!"
     meta_write["tags"] = "★★★★"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["title"] == "Hooray!"
     assert meta_read["tags"] == None
     meta_write["tags"] = "★, Some,Tags!,Yay"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["tags"] == "Some,Tags!,Yay"
     meta_write["tags"] = "More, tags, and, such, ★★★"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["tags"] == "More,tags,and,such"
     meta_write["tags"] = "Other, ★★★★★, Final "
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["tags"] == "Other,Final"
     meta_write["tags"] = "Larger,Star,Count,★★★★★★★★★★"
-    xml = get_comic_xml(meta_write, False)
-    write_text_file(xml_file, xml)
-    meta_read = read_comic_info(xml_file)
+    xml = mm_comic_xml.get_comic_xml(meta_write, False)
+    mm_file_tools.write_text_file(xml_file, xml)
+    meta_read = mm_comic_xml.read_comic_info(xml_file)
     assert meta_read["tags"] == "Larger,Star,Count,★★★★★★★★★★"
     # Test if given file is not a proper XML file
     unrelated = abspath(join(temp_dir, "blah.xml"))
-    write_text_file(unrelated, "This is some unimportant non-xml text.")
+    mm_file_tools.write_text_file(unrelated, "This is some unimportant non-xml text.")
     assert exists(unrelated)
-    meta_read = read_comic_info(unrelated)
+    meta_read = mm_comic_xml.read_comic_info(unrelated)
     assert meta_read["title"] is None
     assert meta_read["series"] is None
 
 def test_generate_info_from_jsons():
     """
     Tests the generate_info_from_jsons function.
     """
     # Test getting title
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     sub_dir = abspath(join(temp_dir, "sub"))
-    mkdir(sub_dir)
+    os.mkdir(sub_dir)
     main_media = abspath(join(temp_dir, "json.txt"))
     main_json = abspath(join(temp_dir, "json.json"))
     sub_media = abspath(join(sub_dir, "blah.png"))
     sub_json = abspath(join(sub_dir, "blah.json"))
     json_meta = {"title":"This is a title!"}
-    write_text_file(main_media, "This is text")
-    write_json_file(main_json, json_meta)
-    write_text_file(sub_media, "Not actually an image")
-    write_json_file(sub_json, {"no":"info"})
+    mm_file_tools.write_text_file(main_media, "This is text")
+    mm_file_tools.write_json_file(main_json, json_meta)
+    mm_file_tools.write_text_file(sub_media, "Not actually an image")
+    mm_file_tools.write_json_file(sub_json, {"no":"info"})
     assert exists(main_media)
     assert exists(main_json)
     assert exists(sub_media)
     assert exists(sub_json)
-    meta = generate_info_from_jsons(temp_dir)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "This is a title!"
     assert meta["artist"] is None
     assert meta["description"] is None
     # Test getting description
     json_meta["description"] = "Some caption."
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "This is a title!"
     assert meta["description"] == "Some caption."
     assert meta["date"] is None
     assert meta["cover_artist"] is None
     # Test simplifying description with HTML info contained
     json_meta["description"] = "Let's say there's a <a href='ajsdlf'>link</a>.<br>Other!!"
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["description"] == "Let's say there's a link. Other!!"
     json_meta["description"] = "<div><p>Way too many tags!</p><br>\n<br/> <b>B</b>ut it's <i>o</i>kay right?</div>"
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["description"] == "Way too many tags! But it's okay right?"
     json_meta["description"] = "What about 'em elements &amp; such? &gt;.&gt;"
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["description"] == "What about 'em elements & such? >.>"
     # Test getting date
     json_meta["date"] = "2012-12-21"
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "This is a title!"
     assert meta["date"] == "2012-12-21"
     assert meta["cover_artist"] is None
     # Test getting artist data
     json_meta["artist"] = "Person!"
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "This is a title!"
     assert meta["writer"] == "Person!"
     assert meta["cover_artist"] == "Person!"
     assert meta["artist"] == "Person!"
     assert meta["publisher"] is None
     # Test getting publisher
     json_meta["url"] = "youtube.com/something"
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "This is a title!"
     assert meta["publisher"] == "YouTube"
     assert meta["tags"] is None
     # Test getting tags
     json_meta["tags"] = ["These", "Are", "Tags"]
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "This is a title!"
     assert meta["tags"] == "These,Are,Tags"
     json_meta["tags"] = ["Tag"]
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["tags"] == "Tag"
     json_meta["tags"] = []
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["tags"] is None
     # Test getting url
     json_meta["url"] = "someurlthing.net"
-    write_json_file(main_json, json_meta)
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(main_json, json_meta)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "This is a title!"
     assert meta["url"] == "someurlthing.net"
     assert meta["tags"] is None
     assert meta["age_rating"] == "Unknown"
     # Test getting age rating
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     media_everyone = abspath(join(temp_dir, "everyone.png"))
     json_everyone = abspath(join(temp_dir, "everyone.json"))
-    write_text_file(media_everyone, "E For All")
-    write_json_file(json_everyone, {"title":"Thing!", "url":"newgrounds.com/", "rating":"E"})
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_text_file(media_everyone, "E For All")
+    mm_file_tools.write_json_file(json_everyone, {"title":"Thing!", "url":"newgrounds.com/", "rating":"E"})
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "Thing!"
     assert meta["age_rating"] == "Everyone"
     media_teen = abspath(join(temp_dir, "teen.gif"))
     json_teen = abspath(join(temp_dir, "teen.json"))
-    write_json_file(media_teen, "Edgy")
-    write_json_file(json_teen, {"rating":"t", "url":"www.newgrounds.com"})
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_json_file(media_teen, "Edgy")
+    mm_file_tools.write_json_file(json_teen, {"rating":"t", "url":"www.newgrounds.com"})
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["age_rating"] == "Teen"
     media_mature = abspath(join(temp_dir, "mature.txt"))
     json_mature = abspath(join(temp_dir, "mature.json"))
-    write_text_file(media_mature, "Blood Bleeder")
-    write_json_file(json_mature, {"url":"newgrounds", "rating":"m"})
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_text_file(media_mature, "Blood Bleeder")
+    mm_file_tools.write_json_file(json_mature, {"url":"newgrounds", "rating":"m"})
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["age_rating"] == "Mature 17+"
     media_adult = abspath(join(temp_dir, "adult.png"))
     json_adult = abspath(join(temp_dir, "adult.json"))
-    write_text_file(media_adult, "AAAAAAAAAA!")
-    write_json_file(json_adult, {"url":"www.newgrounds.com/thing", "rating":"A"})
-    meta = generate_info_from_jsons(temp_dir)
+    mm_file_tools.write_text_file(media_adult, "AAAAAAAAAA!")
+    mm_file_tools.write_json_file(json_adult, {"url":"www.newgrounds.com/thing", "rating":"A"})
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["age_rating"] == "X18+"
     assert exists(json_everyone)
     assert exists(json_teen)
     assert exists(json_mature)
     assert exists(json_adult)
     # Test with JSON files only in subdirectories
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     sub1 = abspath(join(temp_dir, "aaaa"))
     sub2 = abspath(join(temp_dir, "bbbb"))
     main_media = abspath(join(sub1, "thing.png"))
     main_json = abspath(join(sub1, "thing.json"))
     sub_media = abspath(join(sub2, "first.txt"))
     sub_json = abspath(join(sub2, "first.json"))
-    mkdir(sub1)
-    mkdir(sub2)
-    write_text_file(main_media, "Main File")
-    write_json_file(main_json, {"title":"Real Title."})
-    write_text_file(sub_media, "Sub file")
-    write_json_file(sub_json, {"title":"Not this one."})
+    os.mkdir(sub1)
+    os.mkdir(sub2)
+    mm_file_tools.write_text_file(main_media, "Main File")
+    mm_file_tools.write_json_file(main_json, {"title":"Real Title."})
+    mm_file_tools.write_text_file(sub_media, "Sub file")
+    mm_file_tools.write_json_file(sub_json, {"title":"Not this one."})
     assert exists(main_media)
     assert exists(main_json)
     assert exists(sub_media)
     assert exists(sub_json)
-    meta = generate_info_from_jsons(temp_dir)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] == "Real Title."
     # Test with no JSON files
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     test_file = abspath(join(temp_dir, "File!.txt"))
-    write_text_file(test_file, "Blah.")
+    mm_file_tools.write_text_file(test_file, "Blah.")
     assert exists(test_file)
-    meta = generate_info_from_jsons(temp_dir)
+    meta = mm_comic_xml.generate_info_from_jsons(temp_dir)
     assert meta["title"] is None
     assert meta["description"] is None
     assert meta["date"] is None
     assert meta["writer"] is None
     assert meta["artist"] is None
     assert meta["cover_artist"] is None
     assert meta["publisher"] is None
```

## Comparing `metadata_magic/test/comic_archive/test_extract_all.py` & `metadata_magic/test/archive/test_extract_all.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,96 +1,95 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_archive import create_cbz
-from metadata_magic.main.comic_archive.extract_all import extract_all
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import listdir, mkdir
+import os
+import shutil
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_archive as mm_comic_archive
+import metadata_magic.archive.extract_all as mm_extract_all
 from os.path import abspath, exists, join
-from shutil import copytree, move, rmtree
 
 def test_extract_all():
     """
     Tests the extract_all function.
     """
     # Create test cbz files
-    temp_dir = get_temp_dir()
-    cbz_builder = get_temp_dir("dvk_test_cbz_builder")
+    temp_dir = mm_file_tools.get_temp_dir()
+    cbz_builder = mm_file_tools.get_temp_dir("dvk_test_cbz_builder")
     text_file = abspath(join(cbz_builder, "text.txt"))
-    write_text_file(text_file, "This is text.")
+    mm_file_tools.write_text_file(text_file, "This is text.")
     assert exists(text_file)
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Some Title"
-    cbz_file = create_cbz(cbz_builder, "One", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_builder, "One", metadata=metadata)
     assert exists(cbz_file)
-    move(cbz_file, abspath(join(temp_dir, "simple.cbz")))
-    cbz_builder = get_temp_dir("dvk_test_cbz_builder")
+    shutil.move(cbz_file, abspath(join(temp_dir, "simple.cbz")))
+    cbz_builder = mm_file_tools.get_temp_dir("dvk_test_cbz_builder")
     sub_dir_1 = abspath(join(cbz_builder, "1-sub"))
     sub_dir_2 = abspath(join(cbz_builder, "2-sub"))
     media_file = abspath(join(sub_dir_1, "media.png"))
     text_file = abspath(join(sub_dir_2, "text.txt"))
-    mkdir(sub_dir_1)
-    mkdir(sub_dir_2)
-    write_text_file(media_file, "Media")
-    write_text_file(text_file, "Text")
+    os.mkdir(sub_dir_1)
+    os.mkdir(sub_dir_2)
+    mm_file_tools.write_text_file(media_file, "Media")
+    mm_file_tools.write_text_file(text_file, "Text")
     assert exists(media_file)
     assert exists(text_file)
-    cbz_file = create_cbz(cbz_builder, "Two", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_builder, "Two", metadata=metadata)
     assert exists(cbz_file)
-    move(cbz_file, abspath(join(temp_dir, "subs.cbz")))
-    assert sorted(listdir(temp_dir)) == ["simple.cbz", "subs.cbz"]
+    shutil.move(cbz_file, abspath(join(temp_dir, "subs.cbz")))
+    assert sorted(os.listdir(temp_dir)) == ["simple.cbz", "subs.cbz"]
     # Test extracting cbz files
-    temp_dir_2 = get_temp_dir("dvk_test_extract")
+    temp_dir_2 = mm_file_tools.get_temp_dir("dvk_test_extract")
     extract_dir = abspath(join(temp_dir_2, "new"))
-    copytree(temp_dir, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
-    extract_all(extract_dir, remove_internals=False)
-    assert sorted(listdir(extract_dir)) == ["simple", "subs"]
+    shutil.copytree(temp_dir, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
+    mm_extract_all.extract_all(extract_dir, remove_internals=False)
+    assert sorted(os.listdir(extract_dir)) == ["simple", "subs"]
     sub_dir = abspath(join(extract_dir, "simple"))
-    assert sorted(listdir(sub_dir)) == ["ComicInfo.xml", "One"]
-    assert listdir(abspath(join(sub_dir, "One"))) == ["text.txt"]
+    assert sorted(os.listdir(sub_dir)) == ["ComicInfo.xml", "One"]
+    assert os.listdir(abspath(join(sub_dir, "One"))) == ["text.txt"]
     sub_dir = abspath(join(extract_dir, "subs"))
-    assert sorted(listdir(sub_dir)) == ["1-sub", "2-sub", "ComicInfo.xml"]
-    assert listdir(abspath(join(sub_dir, "1-sub"))) == ["media.png"]
-    assert listdir(abspath(join(sub_dir, "2-sub"))) == ["text.txt"]
+    assert sorted(os.listdir(sub_dir)) == ["1-sub", "2-sub", "ComicInfo.xml"]
+    assert os.listdir(abspath(join(sub_dir, "1-sub"))) == ["media.png"]
+    assert os.listdir(abspath(join(sub_dir, "2-sub"))) == ["text.txt"]
     # Test extracting cbz files while removing the ComicInfo.xml file
-    rmtree(extract_dir)
-    copytree(temp_dir, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
-    extract_all(extract_dir, remove_internals=False, remove_metadata=True)
-    assert sorted(listdir(extract_dir)) == ["simple", "subs"]
+    shutil.rmtree(extract_dir)
+    shutil.copytree(temp_dir, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
+    mm_extract_all.extract_all(extract_dir, remove_internals=False, remove_metadata=True)
+    assert sorted(os.listdir(extract_dir)) == ["simple", "subs"]
     sub_dir = abspath(join(extract_dir, "simple"))
-    assert sorted(listdir(sub_dir)) == ["One"]
-    assert listdir(abspath(join(sub_dir, "One"))) == ["text.txt"]
+    assert sorted(os.listdir(sub_dir)) == ["One"]
+    assert os.listdir(abspath(join(sub_dir, "One"))) == ["text.txt"]
     sub_dir = abspath(join(extract_dir, "subs"))
-    assert sorted(listdir(sub_dir)) == ["1-sub", "2-sub"]
-    assert listdir(abspath(join(sub_dir, "1-sub"))) == ["media.png"]
-    assert listdir(abspath(join(sub_dir, "2-sub"))) == ["text.txt"]
+    assert sorted(os.listdir(sub_dir)) == ["1-sub", "2-sub"]
+    assert os.listdir(abspath(join(sub_dir, "1-sub"))) == ["media.png"]
+    assert os.listdir(abspath(join(sub_dir, "2-sub"))) == ["text.txt"]
     # Test extracting cbz into the base directory
-    rmtree(extract_dir)
-    copytree(temp_dir, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
-    extract_all(extract_dir, create_folders=False, remove_internals=False)
-    assert sorted(listdir(extract_dir)) == ["1-sub", "2-sub", "One"]
-    assert listdir(abspath(join(extract_dir, "1-sub"))) == ["media.png"]
-    assert listdir(abspath(join(extract_dir, "2-sub"))) == ["text.txt"]
-    assert listdir(abspath(join(extract_dir, "One"))) == ["text.txt"]
+    shutil.rmtree(extract_dir)
+    shutil.copytree(temp_dir, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
+    mm_extract_all.extract_all(extract_dir, create_folders=False, remove_internals=False)
+    assert sorted(os.listdir(extract_dir)) == ["1-sub", "2-sub", "One"]
+    assert os.listdir(abspath(join(extract_dir, "1-sub"))) == ["media.png"]
+    assert os.listdir(abspath(join(extract_dir, "2-sub"))) == ["text.txt"]
+    assert os.listdir(abspath(join(extract_dir, "One"))) == ["text.txt"]
     # Test extracting cbz files without the internal folder
-    rmtree(extract_dir)
-    copytree(temp_dir, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
-    extract_all(extract_dir, remove_internals=True, remove_metadata=True)
-    assert sorted(listdir(extract_dir)) == ["simple", "subs"]
-    assert listdir(abspath(join(extract_dir, "simple"))) == ["text.txt"]
+    shutil.rmtree(extract_dir)
+    shutil.copytree(temp_dir, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
+    mm_extract_all.extract_all(extract_dir, remove_internals=True, remove_metadata=True)
+    assert sorted(os.listdir(extract_dir)) == ["simple", "subs"]
+    assert os.listdir(abspath(join(extract_dir, "simple"))) == ["text.txt"]
     sub_dir = abspath(join(extract_dir, "subs"))
-    assert sorted(listdir(sub_dir)) == ["1-sub", "2-sub"]
-    assert listdir(abspath(join(sub_dir, "1-sub"))) == ["media.png"]
-    assert listdir(abspath(join(sub_dir, "2-sub"))) == ["text.txt"]
+    assert sorted(os.listdir(sub_dir)) == ["1-sub", "2-sub"]
+    assert os.listdir(abspath(join(sub_dir, "1-sub"))) == ["media.png"]
+    assert os.listdir(abspath(join(sub_dir, "2-sub"))) == ["text.txt"]
     # Test extracting files without internal folder directly into the base directory
-    rmtree(extract_dir)
-    copytree(temp_dir, extract_dir)
-    assert sorted(listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
-    extract_all(extract_dir, create_folders=False, remove_internals=True, remove_metadata=True)
-    assert sorted(listdir(extract_dir)) == ["1-sub", "2-sub", "text.txt"]
-    assert listdir(abspath(join(extract_dir, "1-sub"))) == ["media.png"]
-    assert listdir(abspath(join(extract_dir, "2-sub"))) == ["text.txt"]
+    shutil.rmtree(extract_dir)
+    shutil.copytree(temp_dir, extract_dir)
+    assert sorted(os.listdir(extract_dir)) == ["simple.cbz", "subs.cbz"]
+    mm_extract_all.extract_all(extract_dir, create_folders=False, remove_internals=True, remove_metadata=True)
+    assert sorted(os.listdir(extract_dir)) == ["1-sub", "2-sub", "text.txt"]
+    assert os.listdir(abspath(join(extract_dir, "1-sub"))) == ["media.png"]
+    assert os.listdir(abspath(join(extract_dir, "2-sub"))) == ["text.txt"]
```

## Comparing `metadata_magic/test/epub/test_epub.py` & `metadata_magic/test/archive/test_epub.py`

 * *Files 3% similar despite different names*

```diff
@@ -1,95 +1,78 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.epub.epub import create_epub
-from metadata_magic.main.epub.epub import create_epub_files
-from metadata_magic.main.epub.epub import create_image_page
-from metadata_magic.main.epub.epub import create_nav_file
-from metadata_magic.main.epub.epub import create_ncx_file
-from metadata_magic.main.epub.epub import create_manifest
-from metadata_magic.main.epub.epub import create_metadata_xml
-from metadata_magic.main.epub.epub import create_style_file
-from metadata_magic.main.epub.epub import format_xhtml
-from metadata_magic.main.epub.epub import get_title_from_file
-from metadata_magic.main.epub.epub import html_to_xhtml
-from metadata_magic.main.epub.epub import newline_to_tag
-from metadata_magic.main.epub.epub import txt_to_xhtml
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import extract_zip
-from metadata_magic.main.file_tools.file_tools import read_text_file
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from metadata_magic.main.rename.rename_tools import sort_alphanum
-from os import listdir, mkdir
+import os
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.epub as mm_epub
 from os.path import abspath, basename, exists, isdir, join
-
 from PIL import Image
 
 def test_newline_to_tag():
     """
     Tests the newline_to_tag function.
     """
-    assert newline_to_tag("\n") == "{{{br}}}"
-    assert newline_to_tag("\n\n\n") == "{{{br}}}{{{br}}}{{{br}}}"
-    assert newline_to_tag("\n\n\n\n\n") == "{{{br}}}{{{br}}}{{{br}}}{{{br}}}{{{br}}}"
-    assert newline_to_tag("\n\n") == "{{{br}}}{{{br}}}"
+    assert mm_epub.newline_to_tag("\n") == "{{{br}}}"
+    assert mm_epub.newline_to_tag("\n\n\n") == "{{{br}}}{{{br}}}{{{br}}}"
+    assert mm_epub.newline_to_tag("\n\n\n\n\n") == "{{{br}}}{{{br}}}{{{br}}}{{{br}}}{{{br}}}"
+    assert mm_epub.newline_to_tag("\n\n") == "{{{br}}}{{{br}}}"
 
 def test_get_title_from_file():
     """
     Tests the get_title_from_file function.
     """
-    temp_file = get_temp_dir()
+    temp_file = mm_file_tools.get_temp_dir()
     filename = abspath(join(temp_file, "thing.txt"))
-    assert get_title_from_file(filename) == "thing"
+    assert mm_epub.get_title_from_file(filename) == "thing"
     filename = abspath(join(temp_file, "[00] Image  .png"))
-    assert get_title_from_file(filename) == "Image"
+    assert mm_epub.get_title_from_file(filename) == "Image"
     filename = abspath(join(temp_file, "[This is a thing] Cover"))
-    assert get_title_from_file(filename) == "Cover"
+    assert mm_epub.get_title_from_file(filename) == "Cover"
     filename = abspath(join(temp_file, "none"))
-    assert get_title_from_file(filename) == "none"
+    assert mm_epub.get_title_from_file(filename) == "none"
 
 def test_format_xhtml():
     """
     Tests the format_xhtml function.
     """
     # Test single tag
     start = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<html xmlns=\"http://www.w3.org/1999/xhtml\">"
     head = "<head><title>Title!</title><meta charset=\"utf-8\" />"
     head = f"{head}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" /></head>"
     html = "<p>This is a simple test &amp; stuff</p>"
-    xhtml = format_xhtml(html, "Title!", indent=False)
+    xhtml = mm_epub.format_xhtml(html, "Title!", indent=False)
     assert xhtml == f"{start}{head}<body><p>This is a simple test &amp; stuff</p></body></html>"
     # Test with multiple tags
     html = "<p>Multiple</p><p>Paragraphs!!!</p>"
-    xhtml = format_xhtml(html, "Title!", indent=False)
+    xhtml = mm_epub.format_xhtml(html, "Title!", indent=False)
     assert xhtml == f"{start}{head}<body><p>Multiple</p><p>Paragraphs!!!</p></body></html>"
     # Test with no tags
     head = "<head><title>Title thing.</title><meta charset=\"utf-8\" />"
     head = f"{head}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" /></head>"
     html = "This is a thing.<br/><br/>Final thing."
-    xhtml = format_xhtml(html, "Title thing.", indent=False)
+    xhtml = mm_epub.format_xhtml(html, "Title thing.", indent=False)
     assert xhtml == f"{start}{head}<body>This is a thing.<br /><br />Final thing.</body></html>"
     # Test with spaces and newlines
     html = "  <p>  This is a thing!  </p>\n  <div> Another </div> "
-    xhtml = format_xhtml(html, "Title thing.", indent=False)
+    xhtml = mm_epub.format_xhtml(html, "Title thing.", indent=False)
     assert xhtml == f"{start}{head}<body><p>  This is a thing!  </p>  <div> Another </div></body></html>"
     # Test header tags
     html="<p>bleh</p>"
     tags = [{"type":"thing", "params":{"class":"name"}}, {"type":"meta", "params":{"item":"other"}}]
-    xhtml = format_xhtml(html, "Name", tags, indent=False)
+    xhtml = mm_epub.format_xhtml(html, "Name", tags, indent=False)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>"
     compare = f"{compare}<title>Name</title><meta charset=\"utf-8\" />"
     compare = f"{compare}<thing class=\"name\" /><meta item=\"other\" />"
     compare = f"{compare}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />"
     compare = f"{compare}</head><body><p>bleh</p></body></html>"
     assert xhtml == compare
     # Test adding indent
     html = "<p>These</p><p>Are</p><p>Paragraphs!</p>"
-    xhtml = format_xhtml(html, "New", indent=True)
+    xhtml = mm_epub.format_xhtml(html, "New", indent=True)
     xml = f"{start}\n"
     xml = f"{xml}   <head>\n"
     xml = f"{xml}      <title>New</title>\n"
     xml = f"{xml}      <meta charset=\"utf-8\" />\n"
     xml = f"{xml}      <link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />\n"
     xml = f"{xml}   </head>\n"
     xml = f"{xml}   <body>\n"
@@ -101,53 +84,53 @@
     assert xml == xhtml
 
 def test_create_image_page():
     """
     Tests the create_image_page function.
     """
     # Create image files
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     png_file = abspath(join(temp_dir, "[00] Cover.png"))
     jpg_file = abspath(join(temp_dir, "thing.jpg"))
     png_image = Image.new("RGB", (360, 480), color=(255,0,0))
     jpg_image = Image.new("RGB", (500, 300), color=(0,255,0))
     png_image.save(png_file)
     jpg_image.save(jpg_file)
     assert exists(png_file)
     assert exists(jpg_file)
     # Test with vertical image
-    chapter = create_image_page(png_file, False)
+    chapter = mm_epub.create_image_page(png_file, False)
     body = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     body = f"{body}<html xmlns=\"http://www.w3.org/1999/xhtml\">"
     body = f"{body}<head><title>Cover</title><meta charset=\"utf-8\" />"
     body = f"{body}<meta content=\"width=360, height=480\" name=\"viewport\" />"
     body = f"{body}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />"
     body = f"{body}</head><body><div class=\"image-page-container\">"
     body = f"{body}<img class=\"vertical-image-page\" src=\"../images/[00] Cover.png\" alt=\"Cover\" />"
     body = f"{body}</div></body></html>"
     assert chapter == body
     # Test with horizontal image
-    chapter = create_image_page(jpg_file, False)
+    chapter = mm_epub.create_image_page(jpg_file, False)
     body = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     body = f"{body}<html xmlns=\"http://www.w3.org/1999/xhtml\">"
     body = f"{body}<head><title>thing</title><meta charset=\"utf-8\" />"
     body = f"{body}<meta content=\"width=500, height=300\" name=\"viewport\" />"
     body = f"{body}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />"
     body = f"{body}</head><body><div class=\"image-page-container\">"
     body = f"{body}<img class=\"horizontal-image-page\" src=\"../images/thing.jpg\" alt=\"thing\" />"
     body = f"{body}</div></body></html>"
     assert chapter == body
     # Test with invalid image file
     text_file = abspath(join(temp_dir, "thing.png"))
-    write_text_file(text_file, "Some Text")
+    mm_file_tools.write_text_file(text_file, "Some Text")
     assert exists(text_file)
-    assert create_image_page(text_file) is None
-    assert create_image_page("/non/existant/thing.png") is None
+    assert mm_epub.create_image_page(text_file) is None
+    assert mm_epub.create_image_page("/non/existant/thing.png") is None
     # Test with indents
-    chapter = create_image_page(jpg_file, True)
+    chapter = mm_epub.create_image_page(jpg_file, True)
     body = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     body = f"{body}<html xmlns=\"http://www.w3.org/1999/xhtml\">\n"
     body = f"{body}   <head>\n"
     body = f"{body}      <title>thing</title>\n"
     body = f"{body}      <meta charset=\"utf-8\" />\n"
     body = f"{body}      <meta content=\"width=500, height=300\" name=\"viewport\" />\n"
     body = f"{body}      <link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />\n"
@@ -161,48 +144,48 @@
     assert chapter == body
 
 def test_html_to_xhtml():
     """
     Tests the html_to_xml function.
     """
     # Test HTML inside a body
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     html_file = abspath(join(temp_dir, "thing.html"))
     text = "<!DOCTYPE html><html><body><p>This is text!</p><br><p><b>YAY!</b></p></body></html>"
-    write_text_file(html_file, text)
+    mm_file_tools.write_text_file(html_file, text)
     assert exists(html_file)
-    contents = html_to_xhtml(html_file, indent=False)
+    contents = mm_epub.html_to_xhtml(html_file, indent=False)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>"
     compare = f"{compare}<title>thing</title><meta charset=\"utf-8\" />"
     compare = f"{compare}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" "
     compare = f"{compare}type=\"text/css\" /></head><body>"
     compare = f"{compare}<div class=\"text-container\"><p>This is text!</p>"
     compare = f"{compare}<br /><p><b>YAY!</b></p></div></body></html>"
     assert contents == compare
     # Test simple HTML with no body
     html_file = abspath(join(temp_dir, "New.htm"))
     text = "<b>A thing</b> and Thing.<hr>Other!"
-    write_text_file(html_file, text)
+    mm_file_tools.write_text_file(html_file, text)
     assert exists(html_file)
-    contents = html_to_xhtml(html_file, indent=False)
+    contents = mm_epub.html_to_xhtml(html_file, indent=False)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\">"
     compare = f"{compare}<head><title>New</title><meta charset=\"utf-8\" />"
     compare = f"{compare}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" "
     compare = f"{compare}type=\"text/css\" /></head><body>"
     compare = f"{compare}<div class=\"text-container\"><b>A thing</b> and Thing."
     compare = f"{compare}<hr />Other!</div></body></html>"
     assert contents == compare
     # Test adding indents
     html_file = abspath(join(temp_dir, "Final.htm"))
     text = "Some Words..."
-    write_text_file(html_file, text)
+    mm_file_tools.write_text_file(html_file, text)
     assert exists(html_file)
-    contents = html_to_xhtml(html_file, indent=True)
+    contents = mm_epub.html_to_xhtml(html_file, indent=True)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\">\n"
     compare = f"{compare}   <head>\n"
     compare = f"{compare}      <title>Final</title>\n"
     compare = f"{compare}      <meta charset=\"utf-8\" />\n"
     compare = f"{compare}      <link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />\n"
     compare = f"{compare}   </head>\n"
@@ -215,97 +198,97 @@
     assert contents == compare
 
 def test_txt_to_xhtml():
     """
     Tests the txt_to_xhtml function.
     """
     # Test a single paragraph
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     text_file = abspath(join(temp_dir, "Text.txt"))
     text = "This is a simple sentence!"
-    write_text_file(text_file, text)
+    mm_file_tools.write_text_file(text_file, text)
     assert exists(text_file)
-    chapter = txt_to_xhtml(text_file, indent=False)
+    chapter = mm_epub.txt_to_xhtml(text_file, indent=False)
     head = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     head = f"{head}<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>"
     head = f"{head}<title>Text</title><meta charset=\"utf-8\" />"
     head = f"{head}<link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />"
     head = f"{head}</head>"
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>This is a simple sentence!</p></div></body></html>"
     assert chapter == body
     # Test multiple paragraphs
     text = "Different paragraphs!\n\nHow cool!"
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>Different paragraphs!</p><p>How cool!</p></div></body></html>"
     assert chapter == body
     # Test single new line character
     text = "More text!\nAnd This & That..."
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>More text!<br />And This &amp; That...</p></div></body></html>"
     assert chapter == body
     # Test new lines and separate paragraphs
     text = "Paragraph\n\nOther\nText!\n\nFinal\nParagraph..."
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>Paragraph</p><p>Other<br />Text!</p>"
     body = f"{body}<p>Final<br />Paragraph...</p></div></body></html>"
     assert chapter == body
     # Test with more than one two new lines
     text = "Thing\n\n\nOther"
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = "<body><div class=\"text-container\"><p>Thing<br/><br/><br/>Other</p></div></body>"
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>Thing<br /><br /><br />Other</p></div></body></html>"
     assert chapter == body
     text = "Thing\n\n\nOther\n\nParagraph\n\n\n\nNext"
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>Thing<br /><br /><br />Other</p>"
     body = f"{body}<p>Paragraph<br /><br /><br /><br />Next</p></div></body></html>"
     assert chapter == body
     # Test removing text stand-ins for HTML tags
     text = "{{i}}Title{{/i}}{{br}}{{b}}Thing{{/b}}"
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p><i>Title</i><br /><b>Thing</b></p></div></body></html>"
     assert chapter == body
     # Remove dangling paragraph tags
     text = "Text  \n\nThing {{br}} {{br}}"
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>Text</p><p>Thing</p></div></body></html>"
     assert chapter == body
     # Remove dangling italic/bold tags tags
     text = "This is a {{b}}fine{{/b}} sentence."
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>This is a <b>fine</b> sentence.</p></div></body></html>"
     assert chapter == body
     text = "Some {{b}}words {{/b}} , should {{i}}change{{/i}}  ."
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, False)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, False)
     body = f"{head}<body><div class=\"text-container\">"
     body = f"{body}<p>Some <b>words</b>, should <i>change</i>.</p></div></body></html>"
     assert chapter == body
     # Test with indent
     text = "These are...\n\nwords."
     text_file = abspath(join(temp_dir, "[01] New Thing.txt"))
-    write_text_file(text_file, text)
-    chapter = txt_to_xhtml(text_file, True)
+    mm_file_tools.write_text_file(text_file, text)
+    chapter = mm_epub.txt_to_xhtml(text_file, True)
     body = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     body = f"{body}<html xmlns=\"http://www.w3.org/1999/xhtml\">\n"
     body = f"{body}   <head>\n"
     body = f"{body}      <title>New Thing</title>\n"
     body = f"{body}      <meta charset=\"utf-8\" />\n"
     body = f"{body}      <link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />\n"
     body = f"{body}   </head>\n"
@@ -318,21 +301,21 @@
     body = f"{body}</html>"
     assert chapter == body
 
 def test_create_style_file():
     """
     Tests the create_style_file function()
     """
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     css_file = abspath(join(temp_dir, "epubstyle.css"))
     assert not exists(css_file)
-    create_style_file(css_file)
+    mm_epub.create_style_file(css_file)
     assert exists(css_file)
     # Test contents of the css file
-    style = read_text_file(css_file)
+    style = mm_file_tools.read_text_file(css_file)
     compare = "body {\n"
     compare = f"{compare}    margin: 0px 0px 0px 0px;\n"
     compare = f"{compare}}}\n\n"
     compare = f"{compare}.header {{\n"
     compare = f"{compare}    width: 100%;\n"
     compare = f"{compare}    font-size: 2em;\n"
     compare = f"{compare}    line-height: 1.5em;\n"
@@ -368,38 +351,38 @@
 
 def test_create_nav_file():
     """
     Tests the create_nav_file function.
     """
     # Test creating nav file
     xhtmls = []
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     xhtmls.append(abspath(join(temp_dir, "[00] Cover.xhtml")))
     xhtmls.append(abspath(join(temp_dir, "Chapter 1.xhtml")))
     xhtmls.append(abspath(join(temp_dir, "Chapter 2.xhtml")))
     xhtmls.append(abspath(join(temp_dir, "Epilogues.xhtml")))
     nav_file = abspath(join(temp_dir, "nav.xhtml"))
     assert not exists(nav_file)
-    create_nav_file(xhtmls, nav_file, "Name of thing!", False)
+    mm_epub.create_nav_file(xhtmls, nav_file, "Name of thing!", False)
     assert exists(nav_file)
-    content = read_text_file(nav_file)
+    content = mm_file_tools.read_text_file(nav_file)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:epub=\"http://www.idpf.org/2007/ops\" lang=\"en\" xml:lang=\"en\">"
     compare = f"{compare}<head><meta charset=\"utf-8\" /><title>Name of thing!</title></head>"
     compare = f"{compare}<body><h1>Name of thing!</h1><nav epub:type=\"toc\" id=\"toc\">"
     compare = f"{compare}<ol><li><a href=\"content/[00] Cover.xhtml\">Cover</a></li>"
     compare = f"{compare}<li><a href=\"content/Chapter 1.xhtml\">Chapter 1</a></li>"
     compare = f"{compare}<li><a href=\"content/Chapter 2.xhtml\">Chapter 2</a></li>"
     compare = f"{compare}<li><a href=\"content/Epilogues.xhtml\">Epilogues</a></li>"
     compare = f"{compare}</ol></nav></body></html>"
     assert content == compare
     # Test creating nav file with indents
     xhtmls = [abspath(join(temp_dir, "[3] Cover.xhtml"))]
-    create_nav_file(xhtmls, nav_file, "Other thing", True)
-    content = read_text_file(nav_file)
+    mm_epub.create_nav_file(xhtmls, nav_file, "Other thing", True)
+    content = mm_file_tools.read_text_file(nav_file)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:epub=\"http://www.idpf.org/2007/ops\" lang=\"en\" xml:lang=\"en\">\n"
     compare = f"{compare}   <head>\n"
     compare = f"{compare}      <meta charset=\"utf-8\" />\n"
     compare = f"{compare}      <title>Other thing</title>\n"
     compare = f"{compare}   </head>\n"
     compare = f"{compare}   <body>\n"
@@ -417,24 +400,24 @@
 
 def test_create_ncx_file():
     """
     Tests the create_ncx_file function.
     """
     # Test creating ncx file
     xhtmls = []
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     xhtmls.append(abspath(join(temp_dir, "[00] Cover.xhtml")))
     xhtmls.append(abspath(join(temp_dir, "Chapter 1.xhtml")))
     xhtmls.append(abspath(join(temp_dir, "Chapter 2.xhtml")))
     xhtmls.append(abspath(join(temp_dir, "Epilogues.xhtml")))
     ncx_file = abspath(join(temp_dir, "toc.ncx"))
     assert not exists(ncx_file)
-    create_ncx_file(xhtmls, ncx_file, "Name of thing!", "UNIQUE-id", False)
+    mm_epub.create_ncx_file(xhtmls, ncx_file, "Name of thing!", "UNIQUE-id", False)
     assert exists(ncx_file)
-    content = read_text_file(ncx_file)
+    content = mm_file_tools.read_text_file(ncx_file)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<ncx xmlns=\"http://www.daisy.org/z3986/2005/ncx/\" version=\"2005-1\">"
     compare = f"{compare}<head><meta content=\"UNIQUE-id\" name=\"dtb:uid\" />"
     compare = f"{compare}<meta content=\"0\" name=\"dtb:depth\" />"
     compare = f"{compare}<meta content=\"0\" name=\"dtb:totalPageCount\" />"
     compare = f"{compare}<meta content=\"0\" name=\"dtb:maxPageNumber\" /></head>"
     compare = f"{compare}<docTitle><text>Name of thing!</text></docTitle><navMap>"
@@ -445,16 +428,16 @@
     compare = f"{compare}<navPoint id=\"Chapter 2-xhtml\"><navLabel><text>Chapter 2</text></navLabel>"
     compare = f"{compare}<content>content/Chapter 2.xhtml</content></navPoint>"
     compare = f"{compare}<navPoint id=\"Epilogues-xhtml\"><navLabel><text>Epilogues</text></navLabel>"
     compare = f"{compare}<content>content/Epilogues.xhtml</content></navPoint></navMap></ncx>"
     assert content == compare
     # Test creating ncx file with indents
     xhtmls = [abspath(join(temp_dir, "[3] Cover.xhtml"))]
-    create_ncx_file(xhtmls, ncx_file, "Other thing", "new-uid", True)
-    content = read_text_file(ncx_file)
+    mm_epub.create_ncx_file(xhtmls, ncx_file, "Other thing", "new-uid", True)
+    content = mm_file_tools.read_text_file(ncx_file)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<ncx xmlns=\"http://www.daisy.org/z3986/2005/ncx/\" version=\"2005-1\">\n"
     compare = f"{compare}   <head>\n"
     compare = f"{compare}      <meta content=\"new-uid\" name=\"dtb:uid\" />\n"
     compare = f"{compare}      <meta content=\"0\" name=\"dtb:depth\" />\n"
     compare = f"{compare}      <meta content=\"0\" name=\"dtb:totalPageCount\" />\n"
     compare = f"{compare}      <meta content=\"0\" name=\"dtb:maxPageNumber\" />\n"
@@ -474,20 +457,20 @@
     assert content == compare
 
 def test_create_manifest():
     """
     Tests the create_manifest function.
     """
     files = []
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     files.append(abspath(join(temp_dir, "[03] Cover.xhtml")))
     files.append(abspath(join(temp_dir, "Picture.png")))
     files.append(abspath(join(temp_dir, "[02] Jpeg!.jpg")))
     files.append(abspath(join(temp_dir, "Thing.svg")))
-    manifest = create_manifest(files)
+    manifest = mm_epub.create_manifest(files)
     compare = "<manifest>"
     compare = f"{compare}<item href=\"nav.xhtml\" id=\"toc\" media-type=\"application/xhtml+xml\" properties=\"nav\" />"
     compare = f"{compare}<item href=\"content/[03] Cover.xhtml\" id=\"Cover-xhtml\" media-type=\"application/xhtml+xml\" />"
     compare = f"{compare}<item href=\"images/Picture.png\" id=\"Picture-png\" media-type=\"image/png\" />"
     compare = f"{compare}<item href=\"images/[02] Jpeg!.jpg\" id=\"Jpeg!-jpg\" media-type=\"image/jpeg\" />"
     compare = f"{compare}<item href=\"images/Thing.svg\" id=\"Thing-svg\" media-type=\"image/svg+xml\" />"
     compare = f"{compare}<item href=\"style/epubstyle.css\" id=\"epubstyle-css\" media-type=\"text/css\" />"
@@ -498,201 +481,201 @@
     """
     Tests the create_metadata_xml function.
     """
     # Test setting title in the XML file
     start = "<metadata xmlns:dc=\"http://purl.org/dc/elements/1.1/\"><dc:language>en</dc:language>"
     end = "<meta property=\"dcterms:modified\">0000-00-00T00:00:00+00:00</meta>"
     end = f"{end}<dc:date>0000-00-00T00:00:00+00:00</dc:date></metadata>"
-    meta = get_empty_metadata()
+    meta = mm_meta_reader.get_empty_metadata()
     meta["title"] = "This's a title\\'"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:identifier>this's a title\\'</dc:identifier>"
     compare = f"{compare}<dc:title>This's a title\\'</dc:title>{end}"
     assert xml == compare
     # Test setting identifier in the XML file
-    base_meta = get_empty_metadata()
+    base_meta = mm_meta_reader.get_empty_metadata()
     base_meta["url"] = "this/is/a/test"
     base_meta["title"] = "Title."
     start = f"{start}<dc:identifier>this/is/a/test</dc:identifier>"
     start = f"{start}<dc:title>Title.</dc:title>"
-    xml = create_metadata_xml(base_meta)
+    xml = mm_epub.create_metadata_xml(base_meta)
     assert xml == f"{start}{end}"
     # Test setting description in the XML file
     meta = base_meta
     meta["description"] = "Description of the thing."
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     assert xml == f"{start}<dc:description>Description of the thing.</dc:description>{end}"
     meta["description"] = "'Tis this & That's >.<"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     assert xml == f"{start}<dc:description>'Tis this &amp; That's &gt;.&lt;</dc:description>{end}"
     # Test setting writer() in XML file
     meta["description"] = None
     meta["writer"] = "Person!"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:creator id=\"author1\">Person!</dc:creator>"
     compare = f"{compare}<meta refines=\"#author1\" property=\"role\" scheme=\"marc:relators\">aut</meta>"
     assert xml == f"{compare}{end}"
     meta["writer"] = "More,People"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:creator id=\"author1\">More</dc:creator>"
     compare = f"{compare}<meta refines=\"#author1\" property=\"role\" scheme=\"marc:relators\">aut</meta>"
     compare = f"{compare}<dc:creator id=\"author2\">People</dc:creator>"
     compare = f"{compare}<meta refines=\"#author2\" property=\"role\" scheme=\"marc:relators\">aut</meta>"
     assert xml == f"{compare}{end}"
     # Test setting cover artist in XML file
     meta["writer"] = None
     meta["cover_artist"] = "Guest"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:creator id=\"covartist1\">Guest</dc:creator>"
     compare = f"{compare}<meta refines=\"#covartist1\" property=\"role\" scheme=\"marc:relators\">cov</meta>"
     assert xml == f"{compare}{end}"
     meta["cover_artist"] = "Other,Folks"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:creator id=\"covartist1\">Other</dc:creator>"
     compare = f"{compare}<meta refines=\"#covartist1\" property=\"role\" scheme=\"marc:relators\">cov</meta>"
     compare = f"{compare}<dc:creator id=\"covartist2\">Folks</dc:creator>"
     compare = f"{compare}<meta refines=\"#covartist2\" property=\"role\" scheme=\"marc:relators\">cov</meta>"
     assert xml == f"{compare}{end}"
     # Test setting illustrator in XML file
     meta["cover_artist"] = None
     meta["artist"] = "Bleh"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:creator id=\"illustrator1\">Bleh</dc:creator>"
     compare = f"{compare}<meta refines=\"#illustrator1\" property=\"role\" scheme=\"marc:relators\">ill</meta>"
     assert xml == f"{compare}{end}"
     meta["artist"] = "Other,Artist"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:creator id=\"illustrator1\">Other</dc:creator>"
     compare = f"{compare}<meta refines=\"#illustrator1\" property=\"role\" scheme=\"marc:relators\">ill</meta>"
     compare = f"{compare}<dc:creator id=\"illustrator2\">Artist</dc:creator>"
     compare = f"{compare}<meta refines=\"#illustrator2\" property=\"role\" scheme=\"marc:relators\">ill</meta>"
     assert xml == f"{compare}{end}"
     # Test setting publisher in XML file
     meta["artist"] = None
     meta["publisher"] = "Company"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:publisher>Company</dc:publisher>{end}"
     assert xml == compare
     # Test setting date in the XML file
     meta["publisher"] = None
     meta["date"] = "2023-01-15"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     end = "<meta property=\"dcterms:modified\">2023-01-15T00:00:00+00:00</meta>"
     end = f"{end}<dc:date>2023-01-15T00:00:00+00:00</dc:date></metadata>"
     assert xml == f"{start}{end}"
     meta["date"] = "2014-12-08"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     end = "<meta property=\"dcterms:modified\">2014-12-08T00:00:00+00:00</meta>"
     end = f"{end}<dc:date>2014-12-08T00:00:00+00:00</dc:date></metadata>"
     assert xml == f"{start}{end}"
     # Test setting series info in the XML file
     meta["series"] = "Name!!"
     meta["series_number"] = "2.5"
     meta["series_total"] = "5"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<meta property=\"belongs-to-collection\" id=\"series-title\">Name!!</meta>"
     compare = f"{compare}<meta refines=\"series-title\" property=\"collection-type\">series</meta>"
     compare = f"{compare}<meta refines=\"series-title\" property=\"group-position\">2.5</meta>{end}"
     assert xml == compare
     # Test setting invalid series number
     meta["series_number"] = "NotNumber"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<meta property=\"belongs-to-collection\" id=\"series-title\">Name!!</meta>"
     compare = f"{compare}<meta refines=\"series-title\" property=\"collection-type\">series</meta>{end}"
     assert xml == compare
     # Test setting tags in XML file
     meta["series"] = None
     meta["series_number"] = None
     meta["tags"] = "Some,Tags,&,stuff"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<dc:subject>Some</dc:subject>"
     compare = f"{compare}<dc:subject>Tags</dc:subject>"
     compare = f"{compare}<dc:subject>&amp;</dc:subject>"
     compare = f"{compare}<dc:subject>stuff</dc:subject>{end}"
     assert xml == compare
     # Test setting the score in the XML file
     meta["tags"] = None
     meta["score"] = "0"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     assert xml == f"{start}<meta property=\"calibre:rating\">0.0</meta>{end}"
     meta["score"] = "2"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<meta property=\"calibre:rating\">4.0</meta>"
     compare = f"{compare}<dc:subject>&#9733;&#9733;</dc:subject>{end}"
     assert xml == compare
     meta["score"] = "5"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<meta property=\"calibre:rating\">10.0</meta>"
     compare = f"{compare}<dc:subject>&#9733;&#9733;&#9733;&#9733;&#9733;</dc:subject>{end}"
     assert xml == compare
     # Test setting invalid score in XML file
     meta["score"] = "Blah"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     assert xml == f"{start}{end}"
     meta["score"] = "6"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     assert xml == f"{start}{end}"
     meta["score"] = "-3"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     assert xml == f"{start}{end}"
     # Test adding score as tags
     meta["tags"] = "These,are,things"
     meta["score"] = "3"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<meta property=\"calibre:rating\">6.0</meta>"
     compare = f"{compare}<dc:subject>&#9733;&#9733;&#9733;</dc:subject>"
     compare = f"{compare}<dc:subject>These</dc:subject>"
     compare = f"{compare}<dc:subject>are</dc:subject>"
     compare = f"{compare}<dc:subject>things</dc:subject>{end}"
     assert xml == compare
     meta["score"] = "5"
     meta["tags"] = None
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     compare = f"{start}<meta property=\"calibre:rating\">10.0</meta>"
     compare = f"{compare}<dc:subject>&#9733;&#9733;&#9733;&#9733;&#9733;</dc:subject>{end}"
     assert xml == compare
     meta["score"] = "0"
-    xml = create_metadata_xml(meta)
+    xml = mm_epub.create_metadata_xml(meta)
     assert xml == f"{start}<meta property=\"calibre:rating\">0.0</meta>{end}"
 
 def test_create_epub_files():
     """
     Tests the create_epub_files function.
     """
     # Create test files
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     content = abspath(join(temp_dir, "content"))
     images = abspath(join(temp_dir, "images"))
-    mkdir(content)
-    mkdir(images)
+    os.mkdir(content)
+    os.mkdir(images)
     assert isdir(content) and exists(content)
     cover_page = abspath(join(content, "[00] Cover.xhtml"))
     chapter_page = abspath(join(content, "[01] Chapter1.xhtml"))
     cover_image = abspath(join(images, "cover.png"))
     internal_image = abspath(join(images, "other.jpeg"))
-    write_text_file(cover_page, "Doesn't")
-    write_text_file(chapter_page, "Really")
-    write_text_file(cover_image, "Matter")
-    write_text_file(internal_image, "To Me")
+    mm_file_tools.write_text_file(cover_page, "Doesn't")
+    mm_file_tools.write_text_file(chapter_page, "Really")
+    mm_file_tools.write_text_file(cover_image, "Matter")
+    mm_file_tools.write_text_file(internal_image, "To Me")
     assert exists(cover_page)
     assert exists(chapter_page)
     assert exists(cover_image)
     assert exists(internal_image)
     # Create content file
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Experimental Title"
     metadata["url"] = "thing/page/"
     metadata["date"] = "2020-04-02"
     nav_file = abspath(join(temp_dir, "nav.xhtml"))
     ncx_file = abspath(join(temp_dir, "toc.ncx"))
     content_file = abspath(join(temp_dir, "content.opf"))
-    create_epub_files(temp_dir, metadata)
+    mm_epub.create_epub_files(temp_dir, metadata)
     # Test that nav file is correct
     assert exists(nav_file)
-    contents = read_text_file(nav_file)
+    contents = mm_file_tools.read_text_file(nav_file)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\" "
     compare = f"{compare}xmlns:epub=\"http://www.idpf.org/2007/ops\" lang=\"en\" xml:lang=\"en\">\n"
     compare = f"{compare}   <head>\n"
     compare = f"{compare}      <meta charset=\"utf-8\" />\n"
     compare = f"{compare}      <title>Experimental Title</title>\n"
     compare = f"{compare}   </head>\n"
@@ -709,15 +692,15 @@
     compare = f"{compare}         </ol>\n"
     compare = f"{compare}      </nav>\n"
     compare = f"{compare}   </body>\n"
     compare = f"{compare}</html>"
     assert contents == compare
     # Test that ncx file is correct
     assert exists(ncx_file)
-    contents = read_text_file(ncx_file)
+    contents = mm_file_tools.read_text_file(ncx_file)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<ncx xmlns=\"http://www.daisy.org/z3986/2005/ncx/\" version=\"2005-1\">\n"
     compare = f"{compare}   <head>\n"
     compare = f"{compare}      <meta content=\"thing/page/\" name=\"dtb:uid\" />\n"
     compare = f"{compare}      <meta content=\"0\" name=\"dtb:depth\" />\n"
     compare = f"{compare}      <meta content=\"0\" name=\"dtb:totalPageCount\" />\n"
     compare = f"{compare}      <meta content=\"0\" name=\"dtb:maxPageNumber\" />\n"
@@ -739,15 +722,15 @@
     compare = f"{compare}         <content>content/[01] Chapter1.xhtml</content>\n"
     compare = f"{compare}      </navPoint>\n"
     compare = f"{compare}   </navMap>\n"
     compare = f"{compare}</ncx>"
     assert contents == compare
     # Test that package file is correct
     assert exists(content_file)
-    contents = read_text_file(content_file)
+    contents = mm_file_tools.read_text_file(content_file)
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<package xmlns:dc=\"http://purl.org/dc/elements/1.1/\" "
     compare = f"{compare}xmlns=\"http://www.idpf.org/2007/opf\" unique-identifier=\"uid\" version=\"3.0\">\n"
     compare = f"{compare}   <metadata>\n"
     compare = f"{compare}      <dc:language>en</dc:language>\n"
     compare = f"{compare}      <dc:identifier>thing/page/</dc:identifier>\n"
     compare = f"{compare}      <dc:title>Experimental Title</dc:title>\n"
@@ -770,58 +753,58 @@
     assert contents == compare
 
 def test_create_epub():
     """
     Tests the create_epub function.
     """
     # Create test files
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     json = abspath(join(temp_dir, "blah.json"))
     text_page = abspath(join(temp_dir, "Text.txt"))
     html_page = abspath(join(temp_dir, "Html.htm"))
     cover_file = abspath(join(temp_dir, "[00] Cover.png"))
     internal_file = abspath(join(temp_dir, "Other.jpeg"))
-    write_text_file(json, "Some thing")
-    write_text_file(html_page, "<p>Some things</p>")
-    write_text_file(text_page, "This is some text!!!")
+    mm_file_tools.write_text_file(json, "Some thing")
+    mm_file_tools.write_text_file(html_page, "<p>Some things</p>")
+    mm_file_tools.write_text_file(text_page, "This is some text!!!")
     cover_image = Image.new("RGB", (100, 200), color=(255,0,0))
     internal_image = Image.new("RGB", (500, 300), color=(0,255,0))
     cover_image.save(cover_file)
     internal_image.save(internal_file)
     assert exists(json)
     assert exists(text_page)
     assert exists(html_page)
     assert exists(cover_file)
     assert exists(internal_file)
     # Attempt to create an epub archive
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "New Title."
-    epub = create_epub(temp_dir, metadata)
+    epub = mm_epub.create_epub(temp_dir, metadata)
     assert exists(epub)
     assert basename(epub) == "dvk_meta_magic.epub"
     # Extract epub and check its contents
     extract_dir = abspath(join(temp_dir, "ext"))
-    mkdir(extract_dir)
-    extract_zip(epub, extract_dir)
-    files = sort_alphanum(listdir(extract_dir))
+    os.mkdir(extract_dir)
+    mm_file_tools.extract_zip(epub, extract_dir)
+    files = sorted(os.listdir(extract_dir))
     assert files == ["EPUB", "META-INF", "mimetype"]
     # Check the contents of the EPUB folder
     epub_dir = abspath(join(extract_dir, "EPUB"))
-    files = sort_alphanum(listdir(epub_dir))
+    files = sorted(os.listdir(epub_dir))
     assert files == ["content", "content.opf", "images", "nav.xhtml", "original", "style", "toc.ncx"]
     # Check the contents of the "original" folder
     original_folder = abspath(join(epub_dir, "original"))
-    files = sort_alphanum(listdir(original_folder))
-    assert files == ["[00] Cover.png", "blah.json", "Html.htm", "Other.jpeg", "Text.txt"]
+    files = sorted(os.listdir(original_folder))
+    assert files == ["Html.htm", "Other.jpeg", "Text.txt", "[00] Cover.png", "blah.json"]
     # Check the contents of the "content" folder
     content_folder = abspath(join(epub_dir, "content"))
-    files = sort_alphanum(listdir(content_folder))
-    assert files == ["[00] Cover.xhtml", "Html.xhtml", "Other.xhtml", "Text.xhtml"]
+    files = sorted(os.listdir(content_folder))
+    assert files == ["Html.xhtml", "Other.xhtml", "Text.xhtml", "[00] Cover.xhtml"]
     # Check the contents of the cover image xhtml
-    xml = read_text_file(abspath(join(content_folder, "[00] Cover.xhtml")))
+    xml = mm_file_tools.read_text_file(abspath(join(content_folder, "[00] Cover.xhtml")))
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\">\n"
     compare = f"{compare}   <head>\n"
     compare = f"{compare}      <title>Cover</title>\n"
     compare = f"{compare}      <meta charset=\"utf-8\" />\n"
     compare = f"{compare}      <meta content=\"width=100, height=200\" name=\"viewport\" />\n"
     compare = f"{compare}      <link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />\n"
@@ -830,15 +813,15 @@
     compare = f"{compare}      <div class=\"image-page-container\">\n"
     compare = f"{compare}         <img class=\"vertical-image-page\" src=\"../images/[00] Cover.png\" alt=\"Cover\" />\n"
     compare = f"{compare}      </div>\n"
     compare = f"{compare}   </body>\n"
     compare = f"{compare}</html>"
     assert xml == compare
     # Check the contents of the other image xhtml
-    xml = read_text_file(abspath(join(content_folder, "Other.xhtml")))
+    xml = mm_file_tools.read_text_file(abspath(join(content_folder, "Other.xhtml")))
     compare = "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n"
     compare = f"{compare}<html xmlns=\"http://www.w3.org/1999/xhtml\">\n"
     compare = f"{compare}   <head>\n"
     compare = f"{compare}      <title>Other</title>\n"
     compare = f"{compare}      <meta charset=\"utf-8\" />\n"
     compare = f"{compare}      <meta content=\"width=500, height=300\" name=\"viewport\" />\n"
     compare = f"{compare}      <link rel=\"stylesheet\" href=\"../style/epubstyle.css\" type=\"text/css\" />\n"
@@ -848,13 +831,13 @@
     compare = f"{compare}         <img class=\"horizontal-image-page\" src=\"../images/Other.jpeg\" alt=\"Other\" />\n"
     compare = f"{compare}      </div>\n"
     compare = f"{compare}   </body>\n"
     compare = f"{compare}</html>"
     assert xml == compare
     # Check the contents of the "images" folder
     content_folder = abspath(join(epub_dir, "images"))
-    files = sort_alphanum(listdir(content_folder))
-    assert files == ["[00] Cover.png", "Other.jpeg"]
+    files = sorted(os.listdir(content_folder))
+    assert files == ["Other.jpeg", "[00] Cover.png"]
     # Check the contents of the "style" folder
     content_folder = abspath(join(epub_dir, "style"))
-    files = sort_alphanum(listdir(content_folder))
+    files = sorted(os.listdir(content_folder))
     assert files == ["epubstyle.css"]
```

## Comparing `metadata_magic/test/error_finding/test_missing_fields.py` & `metadata_magic/test/error/test_missing_fields.py`

 * *Files 12% similar despite different names*

```diff
@@ -1,163 +1,160 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.meta_reader import get_empty_metadata
-from metadata_magic.main.comic_archive.comic_xml import get_comic_xml
-from metadata_magic.main.error_finding.missing_fields import find_missing_fields
-from metadata_magic.main.error_finding.missing_fields import find_missing_comic_info
-from metadata_magic.main.comic_archive.comic_archive import create_cbz
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import create_zip
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import listdir, mkdir, remove
+import os
+import shutil
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.meta_reader as mm_meta_reader
+import metadata_magic.archive.comic_xml as mm_comic_xml
+import metadata_magic.archive.comic_archive as mm_comic_archive
+import metadata_magic.error.missing_fields as mm_missing_fields
 from os.path import abspath, basename, exists, join
-from shutil import copy
 
 def test_find_missing_comic_info():
     """
     Tests the find_missing_comic_info function.
     """
     # Create CBZ test files
-    temp_dir = get_temp_dir()
-    cbz_build_dir = get_temp_dir("dvk_cbz_builder")
+    temp_dir = mm_file_tools.get_temp_dir()
+    cbz_build_dir = mm_file_tools.get_temp_dir("dvk_cbz_builder")
     text_file = abspath(join(cbz_build_dir, "text.txt"))
-    write_text_file(text_file, "This is text")
+    mm_file_tools.write_text_file(text_file, "This is text")
     assert exists(text_file)
-    cbz_file = create_cbz(cbz_build_dir, "no-meta")
+    cbz_file = mm_comic_archive.create_cbz(cbz_build_dir, "no-meta")
     assert exists(cbz_file)
-    copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
-    remove(cbz_file)
-    cbz_file = create_cbz(cbz_build_dir, "empty-meta", metadata=get_empty_metadata())
-    assert exists(cbz_file)
-    copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
-    remove(cbz_file)
-    metadata = get_empty_metadata()
+    shutil.copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
+    os.remove(cbz_file)
+    cbz_file = mm_comic_archive.create_cbz(cbz_build_dir, "empty-meta", metadata=mm_meta_reader.get_empty_metadata())
+    assert exists(cbz_file)
+    shutil.copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
+    os.remove(cbz_file)
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Bare Minimum"
-    cbz_file = create_cbz(cbz_build_dir, "some-meta", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_build_dir, "some-meta", metadata=metadata)
     assert exists(cbz_file)
-    copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
-    remove(cbz_file)
-    assert sorted(listdir(temp_dir)) == ["empty-meta.cbz", "no-meta.cbz", "some-meta.cbz"]
+    shutil.copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
+    os.remove(cbz_file)
+    assert sorted(os.listdir(temp_dir)) == ["empty-meta.cbz", "no-meta.cbz", "some-meta.cbz"]
     # Test finding CBZ files with no metadata
-    missing = find_missing_comic_info(temp_dir)
+    missing = mm_missing_fields.find_missing_comic_info(temp_dir)
     assert len(missing) == 2
     assert basename(missing[0]) == "empty-meta.cbz"
     assert basename(missing[1]) == "no-meta.cbz"
     # Test finding CBZ files with metadata in the wrong place
     sub_dir = abspath(join(cbz_build_dir, "sub"))
-    mkdir(sub_dir)
+    os.mkdir(sub_dir)
     metadata_file = abspath(join(sub_dir, "ComicInfo.xml"))
-    write_text_file(metadata_file, get_comic_xml(metadata))
+    mm_file_tools.write_text_file(metadata_file, mm_comic_xml.get_comic_xml(metadata))
     assert exists(metadata_file)
     cbz_file = abspath(join(temp_dir, "internal-meta.cbz"))
-    create_zip(cbz_build_dir, cbz_file)
-    assert sorted(listdir(temp_dir)) == ["empty-meta.cbz", "internal-meta.cbz", "no-meta.cbz", "some-meta.cbz"]
-    missing = find_missing_comic_info(temp_dir)
+    mm_file_tools.create_zip(cbz_build_dir, cbz_file)
+    assert sorted(os.listdir(temp_dir)) == ["empty-meta.cbz", "internal-meta.cbz", "no-meta.cbz", "some-meta.cbz"]
+    missing = mm_missing_fields.find_missing_comic_info(temp_dir)
     assert len(missing) == 3
     assert basename(missing[0]) == "empty-meta.cbz"
     assert basename(missing[1]) == "internal-meta.cbz"
     assert basename(missing[2]) == "no-meta.cbz"
 
 def test_find_missing_fields():
     """
     Tests the find_missing_fields function.
     """
     # Create CBZ test file A
-    temp_dir = get_temp_dir()
-    cbz_build_dir = get_temp_dir("dvk_cbz_builder")
+    temp_dir = mm_file_tools.get_temp_dir()
+    cbz_build_dir = mm_file_tools.get_temp_dir("dvk_cbz_builder")
     text_file = abspath(join(cbz_build_dir, "text.txt"))
-    write_text_file(text_file, "This is text!!!")
+    mm_file_tools.write_text_file(text_file, "This is text!!!")
     assert exists(text_file)
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["series"] = "The Series"
     metadata["description"] = "Description"
     metadata["tags"] = "More Stuff"
     metadata["score"] = 5
-    cbz_file = create_cbz(cbz_build_dir, "CBZ-A", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_build_dir, "CBZ-A", metadata=metadata)
     assert exists(cbz_file)
-    copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
-    remove(cbz_file)
+    shutil.copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
+    os.remove(cbz_file)
     # Create CBZ test file B
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Comic Book B"
     metadata["description"] = "Something"
     metadata["date"] = "2054-03-29"
     metadata["tags"] = "something"
     metadata["url"] = "/page/thing"
     metadata["score"] = 2
-    cbz_file = create_cbz(cbz_build_dir, "CBZ-B", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_build_dir, "CBZ-B", metadata=metadata)
     assert exists(cbz_file)
-    copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
-    remove(cbz_file)
+    shutil.copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
+    os.remove(cbz_file)
     # Create CBZ test file C
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["date"] = "2040-12-03"
     metadata["artist"] = "Person"
     metadata["publisher"] = "New Thing LLC"
     metadata["url"] = "HopefullyNotReal.website"
     metadata["age_rating"] = "Everyone"
-    cbz_file = create_cbz(cbz_build_dir, "CBZ-C", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_build_dir, "CBZ-C", metadata=metadata)
     assert exists(cbz_file)
-    copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
-    remove(cbz_file)
+    shutil.copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
+    os.remove(cbz_file)
     # Create CBZ test file D
-    metadata = get_empty_metadata()
+    metadata = mm_meta_reader.get_empty_metadata()
     metadata["title"] = "Comic Book D"
     metadata["series"] = "The Series"
     metadata["writer"] = "Different Person"
     metadata["tags"] = "these,are,tags"
     metadata["age_rating"] = "Teen"
-    cbz_file = create_cbz(cbz_build_dir, "CBZ-D", metadata=metadata)
+    cbz_file = mm_comic_archive.create_cbz(cbz_build_dir, "CBZ-D", metadata=metadata)
     assert exists(cbz_file)
-    copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
-    remove(cbz_file)
-    assert sorted(listdir(temp_dir)) == ["CBZ-A.cbz", "CBZ-B.cbz", "CBZ-C.cbz", "CBZ-D.cbz"]
+    shutil.copy(cbz_file, abspath(join(temp_dir, basename(cbz_file))))
+    os.remove(cbz_file)
+    assert sorted(os.listdir(temp_dir)) == ["CBZ-A.cbz", "CBZ-B.cbz", "CBZ-C.cbz", "CBZ-D.cbz"]
     # Test finding missing title
-    missing = find_missing_fields(temp_dir, ["title"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["title"])
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-A.cbz"
     assert basename(missing[1]) == "CBZ-C.cbz"
     # Test finding missing series
-    missing = find_missing_fields(temp_dir, ["series"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["series"])
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-B.cbz"
     assert basename(missing[1]) == "CBZ-C.cbz"
     # Test finding missing description
-    missing = find_missing_fields(temp_dir, ["description"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["description"])
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-C.cbz"
     assert basename(missing[1]) == "CBZ-D.cbz"
     # Test finding missing date
-    missing = find_missing_fields(temp_dir, ["date"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["date"])
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-A.cbz"
     assert basename(missing[1]) == "CBZ-D.cbz"
     # Test finding missing artist
-    missing = find_missing_fields(temp_dir, ["artist", "writer"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["artist", "writer"])
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-A.cbz"
     assert basename(missing[1]) == "CBZ-B.cbz"
     # Test finding missing publisher
-    missing = find_missing_fields(temp_dir, ["publisher"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["publisher"])
     assert len(missing) == 3
     assert basename(missing[0]) == "CBZ-A.cbz"
     assert basename(missing[1]) == "CBZ-B.cbz"
     assert basename(missing[2]) == "CBZ-D.cbz"
     # Test finding missing tags
-    missing = find_missing_fields(temp_dir, ["tags"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["tags"])
     assert len(missing) == 1
     assert basename(missing[0]) == "CBZ-C.cbz"
     # Test finding missing url
-    missing = find_missing_fields(temp_dir, ["url"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["url"])
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-A.cbz"
     assert basename(missing[1]) == "CBZ-D.cbz"
     # Test finding missing age_rating
-    missing = find_missing_fields(temp_dir, ["age_rating"], null_value="Unknown")
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["age_rating"], null_value="Unknown")
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-A.cbz"
     assert basename(missing[1]) == "CBZ-B.cbz"
     # Test finding missing score
-    missing = find_missing_fields(temp_dir, ["score"])
+    missing = mm_missing_fields.find_missing_fields(temp_dir, ["score"])
     assert len(missing) == 2
     assert basename(missing[0]) == "CBZ-C.cbz"
     assert basename(missing[1]) == "CBZ-D.cbz"
```

## Comparing `metadata_magic/test/error_finding/test_missing_metadata.py` & `metadata_magic/test/error/test_missing_media.py`

 * *Files 21% similar despite different names*

```diff
@@ -1,35 +1,34 @@
 #!/usr/bin/env python3
 
-from metadata_magic.main.error_finding.missing_metadata import find_missing_metadata
-from metadata_magic.main.file_tools.file_tools import get_temp_dir
-from metadata_magic.main.file_tools.file_tools import write_text_file
-from os import mkdir, pardir
+import os
+import metadata_magic.file_tools as mm_file_tools
+import metadata_magic.error.missing_media as mm_missing_media
 from os.path import abspath, basename, exists, join
 
-def test_find_missing_metadata():
+def test_find_missing_media():
     """
-    Tests the find_missing_metadata function.
+    Test the find_missing_media function.
     """
     # Test with empty directory
-    temp_dir = get_temp_dir()
+    temp_dir = mm_file_tools.get_temp_dir()
     assert exists(temp_dir)
-    assert find_missing_metadata(temp_dir) == []
+    assert mm_missing_media.find_missing_media(temp_dir) == []
     # Test with no unlinked files
     sub = abspath(join(temp_dir, "sub"))
-    mkdir(sub)
-    write_text_file(abspath(join(temp_dir, "main.json")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "main.png")), "BLAH")
-    write_text_file(abspath(join(sub, "unlinked.json")), "BLAH")
-    assert find_missing_metadata(temp_dir) == []
+    os.mkdir(sub)
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "main.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "main.png")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub, "unlinked.txt")), "BLAH")
+    assert mm_missing_media.find_missing_media(temp_dir) == []
     # Test with unlinked files
-    write_text_file(abspath(join(temp_dir, "unlinked.txt")), "BLAH")
-    write_text_file(abspath(join(temp_dir, "thing.jpg")), "BLAH")
-    write_text_file(abspath(join(sub, "next.cbz")), "BLAH")
-    missing_metadata = find_missing_metadata(temp_dir)
-    assert len(missing_metadata) == 3
-    assert basename(missing_metadata[0]) == "next.cbz"
-    assert abspath(join(missing_metadata[0], pardir)) == sub
-    assert basename(missing_metadata[1]) == "thing.jpg"
-    assert abspath(join(missing_metadata[1], pardir)) == temp_dir
-    assert basename(missing_metadata[2]) == "unlinked.txt"
-    assert abspath(join(missing_metadata[2], pardir)) == temp_dir
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "unlinked.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(temp_dir, "thing.json")), "BLAH")
+    mm_file_tools.write_text_file(abspath(join(sub, "next.json")), "BLAH")
+    missing_media = mm_missing_media.find_missing_media(temp_dir)
+    assert len(missing_media) == 3
+    assert basename(missing_media[0]) == "next.json"
+    assert abspath(join(missing_media[0], os.pardir)) == sub
+    assert basename(missing_media[1]) == "thing.json"
+    assert abspath(join(missing_media[1], os.pardir)) == temp_dir
+    assert basename(missing_media[2]) == "unlinked.json"
+    assert abspath(join(missing_media[2], os.pardir)) == temp_dir
```

## Comparing `Metadata_Magic-0.6.2.dist-info/LICENSE` & `Metadata_Magic-0.7.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `Metadata_Magic-0.6.2.dist-info/METADATA` & `Metadata_Magic-0.7.0.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: Metadata-Magic
-Version: 0.6.2
+Version: 0.7.0
 Summary: Utility for managing metadata.
 Home-page: https://github.com/Drakovek/MetadataMagic
 Author: Drakovek
 Author-email: DrakovekMail@gmail.com
 Classifier: Programming Language :: Python :: 3
 Classifier: License :: OSI Approved :: GNU General Public License v3 (GPLv3)
 Classifier: Operating System :: OS Independent
```

## Comparing `Metadata_Magic-0.6.2.dist-info/entry_points.txt` & `Metadata_Magic-0.7.0.dist-info/entry_points.txt`

 * *Files 23% similar despite different names*

```diff
@@ -1,12 +1,12 @@
 [console_scripts]
-archive-all-comics = metadata_magic.main.comic_archive.archive_all:main
-archive-book = metadata_magic.main.epub.epub:main
-archive-comic = metadata_magic.main.comic_archive.comic_archive:main
-archive-series = metadata_magic.main.comic_archive.series_info:main
-extract-all-comics = metadata_magic.main.comic_archive.extract_all:main
-meta-missing-fields = metadata_magic.main.error_finding.missing_fields:main
-meta-missing-media = metadata_magic.main.error_finding.missing_media:main
-meta-missing-metadata = metadata_magic.main.error_finding.missing_metadata:main
-meta-rename = metadata_magic.main.rename.meta_rename:main
-sort-rename = metadata_magic.main.rename.sort_rename:main
-update-comic-archives = metadata_magic.main.comic_archive.comic_archive_update:main
+archive-all-comics = metadata_magic.archive.archive_all:main
+archive-book = metadata_magic.archive.epub:main
+archive-comic = metadata_magic.archive.comic_archive:main
+archive-series = metadata_magic.archive.series_info:main
+extract-all-comics = metadata_magic.archive.extract_all:main
+meta-missing-fields = metadata_magic.error.missing_fields:main
+meta-missing-media = metadata_magic.error.missing_media:main
+meta-missing-metadata = metadata_magic.error.missing_metadata:main
+meta-rename = metadata_magic.rename.meta_rename:main
+sort-rename = metadata_magic.rename.sort_rename:main
+update-comic-archives = metadata_magic.archive.comic_archive_update:main
```

